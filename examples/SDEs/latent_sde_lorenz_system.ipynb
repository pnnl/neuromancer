{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchSDE + Neuromancer: Latent Stochastic Differential Equations (System ID of Stochastic Process)\n",
    "\n",
    "This notebook goes over how to utilize torchsde's functionality within Neuromancer framework. This notebook is based off: https://github.com/google-research/torchsde/blob/master/examples/latent_sde_lorenz.py. In this example, we generate data according to a 3-dimensional stochastic Lorenz attractor. We then perform a \"system identification\" on this data -- seek to model a stochastic differential equation on this data. Upon performant training, this LatentSDE will then be able to reproduce samples that exhibit the same behavior as the provided Lorenz system. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f51db129530>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from neuromancer.psl import plot\n",
    "from neuromancer import psl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from neuromancer.system import Node\n",
    "from neuromancer.dynamics import integrators, ode\n",
    "from neuromancer.trainer import Trainer\n",
    "from neuromancer.problem import Problem\n",
    "from neuromancer.loggers import BasicLogger\n",
    "from neuromancer.dataset import DictDataset\n",
    "from neuromancer.constraint import variable\n",
    "from neuromancer.loss import PenaltyLoss\n",
    "from neuromancer.modules import blocks\n",
    "\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Sequence\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import torchsde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to generate data from a Lorenz attractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearScheduler(object):\n",
    "    def __init__(self, iters, maxval=1.0):\n",
    "        self._iters = max(1, iters)\n",
    "        self._val = maxval / self._iters\n",
    "        self._maxval = maxval\n",
    "\n",
    "    def step(self):\n",
    "        self._val = min(self._maxval, self._val + self._maxval / self._iters)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self._val\n",
    "\n",
    "\n",
    "class StochasticLorenz(object):\n",
    "    \"\"\"Stochastic Lorenz attractor.\n",
    "\n",
    "    Used for simulating ground truth and obtaining noisy data.\n",
    "    Details described in Section 7.2 https://arxiv.org/pdf/2001.01328.pdf\n",
    "    Default a, b from https://openreview.net/pdf?id=HkzRQhR9YX\n",
    "    \"\"\"\n",
    "    noise_type = \"diagonal\"\n",
    "    sde_type = \"ito\"\n",
    "\n",
    "    def __init__(self, a: Sequence = (10., 28., 8 / 3), b: Sequence = (.1, .28, .3)):\n",
    "        super(StochasticLorenz, self).__init__()\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def f(self, t, y):\n",
    "        x1, x2, x3 = torch.split(y, split_size_or_sections=(1, 1, 1), dim=1)\n",
    "        a1, a2, a3 = self.a\n",
    "\n",
    "        f1 = a1 * (x2 - x1)\n",
    "        f2 = a2 * x1 - x2 - x1 * x3\n",
    "        f3 = x1 * x2 - a3 * x3\n",
    "        return torch.cat([f1, f2, f3], dim=1)\n",
    "\n",
    "    def g(self, t, y):\n",
    "        x1, x2, x3 = torch.split(y, split_size_or_sections=(1, 1, 1), dim=1)\n",
    "        b1, b2, b3 = self.b\n",
    "\n",
    "        g1 = x1 * b1\n",
    "        g2 = x2 * b2\n",
    "        g3 = x3 * b3\n",
    "        return torch.cat([g1, g2, g3], dim=1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, x0, ts, noise_std, normalize):\n",
    "        \"\"\"Sample data for training. Store data normalization constants if necessary.\"\"\"\n",
    "        xs = torchsde.sdeint(self, x0, ts)\n",
    "        if normalize:\n",
    "            mean, std = torch.mean(xs, dim=(0, 1)), torch.std(xs, dim=(0, 1))\n",
    "            xs.sub_(mean).div_(std).add_(torch.randn_like(xs) * noise_std)\n",
    "        return xs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def vis(xs, ts, latent_sde, bm_vis, img_path, num_samples=10):\n",
    "    fig = plt.figure(figsize=(20, 9))\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "    ax00 = fig.add_subplot(gs[0, 0], projection='3d')\n",
    "    ax01 = fig.add_subplot(gs[0, 1], projection='3d')\n",
    "\n",
    "    # Left plot: data.\n",
    "    z1, z2, z3 = np.split(xs.cpu().numpy(), indices_or_sections=3, axis=-1)\n",
    "    [ax00.plot(z1[:, i, 0], z2[:, i, 0], z3[:, i, 0]) for i in range(num_samples)]\n",
    "    ax00.scatter(z1[0, :num_samples, 0], z2[0, :num_samples, 0], z3[0, :10, 0], marker='x')\n",
    "    ax00.set_yticklabels([])\n",
    "    ax00.set_xticklabels([])\n",
    "    ax00.set_zticklabels([])\n",
    "    ax00.set_xlabel('$z_1$', labelpad=0., fontsize=16)\n",
    "    ax00.set_ylabel('$z_2$', labelpad=.5, fontsize=16)\n",
    "    ax00.set_zlabel('$z_3$', labelpad=0., horizontalalignment='center', fontsize=16)\n",
    "    ax00.set_title('Data', fontsize=20)\n",
    "    xlim = ax00.get_xlim()\n",
    "    ylim = ax00.get_ylim()\n",
    "    zlim = ax00.get_zlim()\n",
    "\n",
    "    # Right plot: samples from learned model.\n",
    "    xs = latent_sde.sample(batch_size=xs.size(1), ts=ts, bm=bm_vis).cpu().numpy()\n",
    "    z1, z2, z3 = np.split(xs, indices_or_sections=3, axis=-1)\n",
    "\n",
    "    [ax01.plot(z1[:, i, 0], z2[:, i, 0], z3[:, i, 0]) for i in range(num_samples)]\n",
    "    ax01.scatter(z1[0, :num_samples, 0], z2[0, :num_samples, 0], z3[0, :10, 0], marker='x')\n",
    "    ax01.set_yticklabels([])\n",
    "    ax01.set_xticklabels([])\n",
    "    ax01.set_zticklabels([])\n",
    "    ax01.set_xlabel('$z_1$', labelpad=0., fontsize=16)\n",
    "    ax01.set_ylabel('$z_2$', labelpad=.5, fontsize=16)\n",
    "    ax01.set_zlabel('$z_3$', labelpad=0., horizontalalignment='center', fontsize=16)\n",
    "    ax01.set_title('Samples', fontsize=20)\n",
    "    ax01.set_xlim(xlim)\n",
    "    ax01.set_ylim(ylim)\n",
    "    ax01.set_zlim(zlim)\n",
    "\n",
    "    plt.savefig(img_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1024\n",
    "latent_size=4\n",
    "context_size=64\n",
    "hidden_size=128\n",
    "lr_init=1e-2\n",
    "t0=0.\n",
    "t1=2.\n",
    "lr_gamma=0.997\n",
    "num_iters=1\n",
    "kl_anneal_iters=1000\n",
    "pause_every=50\n",
    "noise_std=0.01\n",
    "adjoint=False\n",
    "train_dir='./dump/lorenz/'\n",
    "method=\"euler\"\n",
    "\n",
    "def make_dataset(t0, t1, batch_size, noise_std, train_dir, device):\n",
    "    data_path = os.path.join(train_dir, 'lorenz_data.pth')\n",
    "    \n",
    "    _y0 = torch.randn(batch_size, 3, device=device)\n",
    "    ts = torch.linspace(t0, t1, steps=100, device=device)\n",
    "    xs = StochasticLorenz().sample(_y0, ts, noise_std, normalize=True)\n",
    "\n",
    "    os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "    torch.save({'xs': xs, 'ts': ts}, data_path)\n",
    "    logging.warning(f'Stored toy data at: {data_path}')\n",
    "    return xs, ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuromancer Integration\n",
    "\n",
    "Generate the data and create Neuromancer DictDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Stored toy data at: ./dump/lorenz/lorenz_data.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device='cpu'\n",
    "torch.manual_seed(0)\n",
    "xs, ts = make_dataset(t0=t0, t1=t1, batch_size=batch_size, noise_std=noise_std, train_dir=train_dir, device=device)\n",
    "train_data = DictDataset({'xs':xs},name='train')\n",
    "train_data_loader = DataLoader(train_data, batch_size=1024, collate_fn=train_data.collate_fn, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baz = next(iter(train_data_loader))\n",
    "baz['xs'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Neuromancer components, variables, and problem to train the LatentSDE. Upon training, this LatentSDE will generate new samples that exhibit the behavior of the Lorenz attractor training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sde_block_encoder = blocks.LatentSDE_Encoder(3, latent_size, context_size, hidden_size, ts=ts) \n",
    "integrator = integrators.LatentSDEIntegrator(sde_block_encoder)\n",
    "model_1 = Node(integrator, input_keys=['xs'], output_keys=['zs', 'z0', 'log_ratio',  'xs', 'qz0_mean', 'qz0_logstd'], name='m1')\n",
    "sde_block_decoder = blocks.LatentSDE_Decoder(3, latent_size, noise_std=noise_std)\n",
    "model_2 = Node(sde_block_decoder, input_keys=['xs', 'zs', 'log_ratio', 'qz0_mean', 'qz0_logstd'], output_keys=['log_pxs', 'sum_term', 'log_ratio'], name='m2' )\n",
    "\n",
    "xs = variable('xs')\n",
    "zs = variable('zs')\n",
    "z0 = variable('z0')\n",
    "\n",
    "\n",
    "log_ratio = variable('log_ratio')\n",
    "qz0_mean = variable('qz0_mean')\n",
    "qz0_logstd = variable('qz0_logstd')\n",
    "log_pxs = variable('log_pxs')\n",
    "sum_term = variable('sum_term')\n",
    "\n",
    "\n",
    "\n",
    "loss = (-1.0*log_pxs + log_ratio) == 0.0\n",
    "\n",
    "\n",
    "# aggregate list of objective terms and constraints\n",
    "objectives = [loss]\n",
    "constraints = []\n",
    "# create constrained optimization loss\n",
    "loss = PenaltyLoss(objectives, constraints)\n",
    "# construct constrained optimization problem\n",
    "problem = Problem([model_1, model_2], loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuromancer training the problem to learn the stochastic process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birm560/neuromancer/src/neuromancer/constraint.py:160: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([99, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.l1_loss(left, right)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train_loss: 1733993.375\n",
      "epoch: 1  train_loss: 1752146.75\n",
      "Early stopping!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('nodes.0.callable.block.pz0_mean', tensor([[0., 0., 0., 0.]])),\n",
       "             ('nodes.0.callable.block.pz0_logstd', tensor([[0., 0., 0., 0.]])),\n",
       "             ('nodes.0.callable.block.encoder.gru.weight_ih_l0',\n",
       "              tensor([[ 0.0622,  0.0806,  0.0510],\n",
       "                      [ 0.0128,  0.0423, -0.0440],\n",
       "                      [-0.0742, -0.0770,  0.0892],\n",
       "                      ...,\n",
       "                      [ 0.0462,  0.0818, -0.0287],\n",
       "                      [ 0.0035,  0.0163,  0.0892],\n",
       "                      [ 0.0800, -0.0467, -0.0742]])),\n",
       "             ('nodes.0.callable.block.encoder.gru.weight_hh_l0',\n",
       "              tensor([[-0.0787, -0.0416,  0.0753,  ...,  0.0738,  0.0458, -0.0140],\n",
       "                      [ 0.0055, -0.0083,  0.0195,  ..., -0.0700,  0.0129,  0.0738],\n",
       "                      [ 0.0586,  0.0747,  0.0488,  ...,  0.0444,  0.0043,  0.0752],\n",
       "                      ...,\n",
       "                      [ 0.0160, -0.0344, -0.0338,  ..., -0.0417, -0.0702, -0.0172],\n",
       "                      [ 0.0740, -0.0774, -0.0158,  ..., -0.0868,  0.0807, -0.0887],\n",
       "                      [ 0.0633, -0.0850,  0.0826,  ...,  0.0564,  0.0757,  0.0169]])),\n",
       "             ('nodes.0.callable.block.encoder.gru.bias_ih_l0',\n",
       "              tensor([-0.0452, -0.0429,  0.0288,  0.0250,  0.0309, -0.0208, -0.0182,  0.0214,\n",
       "                       0.0225, -0.0160, -0.0253,  0.0433, -0.0081,  0.0251, -0.0717,  0.0611,\n",
       "                      -0.0484, -0.0604,  0.0097,  0.0076,  0.0009, -0.0836, -0.0296,  0.0746,\n",
       "                       0.0440,  0.0314,  0.0762, -0.0095, -0.0818, -0.0215, -0.0561,  0.0033,\n",
       "                       0.0481,  0.0868,  0.0135,  0.0265,  0.0147,  0.0659,  0.0173,  0.0206,\n",
       "                      -0.0535,  0.0020, -0.0838,  0.0365,  0.0111,  0.0546, -0.0374,  0.0602,\n",
       "                       0.0119,  0.0321,  0.0072,  0.0349,  0.0670,  0.0828, -0.0544, -0.0836,\n",
       "                      -0.0539,  0.0264, -0.0792,  0.0029,  0.0636,  0.0325,  0.0099,  0.0877,\n",
       "                      -0.0461,  0.0870, -0.0550, -0.0725,  0.0620, -0.0624, -0.0840,  0.0728,\n",
       "                      -0.0178,  0.0085,  0.0710, -0.0571,  0.0098,  0.0067, -0.0293,  0.0360,\n",
       "                       0.0545,  0.0802, -0.0498, -0.0017, -0.0576,  0.0372, -0.0206,  0.0470,\n",
       "                      -0.0680,  0.0747, -0.0379,  0.0785,  0.0582,  0.0246,  0.0182,  0.0791,\n",
       "                      -0.0475,  0.0355, -0.0321,  0.0769, -0.0442, -0.0706,  0.0219, -0.0534,\n",
       "                       0.0332, -0.0256,  0.0068,  0.0491, -0.0460, -0.0489, -0.0010,  0.0004,\n",
       "                       0.0399,  0.0244, -0.0745,  0.0778, -0.0794, -0.0861,  0.0854, -0.0869,\n",
       "                       0.0275,  0.0175,  0.0504,  0.0802,  0.0262,  0.0326,  0.0666, -0.0288,\n",
       "                       0.0538, -0.0462, -0.0822, -0.0741, -0.0371,  0.0138,  0.0720, -0.0726,\n",
       "                      -0.0204, -0.0319,  0.0701,  0.0473, -0.0259, -0.0137, -0.0543, -0.0590,\n",
       "                      -0.0224, -0.0022,  0.0430,  0.0459, -0.0057, -0.0517, -0.0736,  0.0802,\n",
       "                       0.0016,  0.0307, -0.0726,  0.0369,  0.0086,  0.0293, -0.0631,  0.0266,\n",
       "                       0.0756, -0.0400, -0.0677,  0.0222,  0.0219, -0.0810,  0.0849,  0.0871,\n",
       "                       0.0786,  0.0677,  0.0188, -0.0381,  0.0455,  0.0669, -0.0199,  0.0242,\n",
       "                      -0.0525, -0.0482, -0.0807, -0.0281, -0.0254, -0.0309,  0.0066, -0.0651,\n",
       "                      -0.0853,  0.0098, -0.0002,  0.0734, -0.0301,  0.0474,  0.0719, -0.0261,\n",
       "                       0.0813,  0.0524, -0.0810, -0.0232,  0.0571,  0.0594,  0.0234, -0.0190,\n",
       "                       0.0786, -0.0150, -0.0417,  0.0041,  0.0346,  0.0423, -0.0375, -0.0084,\n",
       "                      -0.0011,  0.0081, -0.0489, -0.0417,  0.0713, -0.0329,  0.0840,  0.0734,\n",
       "                       0.0243, -0.0596,  0.0422,  0.0873,  0.0713, -0.0478,  0.0729, -0.0385,\n",
       "                       0.0369,  0.0576, -0.0646,  0.0783,  0.0661,  0.0543, -0.0660,  0.0761,\n",
       "                      -0.0869, -0.0433, -0.0416,  0.0550, -0.0500, -0.0358, -0.0525, -0.0020,\n",
       "                       0.0439, -0.0893,  0.0337, -0.0320,  0.0804, -0.0567, -0.0373, -0.0102,\n",
       "                       0.0241,  0.0651,  0.0328, -0.0431, -0.0355, -0.0340,  0.0846, -0.0315,\n",
       "                       0.0067,  0.0610, -0.0748,  0.0767, -0.0054, -0.0304,  0.0361, -0.0130,\n",
       "                      -0.0161, -0.0487,  0.0194,  0.0035, -0.0420, -0.0518, -0.0132,  0.0227,\n",
       "                       0.0217,  0.0558, -0.0237,  0.0265, -0.0750,  0.0060,  0.0068, -0.0120,\n",
       "                      -0.0040, -0.0019,  0.0760, -0.0774, -0.0780,  0.0156, -0.0647, -0.0545,\n",
       "                       0.0831, -0.0377,  0.0188,  0.0529,  0.0649, -0.0652,  0.0056,  0.0421,\n",
       "                      -0.0871,  0.0549, -0.0513, -0.0517,  0.0794, -0.0707,  0.0833, -0.0134,\n",
       "                      -0.0291,  0.0839,  0.0223, -0.0631, -0.0557, -0.0139,  0.0614, -0.0399,\n",
       "                       0.0437,  0.0568,  0.0463, -0.0300, -0.0525,  0.0013, -0.0715, -0.0393,\n",
       "                      -0.0740,  0.0315,  0.0550,  0.0333, -0.0708, -0.0657, -0.0064, -0.0215,\n",
       "                      -0.0347,  0.0851, -0.0041, -0.0480,  0.0265,  0.0648, -0.0179,  0.0862,\n",
       "                       0.0080,  0.0540, -0.0728,  0.0367, -0.0186, -0.0267,  0.0634,  0.0045,\n",
       "                       0.0704, -0.0081, -0.0531,  0.0061, -0.0825, -0.0429,  0.0654,  0.0715,\n",
       "                      -0.0656, -0.0683, -0.0602, -0.0528,  0.0339,  0.0696, -0.0698, -0.0030,\n",
       "                      -0.0667,  0.0291, -0.0329,  0.0086,  0.0537,  0.0734, -0.0184,  0.0323,\n",
       "                       0.0224,  0.0001, -0.0201, -0.0433,  0.0786,  0.0111, -0.0370, -0.0737,\n",
       "                      -0.0566, -0.0149,  0.0084, -0.0408,  0.0784,  0.0170,  0.0264, -0.0863])),\n",
       "             ('nodes.0.callable.block.encoder.gru.bias_hh_l0',\n",
       "              tensor([-1.7076e-02,  6.7401e-02,  1.0152e-02,  2.8210e-02, -3.4353e-02,\n",
       "                      -4.1139e-03,  2.0475e-02,  2.3030e-03,  1.2551e-02,  3.3341e-02,\n",
       "                       4.9610e-03,  3.1428e-02,  1.2842e-02, -8.2167e-02, -1.9889e-02,\n",
       "                       7.5479e-02, -7.0083e-02,  7.1306e-03,  2.5073e-02, -6.4011e-02,\n",
       "                      -8.8910e-02, -2.0452e-02,  8.5456e-02,  7.1252e-02, -2.3451e-02,\n",
       "                      -6.5630e-02, -3.8482e-02,  2.1835e-03, -3.2506e-03, -6.9543e-02,\n",
       "                      -6.0781e-02,  4.7523e-02, -5.7031e-02,  8.4489e-02,  5.3293e-02,\n",
       "                      -9.5808e-03,  4.7895e-02, -8.3598e-02, -1.4401e-02, -9.3457e-03,\n",
       "                      -5.9286e-02,  5.3603e-02, -1.7596e-02,  5.8848e-02, -6.3530e-02,\n",
       "                      -5.5558e-02,  2.1666e-02,  1.1658e-02, -2.7027e-02, -7.7851e-02,\n",
       "                      -3.4218e-02, -1.4261e-02,  8.2634e-02,  8.4497e-02, -1.8478e-02,\n",
       "                       5.8441e-02, -5.4745e-02, -2.3315e-02, -3.2446e-02, -2.3386e-02,\n",
       "                       5.2863e-03,  8.2751e-02, -8.0121e-02, -5.7617e-02,  7.9387e-02,\n",
       "                      -3.3780e-03, -5.1257e-02, -8.4640e-02,  3.0616e-02,  6.6935e-02,\n",
       "                      -2.3728e-02, -1.4051e-02,  5.9762e-02, -7.7619e-03,  1.6125e-02,\n",
       "                       6.0897e-02, -6.8429e-02,  5.9490e-02, -6.1328e-02,  2.5660e-02,\n",
       "                       7.1858e-02,  7.5454e-02,  6.5143e-02,  5.8001e-02, -5.0207e-02,\n",
       "                      -4.6205e-02,  6.6374e-02, -3.8130e-03,  3.2978e-02,  2.1753e-02,\n",
       "                      -2.9747e-02,  3.3400e-02,  8.5879e-02, -1.4274e-03,  6.5557e-02,\n",
       "                       2.6837e-02, -4.2544e-02,  5.0021e-02, -5.9606e-02, -4.8435e-02,\n",
       "                      -8.5854e-02,  2.1561e-02,  3.9811e-02, -2.2224e-02, -5.0819e-03,\n",
       "                      -6.7353e-02, -5.1928e-02, -3.0872e-02,  7.9356e-02, -4.9792e-02,\n",
       "                       1.8691e-02,  1.6816e-03,  6.8173e-03, -5.1157e-02,  1.9580e-02,\n",
       "                       8.6566e-02,  6.0541e-02,  5.9665e-02, -6.5712e-02, -2.2257e-02,\n",
       "                       7.4003e-02,  6.7570e-02,  7.0991e-02,  3.6554e-02, -7.0707e-02,\n",
       "                       4.9781e-02, -6.1105e-02,  1.0182e-02, -7.3406e-03, -4.8529e-02,\n",
       "                      -4.2670e-02, -6.4645e-02, -1.9299e-02, -4.0368e-02,  7.5597e-02,\n",
       "                       5.0544e-02,  3.4118e-03, -6.4756e-02, -8.3647e-02,  4.1932e-02,\n",
       "                      -6.9055e-05,  3.3152e-02, -5.9338e-02,  9.6309e-03,  2.4586e-02,\n",
       "                       7.8331e-02,  7.6873e-02, -4.6781e-02,  5.6231e-02,  3.7156e-02,\n",
       "                       3.3826e-02,  9.8066e-03, -3.0574e-02, -8.4843e-03,  3.1585e-02,\n",
       "                      -7.2712e-02, -4.6705e-02,  3.4838e-02,  7.1296e-02, -6.9637e-02,\n",
       "                      -7.4984e-02, -5.1263e-02,  5.1771e-02,  2.6840e-02,  2.7108e-02,\n",
       "                      -1.5212e-02, -2.3404e-03, -1.0130e-02, -5.4883e-02, -6.6280e-02,\n",
       "                      -7.1109e-02, -8.3665e-02, -6.4015e-02, -3.6134e-02, -5.2665e-03,\n",
       "                       2.9512e-02,  3.3887e-02, -8.2609e-02, -6.7419e-02,  7.6123e-02,\n",
       "                       5.1306e-02,  2.4387e-02,  4.7788e-02, -3.2191e-02, -4.2663e-02,\n",
       "                      -8.5423e-02, -8.4463e-02,  3.3028e-02,  5.5366e-02,  6.6272e-02,\n",
       "                       9.8060e-03,  4.0685e-02,  8.2699e-02,  7.7257e-02,  2.4552e-02,\n",
       "                       4.3566e-02, -3.8159e-02, -6.5580e-02, -1.3488e-02,  6.8326e-03,\n",
       "                      -2.6478e-02,  2.0459e-03,  2.1145e-02, -3.9282e-02, -3.8757e-02,\n",
       "                      -7.0918e-02,  4.7053e-02,  1.0534e-02,  1.6125e-02, -5.4271e-02,\n",
       "                      -7.4024e-02,  8.4434e-03,  3.4001e-02,  2.5344e-02,  3.8494e-02,\n",
       "                       4.1540e-02, -6.7648e-02,  3.1688e-02,  5.3015e-02,  6.9421e-02,\n",
       "                       1.7933e-03,  3.2301e-02,  7.4576e-02, -1.2000e-02, -5.3884e-02,\n",
       "                       4.5139e-02, -5.5602e-02,  4.6626e-02,  6.0342e-02,  3.9980e-02,\n",
       "                      -4.3711e-02,  6.9278e-02,  3.1962e-02,  7.7675e-02,  1.5594e-02,\n",
       "                      -7.4936e-03,  1.2607e-02, -7.7165e-02, -7.7033e-02, -2.4396e-02,\n",
       "                       3.8796e-02, -8.8335e-02,  4.5771e-02,  2.1155e-02,  7.3182e-02,\n",
       "                      -4.1378e-02, -2.3793e-02,  3.0948e-02, -5.9229e-02, -2.2886e-02,\n",
       "                      -5.7323e-02,  8.7206e-02,  7.9890e-02, -7.3565e-02, -5.4971e-02,\n",
       "                      -2.0350e-02, -2.2515e-02,  3.5662e-02, -3.6950e-02,  5.6323e-02,\n",
       "                       2.6840e-02, -5.2015e-02, -6.4417e-02,  8.5566e-02, -3.5931e-02,\n",
       "                       5.7224e-02, -4.1857e-03,  2.3283e-03,  1.3854e-02, -8.2399e-03,\n",
       "                      -2.5091e-02,  1.7816e-02, -6.1636e-02,  1.1489e-02, -6.7455e-02,\n",
       "                       1.7149e-02, -5.6683e-03, -3.0419e-02,  2.4503e-02, -1.7164e-02,\n",
       "                       8.3403e-02, -3.9566e-02,  1.6838e-02, -8.2867e-03,  7.3805e-02,\n",
       "                       2.2260e-02,  8.7286e-02,  2.4170e-02,  5.7005e-02,  4.8413e-02,\n",
       "                      -2.8693e-02, -9.1983e-03, -8.3150e-02,  4.9874e-02, -2.5684e-03,\n",
       "                       4.8081e-02, -6.8479e-03, -5.5364e-02,  1.1200e-02,  4.1874e-02,\n",
       "                      -4.6565e-02, -1.5216e-02, -5.8249e-02,  4.1983e-02, -7.0025e-02,\n",
       "                      -6.5227e-02,  3.3489e-02, -6.3215e-02,  2.5749e-02,  6.2280e-02,\n",
       "                      -3.7715e-02, -2.0497e-02, -7.6351e-02,  7.1728e-02,  8.5023e-02,\n",
       "                      -2.6862e-02,  1.5333e-02, -4.9398e-02, -9.2444e-03,  6.6579e-02,\n",
       "                      -3.3744e-02,  7.9539e-03,  7.6926e-02, -4.1158e-02, -8.6730e-02,\n",
       "                       8.2124e-02, -6.7069e-02, -5.0920e-02,  1.4141e-02, -3.0570e-02,\n",
       "                       3.9411e-02, -4.1365e-02, -4.7014e-02,  4.9509e-02, -3.0543e-02,\n",
       "                      -8.7758e-02, -4.0207e-02, -5.2235e-02, -5.6738e-02,  7.1833e-02,\n",
       "                      -8.3233e-02,  6.6506e-02, -1.6381e-02, -8.4559e-02,  3.2199e-02,\n",
       "                      -7.3835e-02, -4.6086e-02, -6.0751e-02, -6.0005e-02, -8.4721e-02,\n",
       "                       4.7796e-02,  7.0507e-02, -4.7764e-02,  7.1994e-02,  6.2525e-02,\n",
       "                       3.7674e-03, -5.2678e-02, -2.4735e-02,  7.1886e-02, -8.6004e-02,\n",
       "                      -4.3388e-02,  5.2797e-02,  8.5371e-02,  3.6057e-04,  2.5465e-02,\n",
       "                       1.6439e-03,  8.8901e-03, -7.8093e-02,  4.4569e-02,  1.6441e-02,\n",
       "                      -1.5788e-02, -7.7137e-02, -5.0320e-02, -2.8966e-02,  5.7861e-02,\n",
       "                       3.6026e-02, -4.0125e-02,  7.0745e-02, -4.0201e-02,  5.2657e-02,\n",
       "                      -5.3002e-02,  3.5410e-02,  4.3092e-02,  7.5549e-02])),\n",
       "             ('nodes.0.callable.block.encoder.lin.linear.bias',\n",
       "              tensor([ 0.0123,  0.0858, -0.0247,  0.0420, -0.0773,  0.0410, -0.0352, -0.0884,\n",
       "                       0.0105,  0.0056,  0.0530, -0.0138,  0.0171,  0.0136, -0.0430,  0.0155,\n",
       "                      -0.0663, -0.0695, -0.0229,  0.0621,  0.0506, -0.0326,  0.0432,  0.0727,\n",
       "                       0.0857, -0.0084, -0.0776, -0.0165,  0.0783,  0.0230,  0.0711,  0.0477,\n",
       "                      -0.0403, -0.0416, -0.0408, -0.0720, -0.0311, -0.0760, -0.0829, -0.0772,\n",
       "                      -0.0239,  0.0131,  0.0469,  0.0215,  0.0171,  0.0024, -0.0198, -0.0364,\n",
       "                       0.0264,  0.0199,  0.0500,  0.0173,  0.0051, -0.0141, -0.0715, -0.0708,\n",
       "                       0.0618, -0.0170,  0.0438, -0.0291,  0.0181,  0.0288, -0.0178, -0.0130])),\n",
       "             ('nodes.0.callable.block.encoder.lin.linear.weight',\n",
       "              tensor([[-2.2755e-02,  3.3667e-02, -6.8712e-02,  ...,  6.0918e-02,\n",
       "                       -5.7617e-02, -3.6808e-02],\n",
       "                      [ 3.7779e-02,  4.9682e-02,  7.7690e-02,  ..., -2.4555e-02,\n",
       "                        2.5053e-02, -2.4164e-02],\n",
       "                      [-4.7279e-02,  4.5864e-02, -8.9114e-02,  ...,  4.3154e-02,\n",
       "                       -2.1302e-03,  7.0329e-02],\n",
       "                      ...,\n",
       "                      [ 1.0221e-02,  8.5764e-02, -8.7971e-02,  ...,  4.4952e-02,\n",
       "                        7.5623e-02,  6.6570e-02],\n",
       "                      [-5.3726e-02, -6.8018e-02,  5.5072e-02,  ..., -3.0651e-02,\n",
       "                        7.4619e-02, -2.8714e-02],\n",
       "                      [ 2.9604e-02,  9.5976e-05,  3.8342e-02,  ..., -3.5891e-02,\n",
       "                        8.3801e-02, -7.1694e-03]])),\n",
       "             ('nodes.0.callable.block.encoder.lin.linear.linear.weight',\n",
       "              tensor([[-2.2755e-02,  3.3667e-02, -6.8712e-02,  ...,  6.0918e-02,\n",
       "                       -5.7617e-02, -3.6808e-02],\n",
       "                      [ 3.7779e-02,  4.9682e-02,  7.7690e-02,  ..., -2.4555e-02,\n",
       "                        2.5053e-02, -2.4164e-02],\n",
       "                      [-4.7279e-02,  4.5864e-02, -8.9114e-02,  ...,  4.3154e-02,\n",
       "                       -2.1302e-03,  7.0329e-02],\n",
       "                      ...,\n",
       "                      [ 1.0221e-02,  8.5764e-02, -8.7971e-02,  ...,  4.4952e-02,\n",
       "                        7.5623e-02,  6.6570e-02],\n",
       "                      [-5.3726e-02, -6.8018e-02,  5.5072e-02,  ..., -3.0651e-02,\n",
       "                        7.4619e-02, -2.8714e-02],\n",
       "                      [ 2.9604e-02,  9.5976e-05,  3.8342e-02,  ..., -3.5891e-02,\n",
       "                        8.3801e-02, -7.1694e-03]])),\n",
       "             ('nodes.0.callable.block.encoder.lin.linear.linear.bias',\n",
       "              tensor([ 0.0123,  0.0858, -0.0247,  0.0420, -0.0773,  0.0410, -0.0352, -0.0884,\n",
       "                       0.0105,  0.0056,  0.0530, -0.0138,  0.0171,  0.0136, -0.0430,  0.0155,\n",
       "                      -0.0663, -0.0695, -0.0229,  0.0621,  0.0506, -0.0326,  0.0432,  0.0727,\n",
       "                       0.0857, -0.0084, -0.0776, -0.0165,  0.0783,  0.0230,  0.0711,  0.0477,\n",
       "                      -0.0403, -0.0416, -0.0408, -0.0720, -0.0311, -0.0760, -0.0829, -0.0772,\n",
       "                      -0.0239,  0.0131,  0.0469,  0.0215,  0.0171,  0.0024, -0.0198, -0.0364,\n",
       "                       0.0264,  0.0199,  0.0500,  0.0173,  0.0051, -0.0141, -0.0715, -0.0708,\n",
       "                       0.0618, -0.0170,  0.0438, -0.0291,  0.0181,  0.0288, -0.0178, -0.0130])),\n",
       "             ('nodes.0.callable.block.qz0_net.linear.bias',\n",
       "              tensor([-0.0077,  0.1170,  0.0484, -0.0517,  0.0714, -0.1102,  0.0090, -0.0710])),\n",
       "             ('nodes.0.callable.block.qz0_net.linear.weight',\n",
       "              tensor([[ 9.7074e-02, -7.6364e-02, -6.7893e-02,  6.5355e-02, -2.7057e-02,\n",
       "                        9.6397e-02,  1.1522e-01,  3.5717e-02,  1.0940e-01, -1.1842e-02,\n",
       "                        7.3248e-02, -1.0088e-01,  1.9737e-03, -3.9517e-02,  1.0724e-01,\n",
       "                       -4.8328e-02,  9.0312e-02,  2.3384e-02,  3.7392e-02,  2.4099e-02,\n",
       "                       -8.2190e-02,  7.1578e-02, -2.3321e-02, -1.8711e-02, -1.6672e-02,\n",
       "                       -5.7023e-02,  7.2442e-02, -7.8673e-02, -6.9775e-02, -4.1203e-02,\n",
       "                        8.7917e-02, -1.0070e-01, -5.8566e-02,  1.6996e-02, -9.9430e-03,\n",
       "                        1.2191e-02,  1.2638e-02,  5.0374e-02, -4.3082e-02,  9.0698e-02,\n",
       "                       -7.1449e-02, -7.5418e-02,  9.3228e-03,  8.8411e-02, -6.6846e-02,\n",
       "                        6.7507e-02,  1.0762e-01, -4.9120e-02, -8.6637e-02,  2.4393e-02,\n",
       "                        4.5091e-02, -1.1365e-01, -3.2689e-03, -3.6290e-02,  2.1319e-03,\n",
       "                        8.9686e-02,  1.2445e-01, -1.1177e-02, -4.6675e-02,  1.0897e-01,\n",
       "                        6.7150e-02,  6.3090e-02,  1.1697e-01,  1.0576e-01],\n",
       "                      [-4.6599e-02, -5.7181e-02, -1.5113e-02,  6.4833e-02, -1.1662e-02,\n",
       "                       -1.0786e-01, -5.8287e-02, -5.3661e-02, -5.6311e-02, -6.1852e-02,\n",
       "                       -1.3682e-02,  7.0126e-02,  5.7087e-02,  1.1134e-01, -7.1738e-02,\n",
       "                       -1.3929e-02,  7.9333e-02, -8.0261e-02, -9.0346e-02,  5.3062e-02,\n",
       "                       -3.7195e-02, -1.2262e-01, -9.8061e-02,  4.7602e-02,  1.7464e-02,\n",
       "                       -2.2770e-02, -7.0153e-02,  6.6935e-02,  1.5726e-02,  3.2315e-02,\n",
       "                        5.1948e-02, -5.9973e-02, -1.2067e-02,  5.1105e-02, -5.3610e-02,\n",
       "                        9.8432e-02,  1.2307e-01, -2.8882e-04,  9.2795e-02, -2.7593e-02,\n",
       "                        6.1908e-02, -7.7852e-02,  1.2174e-02, -7.3081e-02,  6.1675e-02,\n",
       "                       -5.8570e-02, -3.4331e-03,  3.1134e-02, -1.0306e-02,  1.0300e-01,\n",
       "                       -6.5950e-02, -8.5694e-02, -5.9996e-03,  3.8489e-03, -1.1171e-01,\n",
       "                       -8.4108e-02,  1.1175e-01, -6.3116e-02,  8.0541e-02, -2.5617e-03,\n",
       "                        1.1765e-01, -6.2015e-02,  8.7918e-02, -6.6969e-02],\n",
       "                      [ 5.5647e-02, -4.8830e-03, -1.2424e-01,  8.9523e-02,  1.1547e-01,\n",
       "                        6.0240e-02, -4.3734e-02, -1.7635e-03,  1.3300e-02, -8.7750e-02,\n",
       "                       -8.1012e-02, -1.1096e-01, -5.6879e-02, -1.1270e-01, -4.2723e-02,\n",
       "                       -3.4803e-02, -6.7513e-02, -1.1905e-01, -4.4763e-02, -9.4563e-02,\n",
       "                        1.1362e-01,  6.6696e-02, -3.3798e-02, -1.0040e-01,  8.5296e-02,\n",
       "                        5.2555e-02,  6.0181e-02,  8.5195e-04,  1.8373e-02, -7.8636e-02,\n",
       "                       -8.9893e-02, -4.0417e-02, -8.4035e-02, -5.2340e-02,  8.5017e-02,\n",
       "                       -2.4598e-02, -1.9510e-02, -9.7953e-03,  6.1691e-03,  5.5266e-02,\n",
       "                        3.7749e-02,  1.0173e-01, -4.0993e-02,  1.2190e-01, -1.1073e-01,\n",
       "                       -4.0271e-02, -1.1861e-01,  5.6217e-02, -7.1144e-02,  7.3787e-02,\n",
       "                       -3.8982e-02, -2.1894e-02,  4.2552e-02, -5.0296e-02,  3.9303e-02,\n",
       "                       -5.0668e-02, -2.5290e-02, -6.3030e-02,  1.6237e-02, -1.8852e-02,\n",
       "                        1.1545e-01, -7.0084e-02,  7.4751e-02,  1.0895e-01],\n",
       "                      [-7.3106e-02, -2.5032e-03,  8.2974e-02, -4.3092e-02,  7.6416e-02,\n",
       "                       -1.0500e-01,  7.6680e-02, -1.7069e-03, -1.2609e-02, -6.8656e-02,\n",
       "                       -1.0449e-01,  5.3757e-02,  1.2245e-01,  1.0475e-01, -1.0048e-01,\n",
       "                        1.2195e-01, -8.5989e-02,  8.5017e-02, -2.2782e-03, -7.1929e-02,\n",
       "                        6.1106e-02,  1.4844e-02, -8.6369e-02, -4.5442e-02, -6.0321e-02,\n",
       "                        8.9332e-02,  4.6889e-02,  4.9124e-02,  6.2417e-02,  2.3151e-02,\n",
       "                       -9.0356e-02,  4.4559e-02, -5.1158e-02, -7.8951e-02,  1.2386e-01,\n",
       "                        8.2835e-02,  5.1107e-02,  1.2974e-02, -1.2797e-02, -7.7864e-02,\n",
       "                       -5.7072e-02, -6.0625e-02, -9.0349e-02, -1.0644e-01, -4.2822e-02,\n",
       "                        8.9235e-02,  9.3409e-02, -3.4665e-02,  1.1106e-01, -4.3292e-02,\n",
       "                        1.1210e-01, -1.0549e-01, -1.0772e-01, -2.5182e-03,  6.3716e-03,\n",
       "                       -1.0342e-01, -6.1865e-02,  1.6399e-02, -3.4747e-02, -7.5009e-02,\n",
       "                        2.1953e-02, -1.9671e-02,  9.5916e-02, -4.2182e-02],\n",
       "                      [-1.0102e-01, -4.4593e-02,  2.1551e-02,  8.6813e-02,  1.1709e-01,\n",
       "                       -5.9708e-02, -1.2387e-01, -1.0632e-01, -1.2301e-01, -1.1090e-01,\n",
       "                       -4.3012e-02, -9.2283e-02,  1.1899e-01,  4.7185e-02, -3.8132e-02,\n",
       "                        1.0054e-02,  1.1469e-01, -1.2689e-02,  1.9835e-02,  7.3487e-02,\n",
       "                       -1.0397e-01, -1.2022e-01,  8.8385e-02, -6.6711e-02, -4.4934e-02,\n",
       "                        1.1345e-01, -9.3664e-02,  1.1214e-01, -4.7214e-02,  7.9145e-03,\n",
       "                       -5.1149e-02,  1.2378e-01,  6.9619e-02,  9.7460e-02,  8.2310e-02,\n",
       "                        4.8359e-03,  9.8407e-02, -1.0864e-01, -3.2239e-02,  8.4041e-04,\n",
       "                       -1.1367e-01,  9.2229e-03,  9.2258e-02, -4.3338e-02, -5.6494e-02,\n",
       "                       -4.5373e-02,  1.0574e-01,  9.6865e-02, -4.8287e-02,  9.3487e-03,\n",
       "                        7.5297e-03, -4.8291e-02,  2.5582e-03, -1.1136e-01,  1.0437e-01,\n",
       "                       -2.2931e-02, -5.3483e-02, -1.0112e-01,  9.1419e-02,  4.7040e-05,\n",
       "                       -9.3880e-02, -3.2286e-02, -5.7695e-02,  3.1097e-02],\n",
       "                      [ 6.7310e-02,  5.0499e-02,  1.9342e-02, -9.8728e-02,  6.6314e-02,\n",
       "                        8.6712e-02,  2.7130e-03,  4.1766e-02,  5.8081e-02, -4.5573e-02,\n",
       "                       -7.2372e-03,  8.8449e-02, -7.2623e-02,  7.7699e-03, -1.1736e-01,\n",
       "                       -1.6288e-02, -1.1486e-02,  8.3681e-02,  1.1672e-01, -1.1920e-02,\n",
       "                       -4.7199e-02, -3.7425e-02,  8.8851e-02,  5.3748e-02,  4.4304e-02,\n",
       "                        9.8545e-02, -1.0562e-01,  1.2874e-02,  1.0851e-01,  5.1181e-03,\n",
       "                       -2.0481e-02,  1.2116e-01,  1.2340e-01, -9.7042e-02, -7.5441e-02,\n",
       "                       -8.7345e-02,  3.6274e-02,  7.8194e-03, -1.1533e-01, -6.4527e-02,\n",
       "                       -6.8662e-02, -6.0578e-02, -4.7907e-02, -1.1854e-01,  5.6140e-02,\n",
       "                        1.1280e-01,  8.5757e-02, -1.2052e-01,  9.6621e-03, -1.1886e-01,\n",
       "                        5.3878e-02,  8.7250e-02, -1.0913e-01, -6.7138e-02, -2.5752e-02,\n",
       "                        1.5618e-03,  9.5041e-02, -5.3941e-03,  5.6932e-02, -1.1699e-01,\n",
       "                       -3.2080e-02, -8.1353e-02,  8.5399e-02, -2.9181e-02],\n",
       "                      [-1.0335e-01,  6.8948e-02, -1.6781e-02, -6.0720e-02,  2.1640e-02,\n",
       "                        9.9606e-02, -8.0436e-02,  6.8554e-02, -3.8134e-02,  7.9934e-02,\n",
       "                       -3.0644e-02, -1.9736e-02,  9.4717e-02, -8.6264e-02,  7.0061e-02,\n",
       "                       -4.4354e-03,  3.2488e-02, -1.1323e-01, -2.1624e-02, -7.7926e-02,\n",
       "                        5.3927e-02,  1.9125e-03, -9.8012e-02,  9.1245e-04,  1.1035e-01,\n",
       "                       -8.8882e-02,  1.1429e-01, -5.5621e-02,  1.0610e-01,  7.5914e-02,\n",
       "                       -1.2393e-01, -4.5186e-02, -1.0928e-01,  1.1599e-01, -9.4834e-02,\n",
       "                        6.4918e-02,  5.5582e-02, -2.4132e-02,  1.3144e-02,  9.2415e-02,\n",
       "                       -1.0402e-01,  1.1187e-01,  9.6960e-02,  4.1189e-02, -3.7048e-02,\n",
       "                       -1.0751e-01, -1.0244e-02, -1.7753e-02, -3.0891e-03, -4.9175e-02,\n",
       "                       -4.0023e-02, -4.0166e-02,  1.1646e-01, -2.2334e-02,  5.7499e-02,\n",
       "                        6.2457e-02, -6.0798e-02,  3.3560e-03,  1.0232e-01,  1.1664e-01,\n",
       "                       -4.0750e-02,  2.4197e-02, -1.0012e-01,  1.0464e-01],\n",
       "                      [ 1.0748e-01, -1.1003e-01, -1.1997e-04,  4.2591e-02,  1.0522e-01,\n",
       "                       -1.2108e-01, -1.1145e-03, -7.4044e-02,  5.0145e-02,  1.1745e-01,\n",
       "                       -4.7328e-02, -3.0220e-02, -4.6303e-02,  2.6186e-02,  7.5693e-02,\n",
       "                       -8.2664e-02, -1.0395e-01, -3.7148e-02, -4.0021e-02, -9.6237e-02,\n",
       "                       -7.8287e-02,  1.1919e-02,  1.0967e-01,  7.1718e-02, -2.9401e-02,\n",
       "                        9.0338e-02,  2.2941e-02, -2.7041e-02,  1.3134e-02, -6.8345e-02,\n",
       "                       -3.9669e-02, -8.9295e-02, -1.0468e-01, -1.2354e-01,  6.3235e-02,\n",
       "                        6.2919e-02, -5.7772e-02,  4.9978e-02,  7.2864e-02, -9.3046e-02,\n",
       "                       -9.8742e-02, -9.1606e-02, -5.4596e-02,  6.1013e-02, -8.0086e-02,\n",
       "                       -4.8761e-02, -5.3456e-02, -7.7865e-04, -3.2400e-02, -3.0856e-03,\n",
       "                        8.5109e-02,  1.4742e-02,  1.6355e-02,  6.8063e-02,  1.1284e-01,\n",
       "                       -5.3367e-02,  3.0403e-03,  1.0877e-01, -1.1148e-02, -1.5289e-02,\n",
       "                       -5.3156e-02,  1.0167e-01,  6.9651e-02,  1.6043e-03]])),\n",
       "             ('nodes.0.callable.block.qz0_net.linear.linear.weight',\n",
       "              tensor([[ 9.7074e-02, -7.6364e-02, -6.7893e-02,  6.5355e-02, -2.7057e-02,\n",
       "                        9.6397e-02,  1.1522e-01,  3.5717e-02,  1.0940e-01, -1.1842e-02,\n",
       "                        7.3248e-02, -1.0088e-01,  1.9737e-03, -3.9517e-02,  1.0724e-01,\n",
       "                       -4.8328e-02,  9.0312e-02,  2.3384e-02,  3.7392e-02,  2.4099e-02,\n",
       "                       -8.2190e-02,  7.1578e-02, -2.3321e-02, -1.8711e-02, -1.6672e-02,\n",
       "                       -5.7023e-02,  7.2442e-02, -7.8673e-02, -6.9775e-02, -4.1203e-02,\n",
       "                        8.7917e-02, -1.0070e-01, -5.8566e-02,  1.6996e-02, -9.9430e-03,\n",
       "                        1.2191e-02,  1.2638e-02,  5.0374e-02, -4.3082e-02,  9.0698e-02,\n",
       "                       -7.1449e-02, -7.5418e-02,  9.3228e-03,  8.8411e-02, -6.6846e-02,\n",
       "                        6.7507e-02,  1.0762e-01, -4.9120e-02, -8.6637e-02,  2.4393e-02,\n",
       "                        4.5091e-02, -1.1365e-01, -3.2689e-03, -3.6290e-02,  2.1319e-03,\n",
       "                        8.9686e-02,  1.2445e-01, -1.1177e-02, -4.6675e-02,  1.0897e-01,\n",
       "                        6.7150e-02,  6.3090e-02,  1.1697e-01,  1.0576e-01],\n",
       "                      [-4.6599e-02, -5.7181e-02, -1.5113e-02,  6.4833e-02, -1.1662e-02,\n",
       "                       -1.0786e-01, -5.8287e-02, -5.3661e-02, -5.6311e-02, -6.1852e-02,\n",
       "                       -1.3682e-02,  7.0126e-02,  5.7087e-02,  1.1134e-01, -7.1738e-02,\n",
       "                       -1.3929e-02,  7.9333e-02, -8.0261e-02, -9.0346e-02,  5.3062e-02,\n",
       "                       -3.7195e-02, -1.2262e-01, -9.8061e-02,  4.7602e-02,  1.7464e-02,\n",
       "                       -2.2770e-02, -7.0153e-02,  6.6935e-02,  1.5726e-02,  3.2315e-02,\n",
       "                        5.1948e-02, -5.9973e-02, -1.2067e-02,  5.1105e-02, -5.3610e-02,\n",
       "                        9.8432e-02,  1.2307e-01, -2.8882e-04,  9.2795e-02, -2.7593e-02,\n",
       "                        6.1908e-02, -7.7852e-02,  1.2174e-02, -7.3081e-02,  6.1675e-02,\n",
       "                       -5.8570e-02, -3.4331e-03,  3.1134e-02, -1.0306e-02,  1.0300e-01,\n",
       "                       -6.5950e-02, -8.5694e-02, -5.9996e-03,  3.8489e-03, -1.1171e-01,\n",
       "                       -8.4108e-02,  1.1175e-01, -6.3116e-02,  8.0541e-02, -2.5617e-03,\n",
       "                        1.1765e-01, -6.2015e-02,  8.7918e-02, -6.6969e-02],\n",
       "                      [ 5.5647e-02, -4.8830e-03, -1.2424e-01,  8.9523e-02,  1.1547e-01,\n",
       "                        6.0240e-02, -4.3734e-02, -1.7635e-03,  1.3300e-02, -8.7750e-02,\n",
       "                       -8.1012e-02, -1.1096e-01, -5.6879e-02, -1.1270e-01, -4.2723e-02,\n",
       "                       -3.4803e-02, -6.7513e-02, -1.1905e-01, -4.4763e-02, -9.4563e-02,\n",
       "                        1.1362e-01,  6.6696e-02, -3.3798e-02, -1.0040e-01,  8.5296e-02,\n",
       "                        5.2555e-02,  6.0181e-02,  8.5195e-04,  1.8373e-02, -7.8636e-02,\n",
       "                       -8.9893e-02, -4.0417e-02, -8.4035e-02, -5.2340e-02,  8.5017e-02,\n",
       "                       -2.4598e-02, -1.9510e-02, -9.7953e-03,  6.1691e-03,  5.5266e-02,\n",
       "                        3.7749e-02,  1.0173e-01, -4.0993e-02,  1.2190e-01, -1.1073e-01,\n",
       "                       -4.0271e-02, -1.1861e-01,  5.6217e-02, -7.1144e-02,  7.3787e-02,\n",
       "                       -3.8982e-02, -2.1894e-02,  4.2552e-02, -5.0296e-02,  3.9303e-02,\n",
       "                       -5.0668e-02, -2.5290e-02, -6.3030e-02,  1.6237e-02, -1.8852e-02,\n",
       "                        1.1545e-01, -7.0084e-02,  7.4751e-02,  1.0895e-01],\n",
       "                      [-7.3106e-02, -2.5032e-03,  8.2974e-02, -4.3092e-02,  7.6416e-02,\n",
       "                       -1.0500e-01,  7.6680e-02, -1.7069e-03, -1.2609e-02, -6.8656e-02,\n",
       "                       -1.0449e-01,  5.3757e-02,  1.2245e-01,  1.0475e-01, -1.0048e-01,\n",
       "                        1.2195e-01, -8.5989e-02,  8.5017e-02, -2.2782e-03, -7.1929e-02,\n",
       "                        6.1106e-02,  1.4844e-02, -8.6369e-02, -4.5442e-02, -6.0321e-02,\n",
       "                        8.9332e-02,  4.6889e-02,  4.9124e-02,  6.2417e-02,  2.3151e-02,\n",
       "                       -9.0356e-02,  4.4559e-02, -5.1158e-02, -7.8951e-02,  1.2386e-01,\n",
       "                        8.2835e-02,  5.1107e-02,  1.2974e-02, -1.2797e-02, -7.7864e-02,\n",
       "                       -5.7072e-02, -6.0625e-02, -9.0349e-02, -1.0644e-01, -4.2822e-02,\n",
       "                        8.9235e-02,  9.3409e-02, -3.4665e-02,  1.1106e-01, -4.3292e-02,\n",
       "                        1.1210e-01, -1.0549e-01, -1.0772e-01, -2.5182e-03,  6.3716e-03,\n",
       "                       -1.0342e-01, -6.1865e-02,  1.6399e-02, -3.4747e-02, -7.5009e-02,\n",
       "                        2.1953e-02, -1.9671e-02,  9.5916e-02, -4.2182e-02],\n",
       "                      [-1.0102e-01, -4.4593e-02,  2.1551e-02,  8.6813e-02,  1.1709e-01,\n",
       "                       -5.9708e-02, -1.2387e-01, -1.0632e-01, -1.2301e-01, -1.1090e-01,\n",
       "                       -4.3012e-02, -9.2283e-02,  1.1899e-01,  4.7185e-02, -3.8132e-02,\n",
       "                        1.0054e-02,  1.1469e-01, -1.2689e-02,  1.9835e-02,  7.3487e-02,\n",
       "                       -1.0397e-01, -1.2022e-01,  8.8385e-02, -6.6711e-02, -4.4934e-02,\n",
       "                        1.1345e-01, -9.3664e-02,  1.1214e-01, -4.7214e-02,  7.9145e-03,\n",
       "                       -5.1149e-02,  1.2378e-01,  6.9619e-02,  9.7460e-02,  8.2310e-02,\n",
       "                        4.8359e-03,  9.8407e-02, -1.0864e-01, -3.2239e-02,  8.4041e-04,\n",
       "                       -1.1367e-01,  9.2229e-03,  9.2258e-02, -4.3338e-02, -5.6494e-02,\n",
       "                       -4.5373e-02,  1.0574e-01,  9.6865e-02, -4.8287e-02,  9.3487e-03,\n",
       "                        7.5297e-03, -4.8291e-02,  2.5582e-03, -1.1136e-01,  1.0437e-01,\n",
       "                       -2.2931e-02, -5.3483e-02, -1.0112e-01,  9.1419e-02,  4.7040e-05,\n",
       "                       -9.3880e-02, -3.2286e-02, -5.7695e-02,  3.1097e-02],\n",
       "                      [ 6.7310e-02,  5.0499e-02,  1.9342e-02, -9.8728e-02,  6.6314e-02,\n",
       "                        8.6712e-02,  2.7130e-03,  4.1766e-02,  5.8081e-02, -4.5573e-02,\n",
       "                       -7.2372e-03,  8.8449e-02, -7.2623e-02,  7.7699e-03, -1.1736e-01,\n",
       "                       -1.6288e-02, -1.1486e-02,  8.3681e-02,  1.1672e-01, -1.1920e-02,\n",
       "                       -4.7199e-02, -3.7425e-02,  8.8851e-02,  5.3748e-02,  4.4304e-02,\n",
       "                        9.8545e-02, -1.0562e-01,  1.2874e-02,  1.0851e-01,  5.1181e-03,\n",
       "                       -2.0481e-02,  1.2116e-01,  1.2340e-01, -9.7042e-02, -7.5441e-02,\n",
       "                       -8.7345e-02,  3.6274e-02,  7.8194e-03, -1.1533e-01, -6.4527e-02,\n",
       "                       -6.8662e-02, -6.0578e-02, -4.7907e-02, -1.1854e-01,  5.6140e-02,\n",
       "                        1.1280e-01,  8.5757e-02, -1.2052e-01,  9.6621e-03, -1.1886e-01,\n",
       "                        5.3878e-02,  8.7250e-02, -1.0913e-01, -6.7138e-02, -2.5752e-02,\n",
       "                        1.5618e-03,  9.5041e-02, -5.3941e-03,  5.6932e-02, -1.1699e-01,\n",
       "                       -3.2080e-02, -8.1353e-02,  8.5399e-02, -2.9181e-02],\n",
       "                      [-1.0335e-01,  6.8948e-02, -1.6781e-02, -6.0720e-02,  2.1640e-02,\n",
       "                        9.9606e-02, -8.0436e-02,  6.8554e-02, -3.8134e-02,  7.9934e-02,\n",
       "                       -3.0644e-02, -1.9736e-02,  9.4717e-02, -8.6264e-02,  7.0061e-02,\n",
       "                       -4.4354e-03,  3.2488e-02, -1.1323e-01, -2.1624e-02, -7.7926e-02,\n",
       "                        5.3927e-02,  1.9125e-03, -9.8012e-02,  9.1245e-04,  1.1035e-01,\n",
       "                       -8.8882e-02,  1.1429e-01, -5.5621e-02,  1.0610e-01,  7.5914e-02,\n",
       "                       -1.2393e-01, -4.5186e-02, -1.0928e-01,  1.1599e-01, -9.4834e-02,\n",
       "                        6.4918e-02,  5.5582e-02, -2.4132e-02,  1.3144e-02,  9.2415e-02,\n",
       "                       -1.0402e-01,  1.1187e-01,  9.6960e-02,  4.1189e-02, -3.7048e-02,\n",
       "                       -1.0751e-01, -1.0244e-02, -1.7753e-02, -3.0891e-03, -4.9175e-02,\n",
       "                       -4.0023e-02, -4.0166e-02,  1.1646e-01, -2.2334e-02,  5.7499e-02,\n",
       "                        6.2457e-02, -6.0798e-02,  3.3560e-03,  1.0232e-01,  1.1664e-01,\n",
       "                       -4.0750e-02,  2.4197e-02, -1.0012e-01,  1.0464e-01],\n",
       "                      [ 1.0748e-01, -1.1003e-01, -1.1997e-04,  4.2591e-02,  1.0522e-01,\n",
       "                       -1.2108e-01, -1.1145e-03, -7.4044e-02,  5.0145e-02,  1.1745e-01,\n",
       "                       -4.7328e-02, -3.0220e-02, -4.6303e-02,  2.6186e-02,  7.5693e-02,\n",
       "                       -8.2664e-02, -1.0395e-01, -3.7148e-02, -4.0021e-02, -9.6237e-02,\n",
       "                       -7.8287e-02,  1.1919e-02,  1.0967e-01,  7.1718e-02, -2.9401e-02,\n",
       "                        9.0338e-02,  2.2941e-02, -2.7041e-02,  1.3134e-02, -6.8345e-02,\n",
       "                       -3.9669e-02, -8.9295e-02, -1.0468e-01, -1.2354e-01,  6.3235e-02,\n",
       "                        6.2919e-02, -5.7772e-02,  4.9978e-02,  7.2864e-02, -9.3046e-02,\n",
       "                       -9.8742e-02, -9.1606e-02, -5.4596e-02,  6.1013e-02, -8.0086e-02,\n",
       "                       -4.8761e-02, -5.3456e-02, -7.7865e-04, -3.2400e-02, -3.0856e-03,\n",
       "                        8.5109e-02,  1.4742e-02,  1.6355e-02,  6.8063e-02,  1.1284e-01,\n",
       "                       -5.3367e-02,  3.0403e-03,  1.0877e-01, -1.1148e-02, -1.5289e-02,\n",
       "                       -5.3156e-02,  1.0167e-01,  6.9651e-02,  1.6043e-03]])),\n",
       "             ('nodes.0.callable.block.qz0_net.linear.linear.bias',\n",
       "              tensor([-0.0077,  0.1170,  0.0484, -0.0517,  0.0714, -0.1102,  0.0090, -0.0710])),\n",
       "             ('nodes.0.callable.block.f_net.0.linear.bias',\n",
       "              tensor([ 6.0861e-02, -6.9432e-02, -5.0520e-02, -1.0279e-01,  8.6324e-02,\n",
       "                       7.3816e-02,  1.1446e-01,  6.8708e-02,  4.6570e-02,  8.6340e-02,\n",
       "                       2.7241e-03, -4.6224e-02, -3.3362e-03,  2.1530e-02,  8.6265e-02,\n",
       "                       7.3466e-02,  1.0290e-01,  1.0431e-01,  3.2529e-02, -8.1042e-02,\n",
       "                      -6.2542e-02,  4.6455e-02, -7.5808e-02,  4.2242e-02,  5.6011e-03,\n",
       "                       2.4038e-02,  9.5810e-02,  5.5779e-02,  6.8718e-02,  3.9152e-02,\n",
       "                      -9.0528e-02, -3.4274e-02,  8.5237e-02,  4.9364e-02, -7.6385e-02,\n",
       "                       8.7403e-02,  5.8809e-02, -6.0612e-02, -7.6029e-02, -6.9348e-02,\n",
       "                       1.7057e-02,  5.6058e-02, -1.5697e-02, -6.8740e-02, -3.6846e-02,\n",
       "                       6.7971e-03,  8.7115e-02,  1.1573e-02, -6.0718e-02,  6.2203e-02,\n",
       "                       4.2553e-03,  7.4283e-02, -4.0237e-02, -9.2648e-02, -4.2449e-02,\n",
       "                       1.9217e-02,  3.7640e-02,  8.0687e-02,  2.8618e-02,  1.1419e-01,\n",
       "                      -1.3072e-03,  5.3656e-02, -1.1291e-01, -5.8960e-02,  6.1492e-02,\n",
       "                      -8.4940e-03, -9.3673e-02, -9.2293e-03,  1.1758e-01, -1.1924e-01,\n",
       "                      -2.0497e-02,  6.3254e-02,  4.9519e-02, -1.1838e-01, -8.9445e-02,\n",
       "                       8.0139e-02,  1.2155e-01, -5.1847e-02,  9.5291e-02, -1.8284e-02,\n",
       "                      -6.7082e-02,  3.5278e-02,  6.1808e-02,  8.0305e-02,  6.5184e-02,\n",
       "                       2.7918e-02, -1.0819e-01, -1.9628e-02,  2.2792e-02,  2.6962e-02,\n",
       "                       1.7128e-02,  5.2220e-02, -1.0035e-01,  4.2016e-02,  6.6467e-02,\n",
       "                       6.0720e-02,  9.2320e-05,  1.7740e-02,  7.8532e-02,  1.1926e-01,\n",
       "                      -2.8272e-02, -7.6175e-02, -3.9618e-02, -9.5662e-03,  4.6508e-02,\n",
       "                       9.4015e-02,  6.7205e-02, -4.3296e-02, -4.4637e-02,  2.5132e-02,\n",
       "                      -5.5414e-02,  2.6658e-02, -2.4947e-02,  1.0745e-02, -6.7545e-03,\n",
       "                      -2.1445e-02,  1.1064e-01, -7.3801e-02,  6.6988e-02, -1.1870e-01,\n",
       "                       3.1011e-02,  1.0889e-01,  9.0125e-03, -1.2188e-01, -1.1321e-01,\n",
       "                       4.2419e-02, -1.1739e-01, -1.1480e-03])),\n",
       "             ('nodes.0.callable.block.f_net.0.linear.weight',\n",
       "              tensor([[ 0.1055,  0.0574,  0.0895,  ..., -0.1190, -0.0265, -0.0929],\n",
       "                      [-0.0103,  0.0904,  0.1153,  ..., -0.0421, -0.1002, -0.0121],\n",
       "                      [ 0.0645,  0.0941,  0.0338,  ...,  0.1176, -0.0060,  0.0866],\n",
       "                      ...,\n",
       "                      [-0.0427,  0.0513,  0.0723,  ...,  0.0142,  0.0943, -0.0022],\n",
       "                      [ 0.0500,  0.0283, -0.0870,  ...,  0.0849, -0.0356, -0.0336],\n",
       "                      [-0.0251, -0.0756,  0.0360,  ...,  0.0468, -0.1193, -0.0068]])),\n",
       "             ('nodes.0.callable.block.f_net.0.linear.linear.weight',\n",
       "              tensor([[ 0.1055,  0.0574,  0.0895,  ..., -0.1190, -0.0265, -0.0929],\n",
       "                      [-0.0103,  0.0904,  0.1153,  ..., -0.0421, -0.1002, -0.0121],\n",
       "                      [ 0.0645,  0.0941,  0.0338,  ...,  0.1176, -0.0060,  0.0866],\n",
       "                      ...,\n",
       "                      [-0.0427,  0.0513,  0.0723,  ...,  0.0142,  0.0943, -0.0022],\n",
       "                      [ 0.0500,  0.0283, -0.0870,  ...,  0.0849, -0.0356, -0.0336],\n",
       "                      [-0.0251, -0.0756,  0.0360,  ...,  0.0468, -0.1193, -0.0068]])),\n",
       "             ('nodes.0.callable.block.f_net.0.linear.linear.bias',\n",
       "              tensor([ 6.0861e-02, -6.9432e-02, -5.0520e-02, -1.0279e-01,  8.6324e-02,\n",
       "                       7.3816e-02,  1.1446e-01,  6.8708e-02,  4.6570e-02,  8.6340e-02,\n",
       "                       2.7241e-03, -4.6224e-02, -3.3362e-03,  2.1530e-02,  8.6265e-02,\n",
       "                       7.3466e-02,  1.0290e-01,  1.0431e-01,  3.2529e-02, -8.1042e-02,\n",
       "                      -6.2542e-02,  4.6455e-02, -7.5808e-02,  4.2242e-02,  5.6011e-03,\n",
       "                       2.4038e-02,  9.5810e-02,  5.5779e-02,  6.8718e-02,  3.9152e-02,\n",
       "                      -9.0528e-02, -3.4274e-02,  8.5237e-02,  4.9364e-02, -7.6385e-02,\n",
       "                       8.7403e-02,  5.8809e-02, -6.0612e-02, -7.6029e-02, -6.9348e-02,\n",
       "                       1.7057e-02,  5.6058e-02, -1.5697e-02, -6.8740e-02, -3.6846e-02,\n",
       "                       6.7971e-03,  8.7115e-02,  1.1573e-02, -6.0718e-02,  6.2203e-02,\n",
       "                       4.2553e-03,  7.4283e-02, -4.0237e-02, -9.2648e-02, -4.2449e-02,\n",
       "                       1.9217e-02,  3.7640e-02,  8.0687e-02,  2.8618e-02,  1.1419e-01,\n",
       "                      -1.3072e-03,  5.3656e-02, -1.1291e-01, -5.8960e-02,  6.1492e-02,\n",
       "                      -8.4940e-03, -9.3673e-02, -9.2293e-03,  1.1758e-01, -1.1924e-01,\n",
       "                      -2.0497e-02,  6.3254e-02,  4.9519e-02, -1.1838e-01, -8.9445e-02,\n",
       "                       8.0139e-02,  1.2155e-01, -5.1847e-02,  9.5291e-02, -1.8284e-02,\n",
       "                      -6.7082e-02,  3.5278e-02,  6.1808e-02,  8.0305e-02,  6.5184e-02,\n",
       "                       2.7918e-02, -1.0819e-01, -1.9628e-02,  2.2792e-02,  2.6962e-02,\n",
       "                       1.7128e-02,  5.2220e-02, -1.0035e-01,  4.2016e-02,  6.6467e-02,\n",
       "                       6.0720e-02,  9.2320e-05,  1.7740e-02,  7.8532e-02,  1.1926e-01,\n",
       "                      -2.8272e-02, -7.6175e-02, -3.9618e-02, -9.5662e-03,  4.6508e-02,\n",
       "                       9.4015e-02,  6.7205e-02, -4.3296e-02, -4.4637e-02,  2.5132e-02,\n",
       "                      -5.5414e-02,  2.6658e-02, -2.4947e-02,  1.0745e-02, -6.7545e-03,\n",
       "                      -2.1445e-02,  1.1064e-01, -7.3801e-02,  6.6988e-02, -1.1870e-01,\n",
       "                       3.1011e-02,  1.0889e-01,  9.0125e-03, -1.2188e-01, -1.1321e-01,\n",
       "                       4.2419e-02, -1.1739e-01, -1.1480e-03])),\n",
       "             ('nodes.0.callable.block.f_net.2.linear.bias',\n",
       "              tensor([ 0.0610,  0.0595, -0.0308,  0.0610,  0.0597, -0.0825, -0.0640, -0.0106,\n",
       "                       0.0063, -0.0605,  0.0033,  0.0653,  0.0449, -0.0422,  0.0145,  0.0121,\n",
       "                      -0.0044,  0.0287,  0.0739, -0.0359, -0.0283, -0.0053, -0.0145, -0.0089,\n",
       "                       0.0057, -0.0675,  0.0217, -0.0364,  0.0752,  0.0715, -0.0627,  0.0184,\n",
       "                       0.0055,  0.0449, -0.0536,  0.0164,  0.0412,  0.0773, -0.0425,  0.0539,\n",
       "                      -0.0257,  0.0685, -0.0446, -0.0536,  0.0419,  0.0288,  0.0494,  0.0720,\n",
       "                       0.0173, -0.0795,  0.0059, -0.0333,  0.0298,  0.0765, -0.0306, -0.0599,\n",
       "                       0.0102, -0.0683, -0.0784,  0.0621,  0.0447, -0.0682,  0.0512, -0.0311,\n",
       "                      -0.0638, -0.0457,  0.0157,  0.0772, -0.0242,  0.0777,  0.0864,  0.0784,\n",
       "                      -0.0583,  0.0684, -0.0434,  0.0113, -0.0212, -0.0025,  0.0132,  0.0058,\n",
       "                       0.0075,  0.0663, -0.0731, -0.0437, -0.0701,  0.0082, -0.0383, -0.0075,\n",
       "                      -0.0113, -0.0401, -0.0427, -0.0184, -0.0674,  0.0582,  0.0144, -0.0439,\n",
       "                       0.0440,  0.0599,  0.0520, -0.0339, -0.0098,  0.0694, -0.0360, -0.0128,\n",
       "                       0.0849,  0.0579, -0.0243,  0.0719, -0.0278,  0.0192,  0.0612,  0.0596,\n",
       "                       0.0396, -0.0081,  0.0173, -0.0417,  0.0820,  0.0002, -0.0747, -0.0479,\n",
       "                      -0.0410,  0.0782,  0.0774, -0.0735,  0.0842, -0.0072, -0.0704, -0.0045])),\n",
       "             ('nodes.0.callable.block.f_net.2.linear.weight',\n",
       "              tensor([[-0.0384, -0.0660, -0.0158,  ..., -0.0103,  0.0128, -0.0018],\n",
       "                      [-0.0812, -0.0338,  0.0795,  ..., -0.0030, -0.0442, -0.0075],\n",
       "                      [-0.0244,  0.0038,  0.0246,  ...,  0.0497,  0.0632,  0.0740],\n",
       "                      ...,\n",
       "                      [ 0.0824, -0.0298,  0.0118,  ..., -0.0632,  0.0730,  0.0103],\n",
       "                      [-0.0775, -0.0112, -0.0452,  ...,  0.0177,  0.0273, -0.0370],\n",
       "                      [-0.0050,  0.0293, -0.0237,  ...,  0.0593,  0.0570,  0.0413]])),\n",
       "             ('nodes.0.callable.block.f_net.2.linear.linear.weight',\n",
       "              tensor([[-0.0384, -0.0660, -0.0158,  ..., -0.0103,  0.0128, -0.0018],\n",
       "                      [-0.0812, -0.0338,  0.0795,  ..., -0.0030, -0.0442, -0.0075],\n",
       "                      [-0.0244,  0.0038,  0.0246,  ...,  0.0497,  0.0632,  0.0740],\n",
       "                      ...,\n",
       "                      [ 0.0824, -0.0298,  0.0118,  ..., -0.0632,  0.0730,  0.0103],\n",
       "                      [-0.0775, -0.0112, -0.0452,  ...,  0.0177,  0.0273, -0.0370],\n",
       "                      [-0.0050,  0.0293, -0.0237,  ...,  0.0593,  0.0570,  0.0413]])),\n",
       "             ('nodes.0.callable.block.f_net.2.linear.linear.bias',\n",
       "              tensor([ 0.0610,  0.0595, -0.0308,  0.0610,  0.0597, -0.0825, -0.0640, -0.0106,\n",
       "                       0.0063, -0.0605,  0.0033,  0.0653,  0.0449, -0.0422,  0.0145,  0.0121,\n",
       "                      -0.0044,  0.0287,  0.0739, -0.0359, -0.0283, -0.0053, -0.0145, -0.0089,\n",
       "                       0.0057, -0.0675,  0.0217, -0.0364,  0.0752,  0.0715, -0.0627,  0.0184,\n",
       "                       0.0055,  0.0449, -0.0536,  0.0164,  0.0412,  0.0773, -0.0425,  0.0539,\n",
       "                      -0.0257,  0.0685, -0.0446, -0.0536,  0.0419,  0.0288,  0.0494,  0.0720,\n",
       "                       0.0173, -0.0795,  0.0059, -0.0333,  0.0298,  0.0765, -0.0306, -0.0599,\n",
       "                       0.0102, -0.0683, -0.0784,  0.0621,  0.0447, -0.0682,  0.0512, -0.0311,\n",
       "                      -0.0638, -0.0457,  0.0157,  0.0772, -0.0242,  0.0777,  0.0864,  0.0784,\n",
       "                      -0.0583,  0.0684, -0.0434,  0.0113, -0.0212, -0.0025,  0.0132,  0.0058,\n",
       "                       0.0075,  0.0663, -0.0731, -0.0437, -0.0701,  0.0082, -0.0383, -0.0075,\n",
       "                      -0.0113, -0.0401, -0.0427, -0.0184, -0.0674,  0.0582,  0.0144, -0.0439,\n",
       "                       0.0440,  0.0599,  0.0520, -0.0339, -0.0098,  0.0694, -0.0360, -0.0128,\n",
       "                       0.0849,  0.0579, -0.0243,  0.0719, -0.0278,  0.0192,  0.0612,  0.0596,\n",
       "                       0.0396, -0.0081,  0.0173, -0.0417,  0.0820,  0.0002, -0.0747, -0.0479,\n",
       "                      -0.0410,  0.0782,  0.0774, -0.0735,  0.0842, -0.0072, -0.0704, -0.0045])),\n",
       "             ('nodes.0.callable.block.f_net.4.linear.bias',\n",
       "              tensor([ 0.0206, -0.0653, -0.0539,  0.0803])),\n",
       "             ('nodes.0.callable.block.f_net.4.linear.weight',\n",
       "              tensor([[ 0.0521, -0.0677,  0.0625,  0.0414, -0.0354,  0.0845,  0.0851, -0.0080,\n",
       "                        0.0256, -0.0176,  0.0510,  0.0677,  0.0491, -0.0255,  0.0669, -0.0044,\n",
       "                       -0.0482,  0.0240, -0.0140,  0.0160,  0.0705, -0.0219, -0.0216,  0.0640,\n",
       "                       -0.0883, -0.0645, -0.0450,  0.0782,  0.0447,  0.0025,  0.0165,  0.0151,\n",
       "                        0.0584, -0.0535, -0.0112, -0.0085, -0.0064,  0.0121, -0.0553, -0.0174,\n",
       "                        0.0773,  0.0209,  0.0156,  0.0417,  0.0208,  0.0494,  0.0078,  0.0047,\n",
       "                       -0.0883, -0.0260, -0.0429,  0.0787,  0.0346, -0.0317, -0.0499, -0.0084,\n",
       "                        0.0519,  0.0153,  0.0189,  0.0340,  0.0225, -0.0610,  0.0572,  0.0383,\n",
       "                        0.0183,  0.0189,  0.0171,  0.0819, -0.0874, -0.0450, -0.0680,  0.0712,\n",
       "                        0.0409, -0.0152, -0.0009,  0.0067, -0.0834,  0.0861,  0.0193, -0.0511,\n",
       "                        0.0620,  0.0802, -0.0491,  0.0160,  0.0815,  0.0678,  0.0697,  0.0660,\n",
       "                        0.0388, -0.0517,  0.0761,  0.0306,  0.0503,  0.0232,  0.0750, -0.0018,\n",
       "                        0.0343, -0.0550,  0.0553,  0.0083, -0.0171, -0.0336, -0.0545,  0.0135,\n",
       "                        0.0481,  0.0041,  0.0505, -0.0304, -0.0622,  0.0636, -0.0269, -0.0105,\n",
       "                       -0.0419,  0.0038,  0.0108, -0.0208,  0.0072,  0.0175, -0.0176, -0.0073,\n",
       "                        0.0236, -0.0570, -0.0476, -0.0164,  0.0659, -0.0290, -0.0787,  0.0357],\n",
       "                      [ 0.0689,  0.0785,  0.0692, -0.0666,  0.0030,  0.0856,  0.0147, -0.0398,\n",
       "                        0.0629,  0.0266,  0.0446,  0.0332, -0.0037, -0.0061,  0.0025, -0.0627,\n",
       "                       -0.0145, -0.0141, -0.0672,  0.0662, -0.0067,  0.0795, -0.0678, -0.0091,\n",
       "                       -0.0193, -0.0611,  0.0633, -0.0437,  0.0581, -0.0288, -0.0223, -0.0866,\n",
       "                        0.0214,  0.0291,  0.0384,  0.0428, -0.0710, -0.0271, -0.0189, -0.0134,\n",
       "                        0.0552,  0.0866, -0.0085,  0.0085,  0.0472, -0.0216, -0.0742,  0.0654,\n",
       "                        0.0631,  0.0186,  0.0471, -0.0752, -0.0546,  0.0738,  0.0678, -0.0273,\n",
       "                       -0.0195, -0.0585, -0.0788, -0.0138, -0.0170, -0.0536, -0.0892,  0.0335,\n",
       "                        0.0627, -0.0581, -0.0344,  0.0013, -0.0592,  0.0281, -0.0530,  0.0036,\n",
       "                        0.0332,  0.0188,  0.0347,  0.0288,  0.0438,  0.0081, -0.0821,  0.0563,\n",
       "                        0.0231,  0.0151, -0.0175,  0.0364,  0.0719, -0.0690, -0.0765,  0.0579,\n",
       "                       -0.0261,  0.0849, -0.0646, -0.0086,  0.0332, -0.0070,  0.0511,  0.0326,\n",
       "                       -0.0430,  0.0737,  0.0818, -0.0015, -0.0656, -0.0776, -0.0787, -0.0203,\n",
       "                       -0.0843,  0.0445, -0.0814, -0.0816,  0.0218,  0.0046,  0.0809,  0.0252,\n",
       "                        0.0708,  0.0371, -0.0070, -0.0335,  0.0363, -0.0130, -0.0412, -0.0515,\n",
       "                       -0.0577, -0.0279,  0.0016,  0.0390, -0.0363, -0.0410, -0.0555,  0.0458],\n",
       "                      [-0.0409,  0.0524, -0.0830, -0.0683, -0.0577, -0.0328,  0.0686, -0.0104,\n",
       "                        0.0761,  0.0470,  0.0747,  0.0787, -0.0171,  0.0003,  0.0021,  0.0747,\n",
       "                       -0.0284, -0.0231, -0.0228, -0.0276,  0.0124,  0.0526,  0.0099,  0.0111,\n",
       "                       -0.0295, -0.0692, -0.0106,  0.0752,  0.0737, -0.0226,  0.0033, -0.0781,\n",
       "                       -0.0142, -0.0294,  0.0649, -0.0111,  0.0289, -0.0258,  0.0474, -0.0191,\n",
       "                       -0.0324,  0.0648, -0.0070, -0.0376, -0.0509,  0.0452, -0.0346, -0.0311,\n",
       "                        0.0756, -0.0710, -0.0722,  0.0873,  0.0112,  0.0413,  0.0658,  0.0090,\n",
       "                       -0.0512,  0.0872,  0.0622,  0.0683,  0.0368,  0.0055,  0.0573, -0.0647,\n",
       "                       -0.0752, -0.0502, -0.0830,  0.0155, -0.0015,  0.0733,  0.0375,  0.0848,\n",
       "                        0.0329,  0.0787,  0.0488, -0.0196,  0.0556, -0.0509,  0.0836, -0.0764,\n",
       "                        0.0616,  0.0656,  0.0353, -0.0266, -0.0160,  0.0508, -0.0092, -0.0747,\n",
       "                       -0.0837,  0.0295, -0.0024, -0.0273, -0.0330, -0.0058,  0.0070,  0.0452,\n",
       "                        0.0483,  0.0077, -0.0624,  0.0473, -0.0088, -0.0844,  0.0403, -0.0599,\n",
       "                       -0.0440, -0.0319,  0.0376, -0.0570,  0.0655,  0.0412, -0.0443, -0.0321,\n",
       "                        0.0837,  0.0796,  0.0729, -0.0205, -0.0860,  0.0446,  0.0275, -0.0734,\n",
       "                       -0.0305,  0.0396,  0.0604, -0.0856,  0.0009, -0.0750,  0.0420,  0.0259],\n",
       "                      [ 0.0881,  0.0702, -0.0503,  0.0182, -0.0357, -0.0262, -0.0313, -0.0156,\n",
       "                        0.0029,  0.0295,  0.0438, -0.0577, -0.0160,  0.0118, -0.0394,  0.0708,\n",
       "                        0.0358, -0.0786,  0.0624,  0.0418, -0.0313,  0.0817, -0.0316, -0.0148,\n",
       "                        0.0238, -0.0727, -0.0265, -0.0593,  0.0073,  0.0404, -0.0213,  0.0845,\n",
       "                       -0.0372, -0.0080,  0.0134, -0.0496, -0.0473,  0.0560,  0.0755, -0.0677,\n",
       "                        0.0608,  0.0530,  0.0379, -0.0823, -0.0078,  0.0522, -0.0573, -0.0486,\n",
       "                       -0.0046, -0.0368,  0.0039, -0.0849, -0.0050, -0.0387, -0.0845,  0.0031,\n",
       "                       -0.0244, -0.0532, -0.0281, -0.0391,  0.0057,  0.0344, -0.0604,  0.0757,\n",
       "                        0.0548, -0.0672, -0.0540,  0.0299,  0.0262,  0.0790, -0.0160, -0.0800,\n",
       "                       -0.0481,  0.0579, -0.0654,  0.0267, -0.0512,  0.0063,  0.0471, -0.0562,\n",
       "                        0.0828,  0.0469, -0.0091, -0.0594,  0.0345, -0.0179,  0.0296,  0.0284,\n",
       "                        0.0644,  0.0640,  0.0865,  0.0527,  0.0524,  0.0006, -0.0547, -0.0865,\n",
       "                       -0.0724, -0.0604,  0.0377, -0.0450,  0.0685,  0.0436, -0.0377, -0.0433,\n",
       "                       -0.0539, -0.0032,  0.0323, -0.0572, -0.0281,  0.0059, -0.0378,  0.0336,\n",
       "                        0.0286, -0.0536, -0.0731, -0.0451,  0.0708,  0.0014, -0.0533, -0.0471,\n",
       "                        0.0866, -0.0160, -0.0644, -0.0150, -0.0156,  0.0208, -0.0273,  0.0159]])),\n",
       "             ('nodes.0.callable.block.f_net.4.linear.linear.weight',\n",
       "              tensor([[ 0.0521, -0.0677,  0.0625,  0.0414, -0.0354,  0.0845,  0.0851, -0.0080,\n",
       "                        0.0256, -0.0176,  0.0510,  0.0677,  0.0491, -0.0255,  0.0669, -0.0044,\n",
       "                       -0.0482,  0.0240, -0.0140,  0.0160,  0.0705, -0.0219, -0.0216,  0.0640,\n",
       "                       -0.0883, -0.0645, -0.0450,  0.0782,  0.0447,  0.0025,  0.0165,  0.0151,\n",
       "                        0.0584, -0.0535, -0.0112, -0.0085, -0.0064,  0.0121, -0.0553, -0.0174,\n",
       "                        0.0773,  0.0209,  0.0156,  0.0417,  0.0208,  0.0494,  0.0078,  0.0047,\n",
       "                       -0.0883, -0.0260, -0.0429,  0.0787,  0.0346, -0.0317, -0.0499, -0.0084,\n",
       "                        0.0519,  0.0153,  0.0189,  0.0340,  0.0225, -0.0610,  0.0572,  0.0383,\n",
       "                        0.0183,  0.0189,  0.0171,  0.0819, -0.0874, -0.0450, -0.0680,  0.0712,\n",
       "                        0.0409, -0.0152, -0.0009,  0.0067, -0.0834,  0.0861,  0.0193, -0.0511,\n",
       "                        0.0620,  0.0802, -0.0491,  0.0160,  0.0815,  0.0678,  0.0697,  0.0660,\n",
       "                        0.0388, -0.0517,  0.0761,  0.0306,  0.0503,  0.0232,  0.0750, -0.0018,\n",
       "                        0.0343, -0.0550,  0.0553,  0.0083, -0.0171, -0.0336, -0.0545,  0.0135,\n",
       "                        0.0481,  0.0041,  0.0505, -0.0304, -0.0622,  0.0636, -0.0269, -0.0105,\n",
       "                       -0.0419,  0.0038,  0.0108, -0.0208,  0.0072,  0.0175, -0.0176, -0.0073,\n",
       "                        0.0236, -0.0570, -0.0476, -0.0164,  0.0659, -0.0290, -0.0787,  0.0357],\n",
       "                      [ 0.0689,  0.0785,  0.0692, -0.0666,  0.0030,  0.0856,  0.0147, -0.0398,\n",
       "                        0.0629,  0.0266,  0.0446,  0.0332, -0.0037, -0.0061,  0.0025, -0.0627,\n",
       "                       -0.0145, -0.0141, -0.0672,  0.0662, -0.0067,  0.0795, -0.0678, -0.0091,\n",
       "                       -0.0193, -0.0611,  0.0633, -0.0437,  0.0581, -0.0288, -0.0223, -0.0866,\n",
       "                        0.0214,  0.0291,  0.0384,  0.0428, -0.0710, -0.0271, -0.0189, -0.0134,\n",
       "                        0.0552,  0.0866, -0.0085,  0.0085,  0.0472, -0.0216, -0.0742,  0.0654,\n",
       "                        0.0631,  0.0186,  0.0471, -0.0752, -0.0546,  0.0738,  0.0678, -0.0273,\n",
       "                       -0.0195, -0.0585, -0.0788, -0.0138, -0.0170, -0.0536, -0.0892,  0.0335,\n",
       "                        0.0627, -0.0581, -0.0344,  0.0013, -0.0592,  0.0281, -0.0530,  0.0036,\n",
       "                        0.0332,  0.0188,  0.0347,  0.0288,  0.0438,  0.0081, -0.0821,  0.0563,\n",
       "                        0.0231,  0.0151, -0.0175,  0.0364,  0.0719, -0.0690, -0.0765,  0.0579,\n",
       "                       -0.0261,  0.0849, -0.0646, -0.0086,  0.0332, -0.0070,  0.0511,  0.0326,\n",
       "                       -0.0430,  0.0737,  0.0818, -0.0015, -0.0656, -0.0776, -0.0787, -0.0203,\n",
       "                       -0.0843,  0.0445, -0.0814, -0.0816,  0.0218,  0.0046,  0.0809,  0.0252,\n",
       "                        0.0708,  0.0371, -0.0070, -0.0335,  0.0363, -0.0130, -0.0412, -0.0515,\n",
       "                       -0.0577, -0.0279,  0.0016,  0.0390, -0.0363, -0.0410, -0.0555,  0.0458],\n",
       "                      [-0.0409,  0.0524, -0.0830, -0.0683, -0.0577, -0.0328,  0.0686, -0.0104,\n",
       "                        0.0761,  0.0470,  0.0747,  0.0787, -0.0171,  0.0003,  0.0021,  0.0747,\n",
       "                       -0.0284, -0.0231, -0.0228, -0.0276,  0.0124,  0.0526,  0.0099,  0.0111,\n",
       "                       -0.0295, -0.0692, -0.0106,  0.0752,  0.0737, -0.0226,  0.0033, -0.0781,\n",
       "                       -0.0142, -0.0294,  0.0649, -0.0111,  0.0289, -0.0258,  0.0474, -0.0191,\n",
       "                       -0.0324,  0.0648, -0.0070, -0.0376, -0.0509,  0.0452, -0.0346, -0.0311,\n",
       "                        0.0756, -0.0710, -0.0722,  0.0873,  0.0112,  0.0413,  0.0658,  0.0090,\n",
       "                       -0.0512,  0.0872,  0.0622,  0.0683,  0.0368,  0.0055,  0.0573, -0.0647,\n",
       "                       -0.0752, -0.0502, -0.0830,  0.0155, -0.0015,  0.0733,  0.0375,  0.0848,\n",
       "                        0.0329,  0.0787,  0.0488, -0.0196,  0.0556, -0.0509,  0.0836, -0.0764,\n",
       "                        0.0616,  0.0656,  0.0353, -0.0266, -0.0160,  0.0508, -0.0092, -0.0747,\n",
       "                       -0.0837,  0.0295, -0.0024, -0.0273, -0.0330, -0.0058,  0.0070,  0.0452,\n",
       "                        0.0483,  0.0077, -0.0624,  0.0473, -0.0088, -0.0844,  0.0403, -0.0599,\n",
       "                       -0.0440, -0.0319,  0.0376, -0.0570,  0.0655,  0.0412, -0.0443, -0.0321,\n",
       "                        0.0837,  0.0796,  0.0729, -0.0205, -0.0860,  0.0446,  0.0275, -0.0734,\n",
       "                       -0.0305,  0.0396,  0.0604, -0.0856,  0.0009, -0.0750,  0.0420,  0.0259],\n",
       "                      [ 0.0881,  0.0702, -0.0503,  0.0182, -0.0357, -0.0262, -0.0313, -0.0156,\n",
       "                        0.0029,  0.0295,  0.0438, -0.0577, -0.0160,  0.0118, -0.0394,  0.0708,\n",
       "                        0.0358, -0.0786,  0.0624,  0.0418, -0.0313,  0.0817, -0.0316, -0.0148,\n",
       "                        0.0238, -0.0727, -0.0265, -0.0593,  0.0073,  0.0404, -0.0213,  0.0845,\n",
       "                       -0.0372, -0.0080,  0.0134, -0.0496, -0.0473,  0.0560,  0.0755, -0.0677,\n",
       "                        0.0608,  0.0530,  0.0379, -0.0823, -0.0078,  0.0522, -0.0573, -0.0486,\n",
       "                       -0.0046, -0.0368,  0.0039, -0.0849, -0.0050, -0.0387, -0.0845,  0.0031,\n",
       "                       -0.0244, -0.0532, -0.0281, -0.0391,  0.0057,  0.0344, -0.0604,  0.0757,\n",
       "                        0.0548, -0.0672, -0.0540,  0.0299,  0.0262,  0.0790, -0.0160, -0.0800,\n",
       "                       -0.0481,  0.0579, -0.0654,  0.0267, -0.0512,  0.0063,  0.0471, -0.0562,\n",
       "                        0.0828,  0.0469, -0.0091, -0.0594,  0.0345, -0.0179,  0.0296,  0.0284,\n",
       "                        0.0644,  0.0640,  0.0865,  0.0527,  0.0524,  0.0006, -0.0547, -0.0865,\n",
       "                       -0.0724, -0.0604,  0.0377, -0.0450,  0.0685,  0.0436, -0.0377, -0.0433,\n",
       "                       -0.0539, -0.0032,  0.0323, -0.0572, -0.0281,  0.0059, -0.0378,  0.0336,\n",
       "                        0.0286, -0.0536, -0.0731, -0.0451,  0.0708,  0.0014, -0.0533, -0.0471,\n",
       "                        0.0866, -0.0160, -0.0644, -0.0150, -0.0156,  0.0208, -0.0273,  0.0159]])),\n",
       "             ('nodes.0.callable.block.f_net.4.linear.linear.bias',\n",
       "              tensor([ 0.0206, -0.0653, -0.0539,  0.0803])),\n",
       "             ('nodes.0.callable.block.h_net.0.linear.bias',\n",
       "              tensor([-0.4392,  0.2894, -0.1628,  0.0036,  0.0647,  0.4573,  0.3764,  0.4140,\n",
       "                       0.3550,  0.1038, -0.4476, -0.4009,  0.0378, -0.4800,  0.0207, -0.0585,\n",
       "                       0.3657, -0.4031, -0.4888, -0.2905,  0.4373,  0.1989, -0.2258,  0.4604,\n",
       "                      -0.3161,  0.2947, -0.1008, -0.2852, -0.1818, -0.1367, -0.1980,  0.4229,\n",
       "                       0.3302, -0.3799, -0.1056,  0.0361, -0.1262, -0.1321, -0.4896, -0.3021,\n",
       "                       0.1617, -0.0551,  0.3279, -0.3791, -0.3732,  0.4825,  0.1107, -0.0760,\n",
       "                       0.1572,  0.1019, -0.0570, -0.4397, -0.2143,  0.0468,  0.0712,  0.1483,\n",
       "                       0.4340,  0.1990, -0.1331,  0.2578,  0.1986, -0.0927,  0.1046, -0.4865,\n",
       "                       0.3057, -0.1731,  0.1649,  0.1033, -0.2758,  0.4657,  0.4410,  0.2468,\n",
       "                      -0.4887, -0.1700, -0.2237,  0.1621,  0.3126,  0.1308,  0.2842,  0.4615,\n",
       "                      -0.2613, -0.2849, -0.2243, -0.3132,  0.4930,  0.4575, -0.3948, -0.0464,\n",
       "                      -0.3947, -0.1023,  0.4605, -0.0159, -0.4991, -0.1414, -0.3768,  0.3419,\n",
       "                      -0.1562, -0.2972, -0.3772,  0.1504,  0.3635, -0.4196,  0.4091, -0.3736,\n",
       "                      -0.2731,  0.1593, -0.0327, -0.0577,  0.4574,  0.0613,  0.3243,  0.2813,\n",
       "                       0.0547, -0.0078, -0.2194, -0.2882, -0.0247,  0.2890, -0.1983, -0.4787,\n",
       "                       0.3641,  0.1564,  0.4707,  0.4635, -0.1911,  0.0765, -0.1351,  0.3277])),\n",
       "             ('nodes.0.callable.block.h_net.0.linear.weight',\n",
       "              tensor([[ 0.1340, -0.1787,  0.0454, -0.2385],\n",
       "                      [-0.2164,  0.0197,  0.0254, -0.2206],\n",
       "                      [ 0.4527,  0.2198, -0.4125, -0.4141],\n",
       "                      [ 0.3356, -0.2354,  0.2027,  0.3275],\n",
       "                      [-0.4769, -0.0482,  0.0386, -0.0936],\n",
       "                      [ 0.4239,  0.4917, -0.0665, -0.0935],\n",
       "                      [-0.3059,  0.0357,  0.0488, -0.2643],\n",
       "                      [-0.4536, -0.0730,  0.1189,  0.0898],\n",
       "                      [-0.1239, -0.4004,  0.2764,  0.1179],\n",
       "                      [-0.1030,  0.1246, -0.4812,  0.3477],\n",
       "                      [-0.2038,  0.4071,  0.3693,  0.0070],\n",
       "                      [-0.4953,  0.2628, -0.4352,  0.0955],\n",
       "                      [-0.0652, -0.3556, -0.3307, -0.3842],\n",
       "                      [ 0.3431,  0.2772, -0.0165,  0.1277],\n",
       "                      [ 0.3687, -0.2362,  0.4653,  0.2696],\n",
       "                      [-0.3181,  0.1532,  0.1161,  0.0338],\n",
       "                      [-0.2235,  0.2534,  0.1516,  0.2238],\n",
       "                      [ 0.1161,  0.0753,  0.2696, -0.1383],\n",
       "                      [ 0.2292,  0.0990, -0.2023, -0.2628],\n",
       "                      [ 0.1872,  0.3200, -0.3126,  0.4467],\n",
       "                      [ 0.0857,  0.4174, -0.1870, -0.0999],\n",
       "                      [ 0.1400, -0.4295, -0.4839,  0.4825],\n",
       "                      [ 0.0884,  0.3910,  0.4198,  0.1080],\n",
       "                      [ 0.2116, -0.2073, -0.3589, -0.0641],\n",
       "                      [ 0.1432,  0.2216, -0.2499,  0.4727],\n",
       "                      [-0.4891,  0.0372,  0.4936, -0.1248],\n",
       "                      [ 0.0954, -0.3944, -0.0416,  0.0308],\n",
       "                      [ 0.1336, -0.3460,  0.4248,  0.4161],\n",
       "                      [ 0.4574,  0.1650,  0.4521, -0.4897],\n",
       "                      [-0.3161,  0.0505, -0.2954,  0.3642],\n",
       "                      [ 0.2089, -0.2417,  0.1392, -0.3536],\n",
       "                      [-0.2842,  0.3034,  0.3765, -0.1765],\n",
       "                      [ 0.1956,  0.0407,  0.1564, -0.3103],\n",
       "                      [-0.4061, -0.1839,  0.3266, -0.1266],\n",
       "                      [-0.2454,  0.3133,  0.4485,  0.4430],\n",
       "                      [ 0.3029,  0.3011, -0.4536, -0.4519],\n",
       "                      [ 0.1614,  0.0748,  0.4537, -0.2683],\n",
       "                      [-0.1162,  0.1277,  0.2206,  0.4219],\n",
       "                      [ 0.4460,  0.2463,  0.0532,  0.2142],\n",
       "                      [ 0.3315,  0.1894,  0.0330, -0.3556],\n",
       "                      [-0.0417, -0.2539, -0.1254,  0.3467],\n",
       "                      [-0.2832,  0.4756,  0.3309,  0.3685],\n",
       "                      [ 0.2397, -0.2586, -0.3532, -0.1578],\n",
       "                      [ 0.3041,  0.2588, -0.4890,  0.3705],\n",
       "                      [-0.3208, -0.2986, -0.0719, -0.2350],\n",
       "                      [ 0.3154, -0.0182, -0.3129,  0.1398],\n",
       "                      [ 0.0134, -0.4889,  0.3312, -0.1259],\n",
       "                      [-0.1197,  0.4699, -0.0097,  0.4419],\n",
       "                      [-0.2868,  0.3354,  0.2110,  0.0234],\n",
       "                      [ 0.2988,  0.1108,  0.3371,  0.2575],\n",
       "                      [ 0.0260, -0.3993,  0.2849, -0.2603],\n",
       "                      [ 0.3023, -0.4551, -0.0990,  0.2746],\n",
       "                      [ 0.4196, -0.3720,  0.4901, -0.3542],\n",
       "                      [ 0.0702, -0.0832,  0.1074,  0.1231],\n",
       "                      [-0.1811, -0.3319, -0.2428, -0.0419],\n",
       "                      [ 0.1659,  0.4420,  0.2266, -0.4206],\n",
       "                      [-0.2438,  0.0483,  0.1071,  0.2565],\n",
       "                      [ 0.4014,  0.0243,  0.3109, -0.0715],\n",
       "                      [ 0.4247,  0.2588, -0.2414,  0.4173],\n",
       "                      [-0.2240,  0.3961, -0.0351,  0.4040],\n",
       "                      [-0.3922, -0.1969,  0.1884, -0.1135],\n",
       "                      [ 0.1004, -0.3191,  0.4142,  0.3810],\n",
       "                      [-0.3802,  0.1391,  0.2404,  0.2164],\n",
       "                      [-0.2777, -0.1261,  0.2381,  0.3772],\n",
       "                      [ 0.2903,  0.1666, -0.0118,  0.0088],\n",
       "                      [ 0.1910,  0.2121, -0.3862, -0.0452],\n",
       "                      [ 0.4179,  0.0983, -0.0770, -0.3823],\n",
       "                      [ 0.3839, -0.2737, -0.2760,  0.1021],\n",
       "                      [ 0.3282, -0.1635,  0.1940,  0.0413],\n",
       "                      [ 0.4779, -0.3361,  0.0955,  0.1864],\n",
       "                      [ 0.4850, -0.2885,  0.3151,  0.4430],\n",
       "                      [ 0.0102, -0.3254, -0.1255, -0.3945],\n",
       "                      [-0.0531, -0.1644,  0.1560, -0.2162],\n",
       "                      [-0.3377, -0.2382,  0.2232, -0.3254],\n",
       "                      [ 0.4534,  0.0834, -0.2204, -0.2263],\n",
       "                      [ 0.1629,  0.0966, -0.3275,  0.2434],\n",
       "                      [-0.1791,  0.2993, -0.1746,  0.2383],\n",
       "                      [-0.3441,  0.3753,  0.1797, -0.0161],\n",
       "                      [ 0.2232,  0.1950,  0.2948,  0.0083],\n",
       "                      [ 0.3232,  0.2722, -0.1960, -0.3336],\n",
       "                      [ 0.4483, -0.1560,  0.4587, -0.3103],\n",
       "                      [ 0.1878, -0.0039,  0.4592, -0.0606],\n",
       "                      [ 0.4432,  0.1848, -0.0349,  0.3773],\n",
       "                      [-0.2161,  0.3143,  0.2287, -0.4554],\n",
       "                      [ 0.0062, -0.0867, -0.0547, -0.4348],\n",
       "                      [-0.4032, -0.2091,  0.3408,  0.3531],\n",
       "                      [-0.4299,  0.4364, -0.0498,  0.3076],\n",
       "                      [-0.2422, -0.0287, -0.2301,  0.0476],\n",
       "                      [-0.1087,  0.4237, -0.3402, -0.1324],\n",
       "                      [ 0.0633,  0.1833,  0.3750, -0.3031],\n",
       "                      [ 0.2974,  0.0049, -0.2917,  0.3901],\n",
       "                      [-0.1099,  0.2045,  0.4648,  0.0650],\n",
       "                      [-0.4218,  0.1723,  0.0348, -0.2496],\n",
       "                      [ 0.3688,  0.1891, -0.2181, -0.1895],\n",
       "                      [-0.3856,  0.3346,  0.4016, -0.0637],\n",
       "                      [ 0.1868, -0.1619, -0.2799, -0.3524],\n",
       "                      [-0.3493,  0.1931, -0.4811,  0.4570],\n",
       "                      [ 0.0242, -0.4596, -0.4968, -0.4490],\n",
       "                      [-0.4180, -0.3247,  0.2537, -0.2894],\n",
       "                      [-0.3003, -0.1034,  0.2077,  0.4661],\n",
       "                      [ 0.3200, -0.4950, -0.1024, -0.1017],\n",
       "                      [ 0.3193,  0.2652, -0.1674,  0.2241],\n",
       "                      [-0.3060,  0.0285, -0.4157, -0.4403],\n",
       "                      [ 0.2542,  0.4688, -0.0419, -0.3446],\n",
       "                      [ 0.0531,  0.2238, -0.1103,  0.4604],\n",
       "                      [-0.1461, -0.4160, -0.1180, -0.1834],\n",
       "                      [ 0.0831, -0.4099,  0.1310,  0.3559],\n",
       "                      [-0.4661, -0.1036, -0.2866, -0.2283],\n",
       "                      [-0.2235, -0.4092,  0.1854, -0.0590],\n",
       "                      [-0.2363, -0.0882,  0.2349,  0.3979],\n",
       "                      [ 0.1374,  0.0537,  0.2070, -0.2862],\n",
       "                      [-0.1466,  0.0099,  0.2991,  0.3316],\n",
       "                      [-0.3932, -0.2693,  0.2669, -0.0153],\n",
       "                      [-0.4534, -0.2349,  0.3436, -0.4700],\n",
       "                      [-0.1252, -0.2883, -0.1390, -0.4714],\n",
       "                      [ 0.3716,  0.0865,  0.4709, -0.4434],\n",
       "                      [-0.3793, -0.4951, -0.4130, -0.3359],\n",
       "                      [-0.1382,  0.1383,  0.2707,  0.3185],\n",
       "                      [-0.2597,  0.3973, -0.0506, -0.4547],\n",
       "                      [-0.1142,  0.1568,  0.2919,  0.1541],\n",
       "                      [-0.0261, -0.3453,  0.0644,  0.4734],\n",
       "                      [-0.3263, -0.1935, -0.3101, -0.4369],\n",
       "                      [ 0.4295, -0.3218,  0.0745, -0.0818],\n",
       "                      [ 0.0250, -0.3544,  0.0387, -0.2098],\n",
       "                      [-0.1143,  0.4173, -0.2468, -0.1288],\n",
       "                      [-0.0229,  0.4528, -0.4948,  0.1085],\n",
       "                      [ 0.4512,  0.3611, -0.0054, -0.3499],\n",
       "                      [ 0.4939, -0.1773,  0.2821,  0.1295]])),\n",
       "             ('nodes.0.callable.block.h_net.0.linear.linear.weight',\n",
       "              tensor([[ 0.1340, -0.1787,  0.0454, -0.2385],\n",
       "                      [-0.2164,  0.0197,  0.0254, -0.2206],\n",
       "                      [ 0.4527,  0.2198, -0.4125, -0.4141],\n",
       "                      [ 0.3356, -0.2354,  0.2027,  0.3275],\n",
       "                      [-0.4769, -0.0482,  0.0386, -0.0936],\n",
       "                      [ 0.4239,  0.4917, -0.0665, -0.0935],\n",
       "                      [-0.3059,  0.0357,  0.0488, -0.2643],\n",
       "                      [-0.4536, -0.0730,  0.1189,  0.0898],\n",
       "                      [-0.1239, -0.4004,  0.2764,  0.1179],\n",
       "                      [-0.1030,  0.1246, -0.4812,  0.3477],\n",
       "                      [-0.2038,  0.4071,  0.3693,  0.0070],\n",
       "                      [-0.4953,  0.2628, -0.4352,  0.0955],\n",
       "                      [-0.0652, -0.3556, -0.3307, -0.3842],\n",
       "                      [ 0.3431,  0.2772, -0.0165,  0.1277],\n",
       "                      [ 0.3687, -0.2362,  0.4653,  0.2696],\n",
       "                      [-0.3181,  0.1532,  0.1161,  0.0338],\n",
       "                      [-0.2235,  0.2534,  0.1516,  0.2238],\n",
       "                      [ 0.1161,  0.0753,  0.2696, -0.1383],\n",
       "                      [ 0.2292,  0.0990, -0.2023, -0.2628],\n",
       "                      [ 0.1872,  0.3200, -0.3126,  0.4467],\n",
       "                      [ 0.0857,  0.4174, -0.1870, -0.0999],\n",
       "                      [ 0.1400, -0.4295, -0.4839,  0.4825],\n",
       "                      [ 0.0884,  0.3910,  0.4198,  0.1080],\n",
       "                      [ 0.2116, -0.2073, -0.3589, -0.0641],\n",
       "                      [ 0.1432,  0.2216, -0.2499,  0.4727],\n",
       "                      [-0.4891,  0.0372,  0.4936, -0.1248],\n",
       "                      [ 0.0954, -0.3944, -0.0416,  0.0308],\n",
       "                      [ 0.1336, -0.3460,  0.4248,  0.4161],\n",
       "                      [ 0.4574,  0.1650,  0.4521, -0.4897],\n",
       "                      [-0.3161,  0.0505, -0.2954,  0.3642],\n",
       "                      [ 0.2089, -0.2417,  0.1392, -0.3536],\n",
       "                      [-0.2842,  0.3034,  0.3765, -0.1765],\n",
       "                      [ 0.1956,  0.0407,  0.1564, -0.3103],\n",
       "                      [-0.4061, -0.1839,  0.3266, -0.1266],\n",
       "                      [-0.2454,  0.3133,  0.4485,  0.4430],\n",
       "                      [ 0.3029,  0.3011, -0.4536, -0.4519],\n",
       "                      [ 0.1614,  0.0748,  0.4537, -0.2683],\n",
       "                      [-0.1162,  0.1277,  0.2206,  0.4219],\n",
       "                      [ 0.4460,  0.2463,  0.0532,  0.2142],\n",
       "                      [ 0.3315,  0.1894,  0.0330, -0.3556],\n",
       "                      [-0.0417, -0.2539, -0.1254,  0.3467],\n",
       "                      [-0.2832,  0.4756,  0.3309,  0.3685],\n",
       "                      [ 0.2397, -0.2586, -0.3532, -0.1578],\n",
       "                      [ 0.3041,  0.2588, -0.4890,  0.3705],\n",
       "                      [-0.3208, -0.2986, -0.0719, -0.2350],\n",
       "                      [ 0.3154, -0.0182, -0.3129,  0.1398],\n",
       "                      [ 0.0134, -0.4889,  0.3312, -0.1259],\n",
       "                      [-0.1197,  0.4699, -0.0097,  0.4419],\n",
       "                      [-0.2868,  0.3354,  0.2110,  0.0234],\n",
       "                      [ 0.2988,  0.1108,  0.3371,  0.2575],\n",
       "                      [ 0.0260, -0.3993,  0.2849, -0.2603],\n",
       "                      [ 0.3023, -0.4551, -0.0990,  0.2746],\n",
       "                      [ 0.4196, -0.3720,  0.4901, -0.3542],\n",
       "                      [ 0.0702, -0.0832,  0.1074,  0.1231],\n",
       "                      [-0.1811, -0.3319, -0.2428, -0.0419],\n",
       "                      [ 0.1659,  0.4420,  0.2266, -0.4206],\n",
       "                      [-0.2438,  0.0483,  0.1071,  0.2565],\n",
       "                      [ 0.4014,  0.0243,  0.3109, -0.0715],\n",
       "                      [ 0.4247,  0.2588, -0.2414,  0.4173],\n",
       "                      [-0.2240,  0.3961, -0.0351,  0.4040],\n",
       "                      [-0.3922, -0.1969,  0.1884, -0.1135],\n",
       "                      [ 0.1004, -0.3191,  0.4142,  0.3810],\n",
       "                      [-0.3802,  0.1391,  0.2404,  0.2164],\n",
       "                      [-0.2777, -0.1261,  0.2381,  0.3772],\n",
       "                      [ 0.2903,  0.1666, -0.0118,  0.0088],\n",
       "                      [ 0.1910,  0.2121, -0.3862, -0.0452],\n",
       "                      [ 0.4179,  0.0983, -0.0770, -0.3823],\n",
       "                      [ 0.3839, -0.2737, -0.2760,  0.1021],\n",
       "                      [ 0.3282, -0.1635,  0.1940,  0.0413],\n",
       "                      [ 0.4779, -0.3361,  0.0955,  0.1864],\n",
       "                      [ 0.4850, -0.2885,  0.3151,  0.4430],\n",
       "                      [ 0.0102, -0.3254, -0.1255, -0.3945],\n",
       "                      [-0.0531, -0.1644,  0.1560, -0.2162],\n",
       "                      [-0.3377, -0.2382,  0.2232, -0.3254],\n",
       "                      [ 0.4534,  0.0834, -0.2204, -0.2263],\n",
       "                      [ 0.1629,  0.0966, -0.3275,  0.2434],\n",
       "                      [-0.1791,  0.2993, -0.1746,  0.2383],\n",
       "                      [-0.3441,  0.3753,  0.1797, -0.0161],\n",
       "                      [ 0.2232,  0.1950,  0.2948,  0.0083],\n",
       "                      [ 0.3232,  0.2722, -0.1960, -0.3336],\n",
       "                      [ 0.4483, -0.1560,  0.4587, -0.3103],\n",
       "                      [ 0.1878, -0.0039,  0.4592, -0.0606],\n",
       "                      [ 0.4432,  0.1848, -0.0349,  0.3773],\n",
       "                      [-0.2161,  0.3143,  0.2287, -0.4554],\n",
       "                      [ 0.0062, -0.0867, -0.0547, -0.4348],\n",
       "                      [-0.4032, -0.2091,  0.3408,  0.3531],\n",
       "                      [-0.4299,  0.4364, -0.0498,  0.3076],\n",
       "                      [-0.2422, -0.0287, -0.2301,  0.0476],\n",
       "                      [-0.1087,  0.4237, -0.3402, -0.1324],\n",
       "                      [ 0.0633,  0.1833,  0.3750, -0.3031],\n",
       "                      [ 0.2974,  0.0049, -0.2917,  0.3901],\n",
       "                      [-0.1099,  0.2045,  0.4648,  0.0650],\n",
       "                      [-0.4218,  0.1723,  0.0348, -0.2496],\n",
       "                      [ 0.3688,  0.1891, -0.2181, -0.1895],\n",
       "                      [-0.3856,  0.3346,  0.4016, -0.0637],\n",
       "                      [ 0.1868, -0.1619, -0.2799, -0.3524],\n",
       "                      [-0.3493,  0.1931, -0.4811,  0.4570],\n",
       "                      [ 0.0242, -0.4596, -0.4968, -0.4490],\n",
       "                      [-0.4180, -0.3247,  0.2537, -0.2894],\n",
       "                      [-0.3003, -0.1034,  0.2077,  0.4661],\n",
       "                      [ 0.3200, -0.4950, -0.1024, -0.1017],\n",
       "                      [ 0.3193,  0.2652, -0.1674,  0.2241],\n",
       "                      [-0.3060,  0.0285, -0.4157, -0.4403],\n",
       "                      [ 0.2542,  0.4688, -0.0419, -0.3446],\n",
       "                      [ 0.0531,  0.2238, -0.1103,  0.4604],\n",
       "                      [-0.1461, -0.4160, -0.1180, -0.1834],\n",
       "                      [ 0.0831, -0.4099,  0.1310,  0.3559],\n",
       "                      [-0.4661, -0.1036, -0.2866, -0.2283],\n",
       "                      [-0.2235, -0.4092,  0.1854, -0.0590],\n",
       "                      [-0.2363, -0.0882,  0.2349,  0.3979],\n",
       "                      [ 0.1374,  0.0537,  0.2070, -0.2862],\n",
       "                      [-0.1466,  0.0099,  0.2991,  0.3316],\n",
       "                      [-0.3932, -0.2693,  0.2669, -0.0153],\n",
       "                      [-0.4534, -0.2349,  0.3436, -0.4700],\n",
       "                      [-0.1252, -0.2883, -0.1390, -0.4714],\n",
       "                      [ 0.3716,  0.0865,  0.4709, -0.4434],\n",
       "                      [-0.3793, -0.4951, -0.4130, -0.3359],\n",
       "                      [-0.1382,  0.1383,  0.2707,  0.3185],\n",
       "                      [-0.2597,  0.3973, -0.0506, -0.4547],\n",
       "                      [-0.1142,  0.1568,  0.2919,  0.1541],\n",
       "                      [-0.0261, -0.3453,  0.0644,  0.4734],\n",
       "                      [-0.3263, -0.1935, -0.3101, -0.4369],\n",
       "                      [ 0.4295, -0.3218,  0.0745, -0.0818],\n",
       "                      [ 0.0250, -0.3544,  0.0387, -0.2098],\n",
       "                      [-0.1143,  0.4173, -0.2468, -0.1288],\n",
       "                      [-0.0229,  0.4528, -0.4948,  0.1085],\n",
       "                      [ 0.4512,  0.3611, -0.0054, -0.3499],\n",
       "                      [ 0.4939, -0.1773,  0.2821,  0.1295]])),\n",
       "             ('nodes.0.callable.block.h_net.0.linear.linear.bias',\n",
       "              tensor([-0.4392,  0.2894, -0.1628,  0.0036,  0.0647,  0.4573,  0.3764,  0.4140,\n",
       "                       0.3550,  0.1038, -0.4476, -0.4009,  0.0378, -0.4800,  0.0207, -0.0585,\n",
       "                       0.3657, -0.4031, -0.4888, -0.2905,  0.4373,  0.1989, -0.2258,  0.4604,\n",
       "                      -0.3161,  0.2947, -0.1008, -0.2852, -0.1818, -0.1367, -0.1980,  0.4229,\n",
       "                       0.3302, -0.3799, -0.1056,  0.0361, -0.1262, -0.1321, -0.4896, -0.3021,\n",
       "                       0.1617, -0.0551,  0.3279, -0.3791, -0.3732,  0.4825,  0.1107, -0.0760,\n",
       "                       0.1572,  0.1019, -0.0570, -0.4397, -0.2143,  0.0468,  0.0712,  0.1483,\n",
       "                       0.4340,  0.1990, -0.1331,  0.2578,  0.1986, -0.0927,  0.1046, -0.4865,\n",
       "                       0.3057, -0.1731,  0.1649,  0.1033, -0.2758,  0.4657,  0.4410,  0.2468,\n",
       "                      -0.4887, -0.1700, -0.2237,  0.1621,  0.3126,  0.1308,  0.2842,  0.4615,\n",
       "                      -0.2613, -0.2849, -0.2243, -0.3132,  0.4930,  0.4575, -0.3948, -0.0464,\n",
       "                      -0.3947, -0.1023,  0.4605, -0.0159, -0.4991, -0.1414, -0.3768,  0.3419,\n",
       "                      -0.1562, -0.2972, -0.3772,  0.1504,  0.3635, -0.4196,  0.4091, -0.3736,\n",
       "                      -0.2731,  0.1593, -0.0327, -0.0577,  0.4574,  0.0613,  0.3243,  0.2813,\n",
       "                       0.0547, -0.0078, -0.2194, -0.2882, -0.0247,  0.2890, -0.1983, -0.4787,\n",
       "                       0.3641,  0.1564,  0.4707,  0.4635, -0.1911,  0.0765, -0.1351,  0.3277])),\n",
       "             ('nodes.0.callable.block.h_net.2.linear.bias',\n",
       "              tensor([-0.0615, -0.0623, -0.0315,  0.0549, -0.0235,  0.0431, -0.0227, -0.0816,\n",
       "                      -0.0765, -0.0476, -0.0480, -0.0202, -0.0753,  0.0596, -0.0415,  0.0164,\n",
       "                      -0.0304,  0.0796,  0.0562,  0.0568,  0.0143, -0.0781, -0.0162,  0.0452,\n",
       "                       0.0072, -0.0230,  0.0352, -0.0705,  0.0793, -0.0519,  0.0847, -0.0454,\n",
       "                      -0.0482, -0.0063,  0.0421,  0.0258,  0.0150, -0.0559, -0.0274, -0.0035,\n",
       "                      -0.0062, -0.0781, -0.0431,  0.0485,  0.0877, -0.0361,  0.0624,  0.0815,\n",
       "                       0.0223,  0.0580, -0.0738, -0.0600, -0.0060, -0.0303, -0.0452,  0.0354,\n",
       "                       0.0412,  0.0159,  0.0819,  0.0075,  0.0314,  0.0644,  0.0027,  0.0016,\n",
       "                       0.0459,  0.0543, -0.0143, -0.0129, -0.0293,  0.0050,  0.0051, -0.0427,\n",
       "                       0.0529,  0.0659,  0.0207, -0.0488,  0.0761,  0.0157,  0.0726, -0.0565,\n",
       "                       0.0738, -0.0346, -0.0416, -0.0532,  0.0374,  0.0285, -0.0462,  0.0714,\n",
       "                      -0.0475, -0.0828, -0.0733,  0.0068, -0.0054, -0.0033,  0.0596,  0.0711,\n",
       "                       0.0503,  0.0379,  0.0785,  0.0254,  0.0556, -0.0290, -0.0329,  0.0011,\n",
       "                      -0.0679, -0.0296, -0.0188,  0.0020, -0.0757, -0.0683, -0.0514,  0.0125,\n",
       "                      -0.0380,  0.0178, -0.0145,  0.0478,  0.0671,  0.0606, -0.0608, -0.0151,\n",
       "                      -0.0646, -0.0547, -0.0503, -0.0716, -0.0151,  0.0270,  0.0381,  0.0408])),\n",
       "             ('nodes.0.callable.block.h_net.2.linear.weight',\n",
       "              tensor([[ 0.0457,  0.0472, -0.0200,  ...,  0.0666,  0.0183,  0.0406],\n",
       "                      [-0.0083, -0.0125,  0.0369,  ..., -0.0204,  0.0441,  0.0236],\n",
       "                      [ 0.0889, -0.0293,  0.0597,  ...,  0.0881,  0.0344, -0.0075],\n",
       "                      ...,\n",
       "                      [-0.0051, -0.0673, -0.0147,  ..., -0.0744, -0.0072, -0.0794],\n",
       "                      [-0.0869,  0.0113,  0.0299,  ..., -0.0473,  0.0018,  0.0639],\n",
       "                      [-0.0714, -0.0215, -0.0389,  ..., -0.0832, -0.0203,  0.0775]])),\n",
       "             ('nodes.0.callable.block.h_net.2.linear.linear.weight',\n",
       "              tensor([[ 0.0457,  0.0472, -0.0200,  ...,  0.0666,  0.0183,  0.0406],\n",
       "                      [-0.0083, -0.0125,  0.0369,  ..., -0.0204,  0.0441,  0.0236],\n",
       "                      [ 0.0889, -0.0293,  0.0597,  ...,  0.0881,  0.0344, -0.0075],\n",
       "                      ...,\n",
       "                      [-0.0051, -0.0673, -0.0147,  ..., -0.0744, -0.0072, -0.0794],\n",
       "                      [-0.0869,  0.0113,  0.0299,  ..., -0.0473,  0.0018,  0.0639],\n",
       "                      [-0.0714, -0.0215, -0.0389,  ..., -0.0832, -0.0203,  0.0775]])),\n",
       "             ('nodes.0.callable.block.h_net.2.linear.linear.bias',\n",
       "              tensor([-0.0615, -0.0623, -0.0315,  0.0549, -0.0235,  0.0431, -0.0227, -0.0816,\n",
       "                      -0.0765, -0.0476, -0.0480, -0.0202, -0.0753,  0.0596, -0.0415,  0.0164,\n",
       "                      -0.0304,  0.0796,  0.0562,  0.0568,  0.0143, -0.0781, -0.0162,  0.0452,\n",
       "                       0.0072, -0.0230,  0.0352, -0.0705,  0.0793, -0.0519,  0.0847, -0.0454,\n",
       "                      -0.0482, -0.0063,  0.0421,  0.0258,  0.0150, -0.0559, -0.0274, -0.0035,\n",
       "                      -0.0062, -0.0781, -0.0431,  0.0485,  0.0877, -0.0361,  0.0624,  0.0815,\n",
       "                       0.0223,  0.0580, -0.0738, -0.0600, -0.0060, -0.0303, -0.0452,  0.0354,\n",
       "                       0.0412,  0.0159,  0.0819,  0.0075,  0.0314,  0.0644,  0.0027,  0.0016,\n",
       "                       0.0459,  0.0543, -0.0143, -0.0129, -0.0293,  0.0050,  0.0051, -0.0427,\n",
       "                       0.0529,  0.0659,  0.0207, -0.0488,  0.0761,  0.0157,  0.0726, -0.0565,\n",
       "                       0.0738, -0.0346, -0.0416, -0.0532,  0.0374,  0.0285, -0.0462,  0.0714,\n",
       "                      -0.0475, -0.0828, -0.0733,  0.0068, -0.0054, -0.0033,  0.0596,  0.0711,\n",
       "                       0.0503,  0.0379,  0.0785,  0.0254,  0.0556, -0.0290, -0.0329,  0.0011,\n",
       "                      -0.0679, -0.0296, -0.0188,  0.0020, -0.0757, -0.0683, -0.0514,  0.0125,\n",
       "                      -0.0380,  0.0178, -0.0145,  0.0478,  0.0671,  0.0606, -0.0608, -0.0151,\n",
       "                      -0.0646, -0.0547, -0.0503, -0.0716, -0.0151,  0.0270,  0.0381,  0.0408])),\n",
       "             ('nodes.0.callable.block.h_net.4.linear.bias',\n",
       "              tensor([-0.0594, -0.0401, -0.0831, -0.0804])),\n",
       "             ('nodes.0.callable.block.h_net.4.linear.weight',\n",
       "              tensor([[-3.5173e-02, -4.4497e-02,  7.6588e-02,  8.7364e-02, -3.0043e-02,\n",
       "                       -3.0896e-02, -8.4616e-03,  2.8905e-02, -2.8570e-02, -3.3212e-02,\n",
       "                        5.6230e-02,  4.5418e-02, -2.8192e-02, -7.9891e-02,  6.9862e-03,\n",
       "                        7.9683e-02, -8.2534e-02,  8.7352e-02,  1.7975e-02,  6.6818e-02,\n",
       "                        8.5050e-02,  5.1660e-03,  2.0489e-02, -7.1080e-02,  7.1861e-02,\n",
       "                        3.8066e-02, -8.0860e-02,  1.5288e-02,  2.9383e-02, -7.4320e-02,\n",
       "                        4.0873e-02, -1.4628e-02,  3.5897e-03,  2.5661e-02,  7.4784e-02,\n",
       "                        6.9696e-02,  5.4568e-02, -3.5123e-02, -5.0126e-02,  4.6214e-02,\n",
       "                       -6.0590e-02, -2.4355e-02,  2.8358e-02, -8.6546e-02,  7.5329e-02,\n",
       "                       -4.4725e-02, -5.4368e-03,  4.9333e-02, -5.4701e-03, -5.6535e-02,\n",
       "                        6.4362e-02, -3.0461e-02, -2.7679e-02, -6.8422e-02,  3.8520e-02,\n",
       "                        8.8863e-02,  5.8934e-02, -5.2553e-02, -1.9937e-03, -3.3308e-02,\n",
       "                        2.5772e-02, -4.5756e-02,  7.6201e-02, -8.5146e-02,  8.0813e-02,\n",
       "                        3.2469e-02,  3.5142e-02,  7.5318e-02, -8.0324e-02, -4.2704e-02,\n",
       "                       -5.0220e-02, -4.5527e-02, -5.8403e-02, -2.7684e-02,  5.7041e-02,\n",
       "                       -6.7524e-02,  5.2480e-02, -1.1037e-02, -4.9907e-03, -3.4826e-02,\n",
       "                        6.6565e-02, -2.5812e-02,  8.2166e-02, -1.8024e-02, -3.5590e-02,\n",
       "                       -4.6999e-02,  4.9579e-03,  1.9043e-03, -2.9053e-02, -3.4134e-02,\n",
       "                        2.6952e-02,  7.3200e-02,  5.5778e-02,  3.9315e-02,  7.7335e-02,\n",
       "                       -3.6789e-02,  4.0438e-02,  7.4670e-02, -8.5703e-02, -2.4556e-02,\n",
       "                       -2.4254e-02,  1.2562e-02,  8.7053e-02,  7.1992e-02, -1.9526e-02,\n",
       "                       -3.1892e-02,  1.1520e-02, -8.0788e-02,  3.2398e-02, -7.0177e-02,\n",
       "                       -4.4256e-02,  2.4456e-02, -7.6879e-02,  7.3001e-02, -9.8512e-03,\n",
       "                       -8.0124e-02,  7.0135e-02, -5.0165e-03, -1.8186e-03,  3.1613e-02,\n",
       "                        5.8455e-02,  5.8285e-02, -5.1941e-03, -3.0671e-02,  4.1575e-02,\n",
       "                        4.8770e-02,  2.7136e-02,  1.8483e-02],\n",
       "                      [-8.8813e-02, -3.1939e-02,  6.3231e-02,  3.7498e-02,  2.5346e-02,\n",
       "                       -5.7532e-02,  5.2633e-02, -3.8021e-02,  3.4746e-02,  2.8866e-03,\n",
       "                       -5.3474e-03, -3.7500e-02,  3.1217e-02,  7.5727e-02, -7.7679e-02,\n",
       "                        3.3901e-02,  1.2616e-02, -3.0250e-03,  7.5394e-02,  1.0348e-03,\n",
       "                        6.6114e-02, -2.9402e-02, -3.8780e-02,  5.0307e-02, -3.9238e-02,\n",
       "                        5.9846e-02,  2.6639e-02, -2.3566e-02,  7.4350e-02, -9.5251e-03,\n",
       "                        3.7650e-02,  7.6840e-02,  3.9021e-02, -6.7876e-02,  4.5737e-02,\n",
       "                       -3.7581e-02,  6.4928e-02,  3.0489e-02,  6.4631e-03,  3.9733e-02,\n",
       "                       -9.4973e-03,  7.9075e-02,  8.1284e-02, -8.7261e-02, -2.6156e-02,\n",
       "                        3.2298e-02, -1.7671e-02,  7.8102e-03, -6.9917e-02, -1.4941e-02,\n",
       "                        1.5037e-02,  7.5266e-02,  5.1356e-02, -6.5954e-02, -6.7302e-02,\n",
       "                        2.8777e-02, -2.5524e-02, -6.0648e-02,  1.1465e-03, -5.1034e-02,\n",
       "                        3.6473e-02, -7.6575e-02, -4.7485e-02, -9.6462e-03, -8.3178e-02,\n",
       "                        8.3369e-02, -4.4991e-02, -2.8951e-02,  3.3293e-02, -1.5229e-02,\n",
       "                       -2.8867e-02,  1.6033e-04, -3.8920e-02, -6.6510e-02,  6.4069e-02,\n",
       "                       -3.1382e-03, -5.4341e-02,  1.7948e-02, -6.0823e-02,  8.1369e-02,\n",
       "                       -2.2022e-02, -4.8792e-03, -8.7676e-02, -7.9658e-02,  7.7293e-02,\n",
       "                       -1.7380e-02, -6.2316e-02,  4.8458e-02, -4.0455e-02, -3.9774e-02,\n",
       "                        4.7649e-02,  6.4107e-02,  2.3936e-02,  4.9305e-02, -1.6919e-02,\n",
       "                       -3.0811e-02,  3.7338e-02,  3.0132e-02,  2.2192e-02,  5.2207e-02,\n",
       "                        3.4541e-02,  2.2659e-02,  5.4383e-02,  2.0541e-02,  3.7585e-02,\n",
       "                        5.2715e-02, -3.6520e-02, -6.5783e-02,  8.1290e-02,  1.9503e-02,\n",
       "                       -5.6536e-02, -4.3634e-02, -7.5881e-02, -1.9798e-02,  7.5605e-02,\n",
       "                        3.2974e-03,  8.2184e-02,  2.7088e-02, -2.2324e-02, -8.6834e-02,\n",
       "                       -1.8462e-02,  7.1073e-02, -2.5805e-02,  8.2875e-02,  1.9377e-02,\n",
       "                       -3.5830e-02, -8.7623e-02,  7.9965e-02],\n",
       "                      [-4.1164e-02,  3.5399e-02, -8.5207e-02,  8.8395e-02,  4.9713e-02,\n",
       "                       -3.7236e-03,  2.5451e-02,  2.8610e-02, -6.8137e-02,  7.0945e-02,\n",
       "                       -2.4770e-02, -3.9282e-02,  8.6827e-02,  6.1716e-02, -1.3392e-02,\n",
       "                       -1.9762e-02,  4.2546e-02, -5.9198e-02, -5.3806e-02, -6.0389e-02,\n",
       "                       -1.7704e-02, -7.4765e-03,  8.3521e-03,  2.4562e-02, -7.7878e-02,\n",
       "                       -4.5409e-02, -3.8038e-02, -5.7220e-02,  7.2765e-03,  4.3225e-02,\n",
       "                       -4.6584e-02,  1.2266e-02,  4.8149e-02, -5.4341e-02,  5.3271e-02,\n",
       "                        8.2987e-05,  6.2069e-03,  5.0989e-02,  3.1633e-02, -1.9848e-02,\n",
       "                       -2.0279e-03,  1.2764e-02, -1.7177e-02, -5.2193e-03,  2.9277e-02,\n",
       "                        8.5870e-02,  8.1618e-02,  3.5360e-02, -3.7607e-02, -5.6583e-02,\n",
       "                       -8.4119e-02,  1.8734e-02, -1.9390e-02, -1.1128e-02,  4.9184e-02,\n",
       "                        7.2864e-02, -1.3267e-02,  7.2239e-02,  3.6702e-02, -2.0602e-02,\n",
       "                        1.9982e-02,  7.9325e-02,  5.1899e-02,  1.5381e-02, -7.6492e-02,\n",
       "                       -1.9938e-02,  6.3239e-02,  2.6422e-02, -3.9926e-02,  6.0776e-02,\n",
       "                       -1.3594e-02, -6.9930e-02, -3.5426e-02, -7.6241e-02,  7.2722e-02,\n",
       "                        1.3603e-03, -2.1854e-02, -1.6625e-02,  6.3929e-02,  7.3812e-02,\n",
       "                        3.7637e-03, -5.6881e-02, -3.6950e-02, -7.1034e-02, -3.9190e-02,\n",
       "                        1.8264e-02,  6.6502e-02,  4.2458e-02, -9.6274e-03, -3.7336e-02,\n",
       "                       -4.7905e-02,  8.6262e-02,  8.5571e-03,  1.9700e-02, -5.9192e-02,\n",
       "                       -6.1123e-02, -8.6234e-02, -8.1519e-02,  3.4573e-02, -7.7321e-02,\n",
       "                       -6.4039e-02,  3.5563e-02,  4.0458e-02,  2.5201e-04, -3.2272e-02,\n",
       "                        7.6549e-03,  6.6674e-02, -6.8912e-02,  2.4600e-02,  5.3329e-02,\n",
       "                       -1.5653e-02, -7.5966e-02,  6.8771e-02, -6.4565e-02,  1.9294e-02,\n",
       "                       -7.9938e-02,  8.3194e-02,  1.8674e-02, -1.6295e-02,  9.4552e-04,\n",
       "                       -4.5627e-02,  5.8777e-02, -4.2428e-02, -8.6817e-02,  8.7773e-02,\n",
       "                       -1.8653e-02, -8.3102e-02, -8.7194e-02],\n",
       "                      [-4.2778e-02, -7.5762e-02, -6.3562e-02, -5.3086e-02, -7.5959e-02,\n",
       "                       -4.4555e-02, -7.1359e-02,  5.8299e-02, -7.3987e-02,  6.8683e-02,\n",
       "                        2.3010e-02, -3.7479e-02, -6.0253e-02,  8.5548e-02,  2.0121e-03,\n",
       "                       -3.0045e-02,  8.5122e-03, -2.0209e-03,  2.6082e-02,  4.1748e-02,\n",
       "                       -5.7912e-02,  2.6891e-02, -7.2411e-02, -6.7645e-02, -4.3058e-02,\n",
       "                       -6.7384e-02, -2.2633e-02,  7.0010e-02, -3.2614e-02,  7.6523e-02,\n",
       "                       -4.8604e-02, -5.2599e-02, -5.8937e-02, -6.2542e-02, -1.4618e-02,\n",
       "                       -7.1429e-02,  7.5726e-02,  2.1633e-02, -6.1033e-02, -4.6572e-02,\n",
       "                        8.6292e-02, -3.8168e-02, -6.5036e-02, -1.9933e-02,  5.1476e-02,\n",
       "                        5.4304e-02, -8.7375e-03,  2.0619e-02, -5.5197e-02, -2.1786e-02,\n",
       "                        6.6220e-03,  1.0532e-02,  6.9504e-02, -1.6402e-02, -3.6029e-02,\n",
       "                        2.3716e-02, -7.4748e-02, -7.2474e-02,  5.3108e-02,  1.4273e-02,\n",
       "                        2.7380e-02, -7.9259e-02,  2.7436e-02,  2.9061e-03, -6.1389e-02,\n",
       "                       -1.9814e-02,  4.4964e-02,  1.2721e-02,  5.1039e-02, -3.6965e-02,\n",
       "                        2.1363e-03, -6.0489e-02,  3.4726e-02,  4.1739e-03,  8.4060e-02,\n",
       "                        2.7472e-03, -7.6328e-02,  8.3682e-02,  3.8259e-02, -8.4644e-02,\n",
       "                        3.8295e-02,  3.6923e-02,  8.5234e-02,  4.9698e-02, -3.0554e-03,\n",
       "                       -4.9519e-02, -3.1398e-02, -3.7005e-02, -2.1562e-02,  8.1393e-02,\n",
       "                        3.7149e-02,  1.6424e-02, -3.0259e-02,  7.0496e-02,  2.1308e-02,\n",
       "                       -5.0191e-02, -8.3477e-02,  4.8129e-02,  3.7815e-02,  6.4810e-02,\n",
       "                        3.9563e-02, -2.4423e-02, -8.0182e-02,  1.8168e-02,  7.6636e-02,\n",
       "                       -7.1774e-03, -5.5596e-03, -1.8374e-02,  6.2613e-02,  4.5536e-02,\n",
       "                       -3.8747e-03,  6.2304e-02, -8.9134e-02, -8.6802e-03,  2.5292e-02,\n",
       "                        4.5518e-02,  1.4344e-02, -2.0183e-03, -3.1357e-02,  4.7621e-02,\n",
       "                        1.9850e-02, -8.6539e-02,  7.7353e-02, -8.3349e-02,  1.3990e-02,\n",
       "                       -1.8320e-02,  8.6543e-02, -2.1271e-02]])),\n",
       "             ('nodes.0.callable.block.h_net.4.linear.linear.weight',\n",
       "              tensor([[-3.5173e-02, -4.4497e-02,  7.6588e-02,  8.7364e-02, -3.0043e-02,\n",
       "                       -3.0896e-02, -8.4616e-03,  2.8905e-02, -2.8570e-02, -3.3212e-02,\n",
       "                        5.6230e-02,  4.5418e-02, -2.8192e-02, -7.9891e-02,  6.9862e-03,\n",
       "                        7.9683e-02, -8.2534e-02,  8.7352e-02,  1.7975e-02,  6.6818e-02,\n",
       "                        8.5050e-02,  5.1660e-03,  2.0489e-02, -7.1080e-02,  7.1861e-02,\n",
       "                        3.8066e-02, -8.0860e-02,  1.5288e-02,  2.9383e-02, -7.4320e-02,\n",
       "                        4.0873e-02, -1.4628e-02,  3.5897e-03,  2.5661e-02,  7.4784e-02,\n",
       "                        6.9696e-02,  5.4568e-02, -3.5123e-02, -5.0126e-02,  4.6214e-02,\n",
       "                       -6.0590e-02, -2.4355e-02,  2.8358e-02, -8.6546e-02,  7.5329e-02,\n",
       "                       -4.4725e-02, -5.4368e-03,  4.9333e-02, -5.4701e-03, -5.6535e-02,\n",
       "                        6.4362e-02, -3.0461e-02, -2.7679e-02, -6.8422e-02,  3.8520e-02,\n",
       "                        8.8863e-02,  5.8934e-02, -5.2553e-02, -1.9937e-03, -3.3308e-02,\n",
       "                        2.5772e-02, -4.5756e-02,  7.6201e-02, -8.5146e-02,  8.0813e-02,\n",
       "                        3.2469e-02,  3.5142e-02,  7.5318e-02, -8.0324e-02, -4.2704e-02,\n",
       "                       -5.0220e-02, -4.5527e-02, -5.8403e-02, -2.7684e-02,  5.7041e-02,\n",
       "                       -6.7524e-02,  5.2480e-02, -1.1037e-02, -4.9907e-03, -3.4826e-02,\n",
       "                        6.6565e-02, -2.5812e-02,  8.2166e-02, -1.8024e-02, -3.5590e-02,\n",
       "                       -4.6999e-02,  4.9579e-03,  1.9043e-03, -2.9053e-02, -3.4134e-02,\n",
       "                        2.6952e-02,  7.3200e-02,  5.5778e-02,  3.9315e-02,  7.7335e-02,\n",
       "                       -3.6789e-02,  4.0438e-02,  7.4670e-02, -8.5703e-02, -2.4556e-02,\n",
       "                       -2.4254e-02,  1.2562e-02,  8.7053e-02,  7.1992e-02, -1.9526e-02,\n",
       "                       -3.1892e-02,  1.1520e-02, -8.0788e-02,  3.2398e-02, -7.0177e-02,\n",
       "                       -4.4256e-02,  2.4456e-02, -7.6879e-02,  7.3001e-02, -9.8512e-03,\n",
       "                       -8.0124e-02,  7.0135e-02, -5.0165e-03, -1.8186e-03,  3.1613e-02,\n",
       "                        5.8455e-02,  5.8285e-02, -5.1941e-03, -3.0671e-02,  4.1575e-02,\n",
       "                        4.8770e-02,  2.7136e-02,  1.8483e-02],\n",
       "                      [-8.8813e-02, -3.1939e-02,  6.3231e-02,  3.7498e-02,  2.5346e-02,\n",
       "                       -5.7532e-02,  5.2633e-02, -3.8021e-02,  3.4746e-02,  2.8866e-03,\n",
       "                       -5.3474e-03, -3.7500e-02,  3.1217e-02,  7.5727e-02, -7.7679e-02,\n",
       "                        3.3901e-02,  1.2616e-02, -3.0250e-03,  7.5394e-02,  1.0348e-03,\n",
       "                        6.6114e-02, -2.9402e-02, -3.8780e-02,  5.0307e-02, -3.9238e-02,\n",
       "                        5.9846e-02,  2.6639e-02, -2.3566e-02,  7.4350e-02, -9.5251e-03,\n",
       "                        3.7650e-02,  7.6840e-02,  3.9021e-02, -6.7876e-02,  4.5737e-02,\n",
       "                       -3.7581e-02,  6.4928e-02,  3.0489e-02,  6.4631e-03,  3.9733e-02,\n",
       "                       -9.4973e-03,  7.9075e-02,  8.1284e-02, -8.7261e-02, -2.6156e-02,\n",
       "                        3.2298e-02, -1.7671e-02,  7.8102e-03, -6.9917e-02, -1.4941e-02,\n",
       "                        1.5037e-02,  7.5266e-02,  5.1356e-02, -6.5954e-02, -6.7302e-02,\n",
       "                        2.8777e-02, -2.5524e-02, -6.0648e-02,  1.1465e-03, -5.1034e-02,\n",
       "                        3.6473e-02, -7.6575e-02, -4.7485e-02, -9.6462e-03, -8.3178e-02,\n",
       "                        8.3369e-02, -4.4991e-02, -2.8951e-02,  3.3293e-02, -1.5229e-02,\n",
       "                       -2.8867e-02,  1.6033e-04, -3.8920e-02, -6.6510e-02,  6.4069e-02,\n",
       "                       -3.1382e-03, -5.4341e-02,  1.7948e-02, -6.0823e-02,  8.1369e-02,\n",
       "                       -2.2022e-02, -4.8792e-03, -8.7676e-02, -7.9658e-02,  7.7293e-02,\n",
       "                       -1.7380e-02, -6.2316e-02,  4.8458e-02, -4.0455e-02, -3.9774e-02,\n",
       "                        4.7649e-02,  6.4107e-02,  2.3936e-02,  4.9305e-02, -1.6919e-02,\n",
       "                       -3.0811e-02,  3.7338e-02,  3.0132e-02,  2.2192e-02,  5.2207e-02,\n",
       "                        3.4541e-02,  2.2659e-02,  5.4383e-02,  2.0541e-02,  3.7585e-02,\n",
       "                        5.2715e-02, -3.6520e-02, -6.5783e-02,  8.1290e-02,  1.9503e-02,\n",
       "                       -5.6536e-02, -4.3634e-02, -7.5881e-02, -1.9798e-02,  7.5605e-02,\n",
       "                        3.2974e-03,  8.2184e-02,  2.7088e-02, -2.2324e-02, -8.6834e-02,\n",
       "                       -1.8462e-02,  7.1073e-02, -2.5805e-02,  8.2875e-02,  1.9377e-02,\n",
       "                       -3.5830e-02, -8.7623e-02,  7.9965e-02],\n",
       "                      [-4.1164e-02,  3.5399e-02, -8.5207e-02,  8.8395e-02,  4.9713e-02,\n",
       "                       -3.7236e-03,  2.5451e-02,  2.8610e-02, -6.8137e-02,  7.0945e-02,\n",
       "                       -2.4770e-02, -3.9282e-02,  8.6827e-02,  6.1716e-02, -1.3392e-02,\n",
       "                       -1.9762e-02,  4.2546e-02, -5.9198e-02, -5.3806e-02, -6.0389e-02,\n",
       "                       -1.7704e-02, -7.4765e-03,  8.3521e-03,  2.4562e-02, -7.7878e-02,\n",
       "                       -4.5409e-02, -3.8038e-02, -5.7220e-02,  7.2765e-03,  4.3225e-02,\n",
       "                       -4.6584e-02,  1.2266e-02,  4.8149e-02, -5.4341e-02,  5.3271e-02,\n",
       "                        8.2987e-05,  6.2069e-03,  5.0989e-02,  3.1633e-02, -1.9848e-02,\n",
       "                       -2.0279e-03,  1.2764e-02, -1.7177e-02, -5.2193e-03,  2.9277e-02,\n",
       "                        8.5870e-02,  8.1618e-02,  3.5360e-02, -3.7607e-02, -5.6583e-02,\n",
       "                       -8.4119e-02,  1.8734e-02, -1.9390e-02, -1.1128e-02,  4.9184e-02,\n",
       "                        7.2864e-02, -1.3267e-02,  7.2239e-02,  3.6702e-02, -2.0602e-02,\n",
       "                        1.9982e-02,  7.9325e-02,  5.1899e-02,  1.5381e-02, -7.6492e-02,\n",
       "                       -1.9938e-02,  6.3239e-02,  2.6422e-02, -3.9926e-02,  6.0776e-02,\n",
       "                       -1.3594e-02, -6.9930e-02, -3.5426e-02, -7.6241e-02,  7.2722e-02,\n",
       "                        1.3603e-03, -2.1854e-02, -1.6625e-02,  6.3929e-02,  7.3812e-02,\n",
       "                        3.7637e-03, -5.6881e-02, -3.6950e-02, -7.1034e-02, -3.9190e-02,\n",
       "                        1.8264e-02,  6.6502e-02,  4.2458e-02, -9.6274e-03, -3.7336e-02,\n",
       "                       -4.7905e-02,  8.6262e-02,  8.5571e-03,  1.9700e-02, -5.9192e-02,\n",
       "                       -6.1123e-02, -8.6234e-02, -8.1519e-02,  3.4573e-02, -7.7321e-02,\n",
       "                       -6.4039e-02,  3.5563e-02,  4.0458e-02,  2.5201e-04, -3.2272e-02,\n",
       "                        7.6549e-03,  6.6674e-02, -6.8912e-02,  2.4600e-02,  5.3329e-02,\n",
       "                       -1.5653e-02, -7.5966e-02,  6.8771e-02, -6.4565e-02,  1.9294e-02,\n",
       "                       -7.9938e-02,  8.3194e-02,  1.8674e-02, -1.6295e-02,  9.4552e-04,\n",
       "                       -4.5627e-02,  5.8777e-02, -4.2428e-02, -8.6817e-02,  8.7773e-02,\n",
       "                       -1.8653e-02, -8.3102e-02, -8.7194e-02],\n",
       "                      [-4.2778e-02, -7.5762e-02, -6.3562e-02, -5.3086e-02, -7.5959e-02,\n",
       "                       -4.4555e-02, -7.1359e-02,  5.8299e-02, -7.3987e-02,  6.8683e-02,\n",
       "                        2.3010e-02, -3.7479e-02, -6.0253e-02,  8.5548e-02,  2.0121e-03,\n",
       "                       -3.0045e-02,  8.5122e-03, -2.0209e-03,  2.6082e-02,  4.1748e-02,\n",
       "                       -5.7912e-02,  2.6891e-02, -7.2411e-02, -6.7645e-02, -4.3058e-02,\n",
       "                       -6.7384e-02, -2.2633e-02,  7.0010e-02, -3.2614e-02,  7.6523e-02,\n",
       "                       -4.8604e-02, -5.2599e-02, -5.8937e-02, -6.2542e-02, -1.4618e-02,\n",
       "                       -7.1429e-02,  7.5726e-02,  2.1633e-02, -6.1033e-02, -4.6572e-02,\n",
       "                        8.6292e-02, -3.8168e-02, -6.5036e-02, -1.9933e-02,  5.1476e-02,\n",
       "                        5.4304e-02, -8.7375e-03,  2.0619e-02, -5.5197e-02, -2.1786e-02,\n",
       "                        6.6220e-03,  1.0532e-02,  6.9504e-02, -1.6402e-02, -3.6029e-02,\n",
       "                        2.3716e-02, -7.4748e-02, -7.2474e-02,  5.3108e-02,  1.4273e-02,\n",
       "                        2.7380e-02, -7.9259e-02,  2.7436e-02,  2.9061e-03, -6.1389e-02,\n",
       "                       -1.9814e-02,  4.4964e-02,  1.2721e-02,  5.1039e-02, -3.6965e-02,\n",
       "                        2.1363e-03, -6.0489e-02,  3.4726e-02,  4.1739e-03,  8.4060e-02,\n",
       "                        2.7472e-03, -7.6328e-02,  8.3682e-02,  3.8259e-02, -8.4644e-02,\n",
       "                        3.8295e-02,  3.6923e-02,  8.5234e-02,  4.9698e-02, -3.0554e-03,\n",
       "                       -4.9519e-02, -3.1398e-02, -3.7005e-02, -2.1562e-02,  8.1393e-02,\n",
       "                        3.7149e-02,  1.6424e-02, -3.0259e-02,  7.0496e-02,  2.1308e-02,\n",
       "                       -5.0191e-02, -8.3477e-02,  4.8129e-02,  3.7815e-02,  6.4810e-02,\n",
       "                        3.9563e-02, -2.4423e-02, -8.0182e-02,  1.8168e-02,  7.6636e-02,\n",
       "                       -7.1774e-03, -5.5596e-03, -1.8374e-02,  6.2613e-02,  4.5536e-02,\n",
       "                       -3.8747e-03,  6.2304e-02, -8.9134e-02, -8.6802e-03,  2.5292e-02,\n",
       "                        4.5518e-02,  1.4344e-02, -2.0183e-03, -3.1357e-02,  4.7621e-02,\n",
       "                        1.9850e-02, -8.6539e-02,  7.7353e-02, -8.3349e-02,  1.3990e-02,\n",
       "                       -1.8320e-02,  8.6543e-02, -2.1271e-02]])),\n",
       "             ('nodes.0.callable.block.h_net.4.linear.linear.bias',\n",
       "              tensor([-0.0594, -0.0401, -0.0831, -0.0804])),\n",
       "             ('nodes.0.callable.block.g_nets.0.0.linear.bias',\n",
       "              tensor([ 0.8719, -0.5928, -0.2220, -0.2942, -0.5823,  0.5652,  0.6625, -0.0988,\n",
       "                       0.8076, -0.9507,  0.0139, -0.0230,  0.7812,  0.9168,  0.5851,  0.2578,\n",
       "                       0.5045, -0.9735, -0.5704,  0.3164, -0.9335, -0.2155, -0.1093, -0.7253,\n",
       "                       0.6443,  0.5655,  0.5040,  0.8119, -0.3732, -0.0869,  0.8706, -0.1401,\n",
       "                      -0.4133, -0.6334, -0.4885,  0.1730, -0.8028,  0.7474, -0.3976, -0.7205,\n",
       "                       0.8384, -0.7916, -0.0498,  0.5542,  0.5798, -0.8868,  0.1533, -0.7674,\n",
       "                       0.7703,  0.6656, -0.6058, -0.8733, -0.4588,  0.8728,  0.2281,  0.0740,\n",
       "                       0.4866,  0.5676,  0.6801,  0.3468,  0.8101,  0.5554, -0.1504, -0.1039,\n",
       "                      -0.6490, -0.6264, -0.9952,  0.1691, -0.1566,  0.4056,  0.8137, -0.3091,\n",
       "                       0.1988,  0.6479, -0.3408, -0.3272,  0.4110,  0.2674,  0.6759, -0.3747,\n",
       "                      -0.9640,  0.8295,  0.9447,  0.1164,  0.7888, -0.9975,  0.0798,  0.0712,\n",
       "                       0.0366, -0.3415,  0.3490, -0.7132, -0.3973, -0.4713, -0.4932, -0.4590,\n",
       "                       0.6773, -0.2633,  0.0323,  0.5725, -0.0177, -0.5563,  0.3635,  0.2645,\n",
       "                       0.9551, -0.0815,  0.3365,  0.6167, -0.6075,  0.6816,  0.3472,  0.1774,\n",
       "                       0.6817,  0.2630, -0.0297,  0.5164,  0.3582, -0.0800, -0.5703,  0.9018,\n",
       "                       0.2686,  0.5089, -0.1319,  0.3270, -0.5485, -0.4628, -0.1080, -0.9905])),\n",
       "             ('nodes.0.callable.block.g_nets.0.0.linear.weight',\n",
       "              tensor([[-0.0604],\n",
       "                      [-0.2595],\n",
       "                      [-0.7095],\n",
       "                      [ 0.7691],\n",
       "                      [ 0.9439],\n",
       "                      [-0.1748],\n",
       "                      [ 0.8309],\n",
       "                      [ 0.6955],\n",
       "                      [ 0.6045],\n",
       "                      [ 0.0861],\n",
       "                      [ 0.5480],\n",
       "                      [ 0.9440],\n",
       "                      [ 0.8976],\n",
       "                      [-0.6451],\n",
       "                      [ 0.3643],\n",
       "                      [-0.6844],\n",
       "                      [ 0.1120],\n",
       "                      [-0.0171],\n",
       "                      [ 0.9895],\n",
       "                      [ 0.4759],\n",
       "                      [ 0.7581],\n",
       "                      [ 0.4293],\n",
       "                      [ 0.6547],\n",
       "                      [-0.7654],\n",
       "                      [ 0.7950],\n",
       "                      [ 0.4838],\n",
       "                      [-0.3691],\n",
       "                      [-0.0330],\n",
       "                      [ 0.3129],\n",
       "                      [ 0.6342],\n",
       "                      [ 0.6567],\n",
       "                      [ 0.2114],\n",
       "                      [ 0.1438],\n",
       "                      [-0.9687],\n",
       "                      [ 0.6545],\n",
       "                      [-0.2865],\n",
       "                      [-0.6670],\n",
       "                      [-0.8978],\n",
       "                      [-0.8701],\n",
       "                      [ 0.2884],\n",
       "                      [ 0.4550],\n",
       "                      [-0.3673],\n",
       "                      [-0.5588],\n",
       "                      [ 0.9010],\n",
       "                      [ 0.5074],\n",
       "                      [-0.2230],\n",
       "                      [-0.4315],\n",
       "                      [-0.5367],\n",
       "                      [-0.8501],\n",
       "                      [ 0.2345],\n",
       "                      [ 0.2152],\n",
       "                      [-0.9137],\n",
       "                      [-0.2439],\n",
       "                      [-0.6810],\n",
       "                      [ 0.6143],\n",
       "                      [ 0.5012],\n",
       "                      [ 0.4367],\n",
       "                      [ 0.6279],\n",
       "                      [ 0.4766],\n",
       "                      [ 0.1953],\n",
       "                      [-0.9760],\n",
       "                      [-0.6892],\n",
       "                      [ 0.5969],\n",
       "                      [ 0.2126],\n",
       "                      [-0.9771],\n",
       "                      [-0.2792],\n",
       "                      [ 0.0926],\n",
       "                      [ 0.1253],\n",
       "                      [ 0.9073],\n",
       "                      [ 0.0433],\n",
       "                      [-0.7782],\n",
       "                      [-0.0390],\n",
       "                      [ 0.4275],\n",
       "                      [-0.6121],\n",
       "                      [-0.3538],\n",
       "                      [-0.4750],\n",
       "                      [-0.0207],\n",
       "                      [-0.6547],\n",
       "                      [ 0.5994],\n",
       "                      [ 0.6774],\n",
       "                      [-0.3237],\n",
       "                      [-0.7169],\n",
       "                      [ 0.0465],\n",
       "                      [ 0.7459],\n",
       "                      [-0.7677],\n",
       "                      [ 0.6274],\n",
       "                      [-0.1345],\n",
       "                      [ 0.9629],\n",
       "                      [ 0.7551],\n",
       "                      [ 0.0847],\n",
       "                      [ 0.5325],\n",
       "                      [ 0.6947],\n",
       "                      [-0.5218],\n",
       "                      [ 0.4180],\n",
       "                      [ 0.8539],\n",
       "                      [-0.4468],\n",
       "                      [ 0.7126],\n",
       "                      [ 0.7571],\n",
       "                      [ 0.2503],\n",
       "                      [-0.2217],\n",
       "                      [ 0.9955],\n",
       "                      [ 0.9798],\n",
       "                      [-0.6207],\n",
       "                      [-0.2727],\n",
       "                      [ 0.8117],\n",
       "                      [-0.8449],\n",
       "                      [ 0.5515],\n",
       "                      [ 0.9719],\n",
       "                      [ 0.1830],\n",
       "                      [ 0.0410],\n",
       "                      [-0.4665],\n",
       "                      [ 0.0939],\n",
       "                      [ 0.7530],\n",
       "                      [-0.1801],\n",
       "                      [ 0.8488],\n",
       "                      [-0.5951],\n",
       "                      [-0.2707],\n",
       "                      [ 0.4340],\n",
       "                      [ 0.0745],\n",
       "                      [ 0.4964],\n",
       "                      [-0.4304],\n",
       "                      [-0.1868],\n",
       "                      [ 0.9001],\n",
       "                      [ 0.4505],\n",
       "                      [-0.5393],\n",
       "                      [-0.0595],\n",
       "                      [-0.8835],\n",
       "                      [ 0.8599]])),\n",
       "             ('nodes.0.callable.block.g_nets.0.0.linear.linear.weight',\n",
       "              tensor([[-0.0604],\n",
       "                      [-0.2595],\n",
       "                      [-0.7095],\n",
       "                      [ 0.7691],\n",
       "                      [ 0.9439],\n",
       "                      [-0.1748],\n",
       "                      [ 0.8309],\n",
       "                      [ 0.6955],\n",
       "                      [ 0.6045],\n",
       "                      [ 0.0861],\n",
       "                      [ 0.5480],\n",
       "                      [ 0.9440],\n",
       "                      [ 0.8976],\n",
       "                      [-0.6451],\n",
       "                      [ 0.3643],\n",
       "                      [-0.6844],\n",
       "                      [ 0.1120],\n",
       "                      [-0.0171],\n",
       "                      [ 0.9895],\n",
       "                      [ 0.4759],\n",
       "                      [ 0.7581],\n",
       "                      [ 0.4293],\n",
       "                      [ 0.6547],\n",
       "                      [-0.7654],\n",
       "                      [ 0.7950],\n",
       "                      [ 0.4838],\n",
       "                      [-0.3691],\n",
       "                      [-0.0330],\n",
       "                      [ 0.3129],\n",
       "                      [ 0.6342],\n",
       "                      [ 0.6567],\n",
       "                      [ 0.2114],\n",
       "                      [ 0.1438],\n",
       "                      [-0.9687],\n",
       "                      [ 0.6545],\n",
       "                      [-0.2865],\n",
       "                      [-0.6670],\n",
       "                      [-0.8978],\n",
       "                      [-0.8701],\n",
       "                      [ 0.2884],\n",
       "                      [ 0.4550],\n",
       "                      [-0.3673],\n",
       "                      [-0.5588],\n",
       "                      [ 0.9010],\n",
       "                      [ 0.5074],\n",
       "                      [-0.2230],\n",
       "                      [-0.4315],\n",
       "                      [-0.5367],\n",
       "                      [-0.8501],\n",
       "                      [ 0.2345],\n",
       "                      [ 0.2152],\n",
       "                      [-0.9137],\n",
       "                      [-0.2439],\n",
       "                      [-0.6810],\n",
       "                      [ 0.6143],\n",
       "                      [ 0.5012],\n",
       "                      [ 0.4367],\n",
       "                      [ 0.6279],\n",
       "                      [ 0.4766],\n",
       "                      [ 0.1953],\n",
       "                      [-0.9760],\n",
       "                      [-0.6892],\n",
       "                      [ 0.5969],\n",
       "                      [ 0.2126],\n",
       "                      [-0.9771],\n",
       "                      [-0.2792],\n",
       "                      [ 0.0926],\n",
       "                      [ 0.1253],\n",
       "                      [ 0.9073],\n",
       "                      [ 0.0433],\n",
       "                      [-0.7782],\n",
       "                      [-0.0390],\n",
       "                      [ 0.4275],\n",
       "                      [-0.6121],\n",
       "                      [-0.3538],\n",
       "                      [-0.4750],\n",
       "                      [-0.0207],\n",
       "                      [-0.6547],\n",
       "                      [ 0.5994],\n",
       "                      [ 0.6774],\n",
       "                      [-0.3237],\n",
       "                      [-0.7169],\n",
       "                      [ 0.0465],\n",
       "                      [ 0.7459],\n",
       "                      [-0.7677],\n",
       "                      [ 0.6274],\n",
       "                      [-0.1345],\n",
       "                      [ 0.9629],\n",
       "                      [ 0.7551],\n",
       "                      [ 0.0847],\n",
       "                      [ 0.5325],\n",
       "                      [ 0.6947],\n",
       "                      [-0.5218],\n",
       "                      [ 0.4180],\n",
       "                      [ 0.8539],\n",
       "                      [-0.4468],\n",
       "                      [ 0.7126],\n",
       "                      [ 0.7571],\n",
       "                      [ 0.2503],\n",
       "                      [-0.2217],\n",
       "                      [ 0.9955],\n",
       "                      [ 0.9798],\n",
       "                      [-0.6207],\n",
       "                      [-0.2727],\n",
       "                      [ 0.8117],\n",
       "                      [-0.8449],\n",
       "                      [ 0.5515],\n",
       "                      [ 0.9719],\n",
       "                      [ 0.1830],\n",
       "                      [ 0.0410],\n",
       "                      [-0.4665],\n",
       "                      [ 0.0939],\n",
       "                      [ 0.7530],\n",
       "                      [-0.1801],\n",
       "                      [ 0.8488],\n",
       "                      [-0.5951],\n",
       "                      [-0.2707],\n",
       "                      [ 0.4340],\n",
       "                      [ 0.0745],\n",
       "                      [ 0.4964],\n",
       "                      [-0.4304],\n",
       "                      [-0.1868],\n",
       "                      [ 0.9001],\n",
       "                      [ 0.4505],\n",
       "                      [-0.5393],\n",
       "                      [-0.0595],\n",
       "                      [-0.8835],\n",
       "                      [ 0.8599]])),\n",
       "             ('nodes.0.callable.block.g_nets.0.0.linear.linear.bias',\n",
       "              tensor([ 0.8719, -0.5928, -0.2220, -0.2942, -0.5823,  0.5652,  0.6625, -0.0988,\n",
       "                       0.8076, -0.9507,  0.0139, -0.0230,  0.7812,  0.9168,  0.5851,  0.2578,\n",
       "                       0.5045, -0.9735, -0.5704,  0.3164, -0.9335, -0.2155, -0.1093, -0.7253,\n",
       "                       0.6443,  0.5655,  0.5040,  0.8119, -0.3732, -0.0869,  0.8706, -0.1401,\n",
       "                      -0.4133, -0.6334, -0.4885,  0.1730, -0.8028,  0.7474, -0.3976, -0.7205,\n",
       "                       0.8384, -0.7916, -0.0498,  0.5542,  0.5798, -0.8868,  0.1533, -0.7674,\n",
       "                       0.7703,  0.6656, -0.6058, -0.8733, -0.4588,  0.8728,  0.2281,  0.0740,\n",
       "                       0.4866,  0.5676,  0.6801,  0.3468,  0.8101,  0.5554, -0.1504, -0.1039,\n",
       "                      -0.6490, -0.6264, -0.9952,  0.1691, -0.1566,  0.4056,  0.8137, -0.3091,\n",
       "                       0.1988,  0.6479, -0.3408, -0.3272,  0.4110,  0.2674,  0.6759, -0.3747,\n",
       "                      -0.9640,  0.8295,  0.9447,  0.1164,  0.7888, -0.9975,  0.0798,  0.0712,\n",
       "                       0.0366, -0.3415,  0.3490, -0.7132, -0.3973, -0.4713, -0.4932, -0.4590,\n",
       "                       0.6773, -0.2633,  0.0323,  0.5725, -0.0177, -0.5563,  0.3635,  0.2645,\n",
       "                       0.9551, -0.0815,  0.3365,  0.6167, -0.6075,  0.6816,  0.3472,  0.1774,\n",
       "                       0.6817,  0.2630, -0.0297,  0.5164,  0.3582, -0.0800, -0.5703,  0.9018,\n",
       "                       0.2686,  0.5089, -0.1319,  0.3270, -0.5485, -0.4628, -0.1080, -0.9905])),\n",
       "             ('nodes.0.callable.block.g_nets.0.2.linear.bias',\n",
       "              tensor([-0.0137])),\n",
       "             ('nodes.0.callable.block.g_nets.0.2.linear.weight',\n",
       "              tensor([[-0.0304, -0.0024,  0.0312,  0.0050,  0.0561, -0.0302, -0.0391, -0.0767,\n",
       "                       -0.0202,  0.0454,  0.0597, -0.0718, -0.0449,  0.0784, -0.0694, -0.0410,\n",
       "                        0.0496,  0.0756,  0.0094, -0.0652,  0.0515, -0.0536, -0.0711,  0.0142,\n",
       "                        0.0366,  0.0110, -0.0130,  0.0713,  0.0564, -0.0829,  0.0607, -0.0732,\n",
       "                       -0.0007, -0.0033, -0.0561, -0.0057,  0.0735, -0.0077,  0.0619,  0.0720,\n",
       "                       -0.0824, -0.0322,  0.0581,  0.0250,  0.0441, -0.0147, -0.0631, -0.0759,\n",
       "                       -0.0014,  0.0358, -0.0240,  0.0145,  0.0681, -0.0413,  0.0697,  0.0251,\n",
       "                        0.0839, -0.0837,  0.0716,  0.0452,  0.0343, -0.0492, -0.0602, -0.0508,\n",
       "                        0.0800, -0.0785, -0.0635, -0.0584, -0.0452,  0.0270, -0.0235, -0.0191,\n",
       "                        0.0104,  0.0738, -0.0632, -0.0289, -0.0546, -0.0511, -0.0600, -0.0029,\n",
       "                       -0.0463,  0.0803,  0.0236,  0.0367,  0.0806,  0.0237,  0.0353, -0.0170,\n",
       "                        0.0746, -0.0705, -0.0341, -0.0263,  0.0275,  0.0431, -0.0005, -0.0189,\n",
       "                        0.0379, -0.0399,  0.0486, -0.0606,  0.0036,  0.0650,  0.0160, -0.0258,\n",
       "                        0.0665,  0.0068, -0.0581, -0.0645,  0.0060, -0.0709,  0.0549, -0.0775,\n",
       "                       -0.0021,  0.0095, -0.0638, -0.0706,  0.0191, -0.0416, -0.0876, -0.0029,\n",
       "                       -0.0581,  0.0359, -0.0384, -0.0332, -0.0296,  0.0052,  0.0435, -0.0387]])),\n",
       "             ('nodes.0.callable.block.g_nets.0.2.linear.linear.weight',\n",
       "              tensor([[-0.0304, -0.0024,  0.0312,  0.0050,  0.0561, -0.0302, -0.0391, -0.0767,\n",
       "                       -0.0202,  0.0454,  0.0597, -0.0718, -0.0449,  0.0784, -0.0694, -0.0410,\n",
       "                        0.0496,  0.0756,  0.0094, -0.0652,  0.0515, -0.0536, -0.0711,  0.0142,\n",
       "                        0.0366,  0.0110, -0.0130,  0.0713,  0.0564, -0.0829,  0.0607, -0.0732,\n",
       "                       -0.0007, -0.0033, -0.0561, -0.0057,  0.0735, -0.0077,  0.0619,  0.0720,\n",
       "                       -0.0824, -0.0322,  0.0581,  0.0250,  0.0441, -0.0147, -0.0631, -0.0759,\n",
       "                       -0.0014,  0.0358, -0.0240,  0.0145,  0.0681, -0.0413,  0.0697,  0.0251,\n",
       "                        0.0839, -0.0837,  0.0716,  0.0452,  0.0343, -0.0492, -0.0602, -0.0508,\n",
       "                        0.0800, -0.0785, -0.0635, -0.0584, -0.0452,  0.0270, -0.0235, -0.0191,\n",
       "                        0.0104,  0.0738, -0.0632, -0.0289, -0.0546, -0.0511, -0.0600, -0.0029,\n",
       "                       -0.0463,  0.0803,  0.0236,  0.0367,  0.0806,  0.0237,  0.0353, -0.0170,\n",
       "                        0.0746, -0.0705, -0.0341, -0.0263,  0.0275,  0.0431, -0.0005, -0.0189,\n",
       "                        0.0379, -0.0399,  0.0486, -0.0606,  0.0036,  0.0650,  0.0160, -0.0258,\n",
       "                        0.0665,  0.0068, -0.0581, -0.0645,  0.0060, -0.0709,  0.0549, -0.0775,\n",
       "                       -0.0021,  0.0095, -0.0638, -0.0706,  0.0191, -0.0416, -0.0876, -0.0029,\n",
       "                       -0.0581,  0.0359, -0.0384, -0.0332, -0.0296,  0.0052,  0.0435, -0.0387]])),\n",
       "             ('nodes.0.callable.block.g_nets.0.2.linear.linear.bias',\n",
       "              tensor([-0.0137])),\n",
       "             ('nodes.0.callable.block.g_nets.1.0.linear.bias',\n",
       "              tensor([ 0.6809,  0.8099, -0.7239,  0.1361, -0.2931, -0.6455,  0.6201, -0.0733,\n",
       "                       0.2914,  0.1359,  0.5410, -0.9833, -0.4615,  0.4596, -0.0629,  0.9110,\n",
       "                       0.8119, -0.8466,  0.7345,  0.9456, -0.0322, -0.8456,  0.0096,  0.6786,\n",
       "                      -0.7712,  0.8633, -0.8676,  0.1358,  0.4614,  0.2487,  0.0831, -0.9337,\n",
       "                       0.4135,  0.7983,  0.7652,  0.8159,  0.9266,  0.5615, -0.1535, -0.4702,\n",
       "                      -0.6331, -0.5769,  0.2032,  0.2097, -0.1176,  0.7594,  0.0988,  0.7649,\n",
       "                       0.5232,  0.7757,  0.6184, -0.0489,  0.7100, -0.0457,  0.9430, -0.9041,\n",
       "                       0.8673, -0.3526, -0.1889,  0.7438,  0.3822, -0.8128, -0.7587,  0.1356,\n",
       "                       0.7732,  0.7354,  0.4914,  0.5181, -0.8850, -0.2812, -0.7738, -0.4303,\n",
       "                      -0.3862, -0.2121, -0.8252, -0.2955, -0.5636, -0.7818,  0.8057, -0.4077,\n",
       "                       0.1616, -0.7625,  0.0147,  0.8300, -0.4439,  0.7425, -0.6416,  0.5878,\n",
       "                       0.7172, -0.1685,  0.0530, -0.8015,  0.7588,  0.0831,  0.2909, -0.2576,\n",
       "                       0.1835, -0.6512,  0.3494,  0.7953, -0.5676, -0.7121, -0.3359, -0.5831,\n",
       "                      -0.0474,  0.9354,  0.8653,  0.4916,  0.2172,  0.4020, -0.9711, -0.1862,\n",
       "                       0.1240, -0.8300,  0.8106,  0.9512,  0.9149, -0.1162, -0.0766,  0.3353,\n",
       "                       0.5959, -0.6846, -0.2559,  0.4911, -0.8649,  0.0031,  0.5051, -0.0258])),\n",
       "             ('nodes.0.callable.block.g_nets.1.0.linear.weight',\n",
       "              tensor([[ 0.1051],\n",
       "                      [-0.0797],\n",
       "                      [ 0.4023],\n",
       "                      [-0.2524],\n",
       "                      [-0.4666],\n",
       "                      [ 0.7697],\n",
       "                      [ 0.6464],\n",
       "                      [-0.9619],\n",
       "                      [ 0.5630],\n",
       "                      [-0.6981],\n",
       "                      [-0.3220],\n",
       "                      [-0.5624],\n",
       "                      [-0.5850],\n",
       "                      [ 0.4425],\n",
       "                      [-0.5330],\n",
       "                      [-0.6235],\n",
       "                      [-0.0367],\n",
       "                      [-0.1825],\n",
       "                      [ 0.9624],\n",
       "                      [ 0.7058],\n",
       "                      [-0.0412],\n",
       "                      [ 0.0039],\n",
       "                      [ 0.3710],\n",
       "                      [-0.2842],\n",
       "                      [ 0.1117],\n",
       "                      [-0.3324],\n",
       "                      [-0.0609],\n",
       "                      [ 0.8822],\n",
       "                      [ 0.7206],\n",
       "                      [ 0.6779],\n",
       "                      [-0.7185],\n",
       "                      [-0.6956],\n",
       "                      [ 0.2935],\n",
       "                      [-0.0367],\n",
       "                      [ 0.6971],\n",
       "                      [ 0.3381],\n",
       "                      [ 0.4350],\n",
       "                      [-0.8355],\n",
       "                      [ 0.7674],\n",
       "                      [ 0.3898],\n",
       "                      [ 0.4570],\n",
       "                      [ 0.1938],\n",
       "                      [ 0.8753],\n",
       "                      [-0.2216],\n",
       "                      [ 0.2815],\n",
       "                      [-0.9136],\n",
       "                      [-0.7925],\n",
       "                      [-0.3841],\n",
       "                      [ 0.5880],\n",
       "                      [-0.4898],\n",
       "                      [ 0.5569],\n",
       "                      [-0.8268],\n",
       "                      [-0.8295],\n",
       "                      [-0.3022],\n",
       "                      [-0.3755],\n",
       "                      [-0.1153],\n",
       "                      [-0.3942],\n",
       "                      [-0.9634],\n",
       "                      [ 0.7764],\n",
       "                      [ 0.4422],\n",
       "                      [ 0.8228],\n",
       "                      [-0.2901],\n",
       "                      [-0.8695],\n",
       "                      [ 0.5279],\n",
       "                      [-0.3353],\n",
       "                      [ 0.7738],\n",
       "                      [ 0.8594],\n",
       "                      [ 0.9213],\n",
       "                      [ 0.8840],\n",
       "                      [ 0.6581],\n",
       "                      [-0.3214],\n",
       "                      [ 0.0018],\n",
       "                      [ 0.3860],\n",
       "                      [ 0.5440],\n",
       "                      [-0.6471],\n",
       "                      [ 0.6810],\n",
       "                      [-0.0812],\n",
       "                      [ 0.9057],\n",
       "                      [ 0.4790],\n",
       "                      [ 0.9291],\n",
       "                      [ 0.3337],\n",
       "                      [-0.0854],\n",
       "                      [ 0.0816],\n",
       "                      [ 0.5386],\n",
       "                      [ 0.9261],\n",
       "                      [-0.0972],\n",
       "                      [ 0.8834],\n",
       "                      [-0.7122],\n",
       "                      [ 0.1499],\n",
       "                      [ 0.1914],\n",
       "                      [-0.8041],\n",
       "                      [-0.9758],\n",
       "                      [ 0.3647],\n",
       "                      [-0.7873],\n",
       "                      [-0.1188],\n",
       "                      [ 0.7513],\n",
       "                      [ 0.5662],\n",
       "                      [-0.6882],\n",
       "                      [-0.8397],\n",
       "                      [-0.2506],\n",
       "                      [-0.5895],\n",
       "                      [-0.4055],\n",
       "                      [ 0.1900],\n",
       "                      [-0.4051],\n",
       "                      [-0.3194],\n",
       "                      [ 0.1973],\n",
       "                      [-0.0163],\n",
       "                      [-0.8008],\n",
       "                      [ 0.6201],\n",
       "                      [-0.7669],\n",
       "                      [ 0.1661],\n",
       "                      [ 0.0883],\n",
       "                      [ 0.1855],\n",
       "                      [ 0.6081],\n",
       "                      [-0.7902],\n",
       "                      [-0.1118],\n",
       "                      [-0.2077],\n",
       "                      [ 0.1415],\n",
       "                      [-0.7800],\n",
       "                      [ 0.5195],\n",
       "                      [ 0.1366],\n",
       "                      [ 0.4522],\n",
       "                      [-0.8314],\n",
       "                      [ 0.0468],\n",
       "                      [ 0.2299],\n",
       "                      [-0.8164],\n",
       "                      [ 0.2331],\n",
       "                      [ 0.6494]])),\n",
       "             ('nodes.0.callable.block.g_nets.1.0.linear.linear.weight',\n",
       "              tensor([[ 0.1051],\n",
       "                      [-0.0797],\n",
       "                      [ 0.4023],\n",
       "                      [-0.2524],\n",
       "                      [-0.4666],\n",
       "                      [ 0.7697],\n",
       "                      [ 0.6464],\n",
       "                      [-0.9619],\n",
       "                      [ 0.5630],\n",
       "                      [-0.6981],\n",
       "                      [-0.3220],\n",
       "                      [-0.5624],\n",
       "                      [-0.5850],\n",
       "                      [ 0.4425],\n",
       "                      [-0.5330],\n",
       "                      [-0.6235],\n",
       "                      [-0.0367],\n",
       "                      [-0.1825],\n",
       "                      [ 0.9624],\n",
       "                      [ 0.7058],\n",
       "                      [-0.0412],\n",
       "                      [ 0.0039],\n",
       "                      [ 0.3710],\n",
       "                      [-0.2842],\n",
       "                      [ 0.1117],\n",
       "                      [-0.3324],\n",
       "                      [-0.0609],\n",
       "                      [ 0.8822],\n",
       "                      [ 0.7206],\n",
       "                      [ 0.6779],\n",
       "                      [-0.7185],\n",
       "                      [-0.6956],\n",
       "                      [ 0.2935],\n",
       "                      [-0.0367],\n",
       "                      [ 0.6971],\n",
       "                      [ 0.3381],\n",
       "                      [ 0.4350],\n",
       "                      [-0.8355],\n",
       "                      [ 0.7674],\n",
       "                      [ 0.3898],\n",
       "                      [ 0.4570],\n",
       "                      [ 0.1938],\n",
       "                      [ 0.8753],\n",
       "                      [-0.2216],\n",
       "                      [ 0.2815],\n",
       "                      [-0.9136],\n",
       "                      [-0.7925],\n",
       "                      [-0.3841],\n",
       "                      [ 0.5880],\n",
       "                      [-0.4898],\n",
       "                      [ 0.5569],\n",
       "                      [-0.8268],\n",
       "                      [-0.8295],\n",
       "                      [-0.3022],\n",
       "                      [-0.3755],\n",
       "                      [-0.1153],\n",
       "                      [-0.3942],\n",
       "                      [-0.9634],\n",
       "                      [ 0.7764],\n",
       "                      [ 0.4422],\n",
       "                      [ 0.8228],\n",
       "                      [-0.2901],\n",
       "                      [-0.8695],\n",
       "                      [ 0.5279],\n",
       "                      [-0.3353],\n",
       "                      [ 0.7738],\n",
       "                      [ 0.8594],\n",
       "                      [ 0.9213],\n",
       "                      [ 0.8840],\n",
       "                      [ 0.6581],\n",
       "                      [-0.3214],\n",
       "                      [ 0.0018],\n",
       "                      [ 0.3860],\n",
       "                      [ 0.5440],\n",
       "                      [-0.6471],\n",
       "                      [ 0.6810],\n",
       "                      [-0.0812],\n",
       "                      [ 0.9057],\n",
       "                      [ 0.4790],\n",
       "                      [ 0.9291],\n",
       "                      [ 0.3337],\n",
       "                      [-0.0854],\n",
       "                      [ 0.0816],\n",
       "                      [ 0.5386],\n",
       "                      [ 0.9261],\n",
       "                      [-0.0972],\n",
       "                      [ 0.8834],\n",
       "                      [-0.7122],\n",
       "                      [ 0.1499],\n",
       "                      [ 0.1914],\n",
       "                      [-0.8041],\n",
       "                      [-0.9758],\n",
       "                      [ 0.3647],\n",
       "                      [-0.7873],\n",
       "                      [-0.1188],\n",
       "                      [ 0.7513],\n",
       "                      [ 0.5662],\n",
       "                      [-0.6882],\n",
       "                      [-0.8397],\n",
       "                      [-0.2506],\n",
       "                      [-0.5895],\n",
       "                      [-0.4055],\n",
       "                      [ 0.1900],\n",
       "                      [-0.4051],\n",
       "                      [-0.3194],\n",
       "                      [ 0.1973],\n",
       "                      [-0.0163],\n",
       "                      [-0.8008],\n",
       "                      [ 0.6201],\n",
       "                      [-0.7669],\n",
       "                      [ 0.1661],\n",
       "                      [ 0.0883],\n",
       "                      [ 0.1855],\n",
       "                      [ 0.6081],\n",
       "                      [-0.7902],\n",
       "                      [-0.1118],\n",
       "                      [-0.2077],\n",
       "                      [ 0.1415],\n",
       "                      [-0.7800],\n",
       "                      [ 0.5195],\n",
       "                      [ 0.1366],\n",
       "                      [ 0.4522],\n",
       "                      [-0.8314],\n",
       "                      [ 0.0468],\n",
       "                      [ 0.2299],\n",
       "                      [-0.8164],\n",
       "                      [ 0.2331],\n",
       "                      [ 0.6494]])),\n",
       "             ('nodes.0.callable.block.g_nets.1.0.linear.linear.bias',\n",
       "              tensor([ 0.6809,  0.8099, -0.7239,  0.1361, -0.2931, -0.6455,  0.6201, -0.0733,\n",
       "                       0.2914,  0.1359,  0.5410, -0.9833, -0.4615,  0.4596, -0.0629,  0.9110,\n",
       "                       0.8119, -0.8466,  0.7345,  0.9456, -0.0322, -0.8456,  0.0096,  0.6786,\n",
       "                      -0.7712,  0.8633, -0.8676,  0.1358,  0.4614,  0.2487,  0.0831, -0.9337,\n",
       "                       0.4135,  0.7983,  0.7652,  0.8159,  0.9266,  0.5615, -0.1535, -0.4702,\n",
       "                      -0.6331, -0.5769,  0.2032,  0.2097, -0.1176,  0.7594,  0.0988,  0.7649,\n",
       "                       0.5232,  0.7757,  0.6184, -0.0489,  0.7100, -0.0457,  0.9430, -0.9041,\n",
       "                       0.8673, -0.3526, -0.1889,  0.7438,  0.3822, -0.8128, -0.7587,  0.1356,\n",
       "                       0.7732,  0.7354,  0.4914,  0.5181, -0.8850, -0.2812, -0.7738, -0.4303,\n",
       "                      -0.3862, -0.2121, -0.8252, -0.2955, -0.5636, -0.7818,  0.8057, -0.4077,\n",
       "                       0.1616, -0.7625,  0.0147,  0.8300, -0.4439,  0.7425, -0.6416,  0.5878,\n",
       "                       0.7172, -0.1685,  0.0530, -0.8015,  0.7588,  0.0831,  0.2909, -0.2576,\n",
       "                       0.1835, -0.6512,  0.3494,  0.7953, -0.5676, -0.7121, -0.3359, -0.5831,\n",
       "                      -0.0474,  0.9354,  0.8653,  0.4916,  0.2172,  0.4020, -0.9711, -0.1862,\n",
       "                       0.1240, -0.8300,  0.8106,  0.9512,  0.9149, -0.1162, -0.0766,  0.3353,\n",
       "                       0.5959, -0.6846, -0.2559,  0.4911, -0.8649,  0.0031,  0.5051, -0.0258])),\n",
       "             ('nodes.0.callable.block.g_nets.1.2.linear.bias',\n",
       "              tensor([0.0825])),\n",
       "             ('nodes.0.callable.block.g_nets.1.2.linear.weight',\n",
       "              tensor([[-0.0202,  0.0146, -0.0712, -0.0555,  0.0862, -0.0244, -0.0765, -0.0706,\n",
       "                       -0.0562, -0.0611, -0.0833,  0.0454, -0.0457,  0.0562, -0.0806,  0.0405,\n",
       "                        0.0215,  0.0109, -0.0032,  0.0757,  0.0802,  0.0603, -0.0503, -0.0820,\n",
       "                        0.0652,  0.0597,  0.0054,  0.0799, -0.0843,  0.0631, -0.0771, -0.0507,\n",
       "                        0.0566, -0.0571, -0.0779, -0.0373,  0.0335,  0.0012, -0.0673,  0.0714,\n",
       "                       -0.0349, -0.0352,  0.0759, -0.0117, -0.0101,  0.0057, -0.0542, -0.0258,\n",
       "                       -0.0092, -0.0314,  0.0862, -0.0760,  0.0592,  0.0185, -0.0339,  0.0374,\n",
       "                        0.0668, -0.0463, -0.0668, -0.0415, -0.0633, -0.0658, -0.0340, -0.0405,\n",
       "                       -0.0270,  0.0818, -0.0687,  0.0156,  0.0572,  0.0034, -0.0062,  0.0514,\n",
       "                       -0.0277,  0.0667, -0.0723, -0.0686,  0.0244, -0.0219,  0.0206,  0.0788,\n",
       "                        0.0073,  0.0262,  0.0324,  0.0224, -0.0208, -0.0450,  0.0300, -0.0554,\n",
       "                        0.0567, -0.0318, -0.0603,  0.0597,  0.0678,  0.0046, -0.0433,  0.0484,\n",
       "                       -0.0609,  0.0788,  0.0253,  0.0575,  0.0496, -0.0077,  0.0772, -0.0076,\n",
       "                       -0.0602,  0.0847,  0.0439,  0.0381, -0.0239, -0.0045, -0.0202,  0.0175,\n",
       "                        0.0233, -0.0219, -0.0369,  0.0011, -0.0775, -0.0398, -0.0478,  0.0606,\n",
       "                        0.0498, -0.0289,  0.0853,  0.0812,  0.0504, -0.0056, -0.0639,  0.0509]])),\n",
       "             ('nodes.0.callable.block.g_nets.1.2.linear.linear.weight',\n",
       "              tensor([[-0.0202,  0.0146, -0.0712, -0.0555,  0.0862, -0.0244, -0.0765, -0.0706,\n",
       "                       -0.0562, -0.0611, -0.0833,  0.0454, -0.0457,  0.0562, -0.0806,  0.0405,\n",
       "                        0.0215,  0.0109, -0.0032,  0.0757,  0.0802,  0.0603, -0.0503, -0.0820,\n",
       "                        0.0652,  0.0597,  0.0054,  0.0799, -0.0843,  0.0631, -0.0771, -0.0507,\n",
       "                        0.0566, -0.0571, -0.0779, -0.0373,  0.0335,  0.0012, -0.0673,  0.0714,\n",
       "                       -0.0349, -0.0352,  0.0759, -0.0117, -0.0101,  0.0057, -0.0542, -0.0258,\n",
       "                       -0.0092, -0.0314,  0.0862, -0.0760,  0.0592,  0.0185, -0.0339,  0.0374,\n",
       "                        0.0668, -0.0463, -0.0668, -0.0415, -0.0633, -0.0658, -0.0340, -0.0405,\n",
       "                       -0.0270,  0.0818, -0.0687,  0.0156,  0.0572,  0.0034, -0.0062,  0.0514,\n",
       "                       -0.0277,  0.0667, -0.0723, -0.0686,  0.0244, -0.0219,  0.0206,  0.0788,\n",
       "                        0.0073,  0.0262,  0.0324,  0.0224, -0.0208, -0.0450,  0.0300, -0.0554,\n",
       "                        0.0567, -0.0318, -0.0603,  0.0597,  0.0678,  0.0046, -0.0433,  0.0484,\n",
       "                       -0.0609,  0.0788,  0.0253,  0.0575,  0.0496, -0.0077,  0.0772, -0.0076,\n",
       "                       -0.0602,  0.0847,  0.0439,  0.0381, -0.0239, -0.0045, -0.0202,  0.0175,\n",
       "                        0.0233, -0.0219, -0.0369,  0.0011, -0.0775, -0.0398, -0.0478,  0.0606,\n",
       "                        0.0498, -0.0289,  0.0853,  0.0812,  0.0504, -0.0056, -0.0639,  0.0509]])),\n",
       "             ('nodes.0.callable.block.g_nets.1.2.linear.linear.bias',\n",
       "              tensor([0.0825])),\n",
       "             ('nodes.0.callable.block.g_nets.2.0.linear.bias',\n",
       "              tensor([ 0.7766, -0.4196,  0.9872, -0.8125, -0.9461, -0.6504, -0.9467, -0.4677,\n",
       "                      -0.5729,  0.4570, -0.3013,  0.1425, -0.6142, -0.7030,  0.7595, -0.4987,\n",
       "                       0.9836,  0.2217, -0.8038,  0.2342, -0.3598,  0.1250, -0.5797, -0.4583,\n",
       "                      -0.5293,  0.1583,  0.0171,  0.9337,  0.4649,  0.7486, -0.1864, -0.0783,\n",
       "                       0.9913, -0.8192,  0.4112, -0.9992,  0.5705, -0.4825,  0.0744,  0.7839,\n",
       "                       0.9916, -0.7633, -0.1458,  0.6438,  0.7376, -0.6882,  0.0839,  0.7943,\n",
       "                       0.8014, -0.1007, -0.4701,  0.8049,  0.3507, -0.0445, -0.1237, -0.7646,\n",
       "                      -0.8013, -0.0107,  0.4827,  0.2059, -0.1281,  0.1122, -0.1330,  0.5301,\n",
       "                      -0.5178,  0.4880,  0.6784,  0.9715,  0.7645, -0.0121, -0.6782,  0.7148,\n",
       "                      -0.9362, -0.8898,  0.9872,  0.1491, -0.2831, -0.5983,  0.0174,  0.6828,\n",
       "                       0.0117, -0.7243, -0.2189,  0.1829, -0.0709, -0.0064, -0.8860,  0.2013,\n",
       "                      -0.3112, -0.3643, -0.9023,  0.7677,  0.5568, -0.5223,  0.6489, -0.2187,\n",
       "                      -0.3312, -0.3919, -0.0805,  0.7425,  0.9082,  0.4934,  0.5838,  0.0297,\n",
       "                       0.6088, -0.9182,  0.3019, -0.5243,  0.1309,  0.6946,  0.9651, -0.5458,\n",
       "                      -0.8748, -0.6481,  0.7322, -0.2031, -0.5475, -0.3195, -0.2620, -0.5683,\n",
       "                       0.3292,  0.9453, -0.0447, -0.7574,  0.1466, -0.4072, -0.3478,  0.3961])),\n",
       "             ('nodes.0.callable.block.g_nets.2.0.linear.weight',\n",
       "              tensor([[-8.2798e-01],\n",
       "                      [-9.6321e-01],\n",
       "                      [ 1.2799e-01],\n",
       "                      [-3.6451e-01],\n",
       "                      [-1.3004e-01],\n",
       "                      [ 1.6879e-01],\n",
       "                      [ 9.7138e-01],\n",
       "                      [-2.2190e-01],\n",
       "                      [-7.9928e-01],\n",
       "                      [-3.2727e-01],\n",
       "                      [-4.5020e-01],\n",
       "                      [ 7.8009e-01],\n",
       "                      [-2.5796e-01],\n",
       "                      [-3.1277e-01],\n",
       "                      [-4.1846e-01],\n",
       "                      [ 1.2391e-01],\n",
       "                      [ 9.5043e-02],\n",
       "                      [-7.2888e-01],\n",
       "                      [-9.6907e-02],\n",
       "                      [-2.9705e-01],\n",
       "                      [ 4.4210e-01],\n",
       "                      [-9.2621e-01],\n",
       "                      [ 6.3068e-01],\n",
       "                      [ 9.8507e-01],\n",
       "                      [ 8.9069e-01],\n",
       "                      [ 7.9164e-01],\n",
       "                      [ 6.9607e-01],\n",
       "                      [ 6.8478e-01],\n",
       "                      [ 1.5658e-01],\n",
       "                      [ 1.4461e-01],\n",
       "                      [ 4.9683e-01],\n",
       "                      [ 5.4834e-01],\n",
       "                      [ 6.6570e-01],\n",
       "                      [ 7.5986e-01],\n",
       "                      [-2.3575e-01],\n",
       "                      [ 1.5797e-01],\n",
       "                      [-9.2523e-01],\n",
       "                      [ 2.3748e-01],\n",
       "                      [ 8.9580e-01],\n",
       "                      [ 2.8775e-02],\n",
       "                      [-6.0244e-01],\n",
       "                      [ 3.6027e-01],\n",
       "                      [-3.4113e-01],\n",
       "                      [ 4.2225e-01],\n",
       "                      [-8.3169e-01],\n",
       "                      [ 9.1967e-01],\n",
       "                      [ 1.1240e-01],\n",
       "                      [-9.6847e-01],\n",
       "                      [-4.8267e-01],\n",
       "                      [ 3.3617e-01],\n",
       "                      [ 5.6533e-01],\n",
       "                      [ 5.5214e-03],\n",
       "                      [-8.2218e-01],\n",
       "                      [-3.3849e-01],\n",
       "                      [-8.0792e-01],\n",
       "                      [-1.2977e-04],\n",
       "                      [-4.2185e-01],\n",
       "                      [ 3.1676e-01],\n",
       "                      [ 2.8676e-01],\n",
       "                      [ 6.9898e-01],\n",
       "                      [ 2.4316e-01],\n",
       "                      [-7.1967e-01],\n",
       "                      [ 6.2538e-01],\n",
       "                      [ 4.5620e-01],\n",
       "                      [ 5.3244e-01],\n",
       "                      [ 1.9510e-01],\n",
       "                      [-9.5560e-01],\n",
       "                      [ 6.4400e-02],\n",
       "                      [-5.5544e-01],\n",
       "                      [ 6.8964e-01],\n",
       "                      [ 1.6307e-01],\n",
       "                      [ 2.2931e-01],\n",
       "                      [-5.2788e-01],\n",
       "                      [-9.7196e-01],\n",
       "                      [ 3.3661e-01],\n",
       "                      [-3.4210e-01],\n",
       "                      [-4.7809e-01],\n",
       "                      [ 7.1877e-01],\n",
       "                      [-5.1381e-01],\n",
       "                      [-5.3852e-01],\n",
       "                      [-7.8372e-01],\n",
       "                      [-2.3877e-01],\n",
       "                      [-1.1267e-01],\n",
       "                      [ 7.2680e-02],\n",
       "                      [ 3.7428e-01],\n",
       "                      [-1.9205e-01],\n",
       "                      [ 5.6323e-01],\n",
       "                      [ 7.7440e-01],\n",
       "                      [ 1.2340e-01],\n",
       "                      [-7.1461e-02],\n",
       "                      [-8.1454e-01],\n",
       "                      [-2.8594e-02],\n",
       "                      [ 2.3811e-01],\n",
       "                      [-9.7654e-01],\n",
       "                      [-3.2774e-01],\n",
       "                      [-8.7965e-01],\n",
       "                      [-7.6079e-01],\n",
       "                      [ 9.7138e-01],\n",
       "                      [ 9.7450e-01],\n",
       "                      [-2.2212e-01],\n",
       "                      [ 8.1868e-01],\n",
       "                      [ 2.0013e-01],\n",
       "                      [ 7.3726e-01],\n",
       "                      [-9.8986e-02],\n",
       "                      [-3.6808e-01],\n",
       "                      [-4.5170e-01],\n",
       "                      [ 3.5438e-01],\n",
       "                      [ 9.6120e-01],\n",
       "                      [-9.5706e-03],\n",
       "                      [-3.9410e-01],\n",
       "                      [ 9.9939e-02],\n",
       "                      [ 6.1625e-01],\n",
       "                      [-8.3137e-01],\n",
       "                      [ 5.1301e-01],\n",
       "                      [ 3.1329e-01],\n",
       "                      [ 2.8780e-01],\n",
       "                      [ 2.5886e-01],\n",
       "                      [-8.6793e-01],\n",
       "                      [-4.8075e-01],\n",
       "                      [-6.6219e-01],\n",
       "                      [ 6.3943e-01],\n",
       "                      [ 5.7304e-01],\n",
       "                      [ 3.6768e-01],\n",
       "                      [-1.8532e-01],\n",
       "                      [ 7.1067e-01],\n",
       "                      [ 4.1980e-01],\n",
       "                      [ 8.8694e-01],\n",
       "                      [ 7.2635e-01]])),\n",
       "             ('nodes.0.callable.block.g_nets.2.0.linear.linear.weight',\n",
       "              tensor([[-8.2798e-01],\n",
       "                      [-9.6321e-01],\n",
       "                      [ 1.2799e-01],\n",
       "                      [-3.6451e-01],\n",
       "                      [-1.3004e-01],\n",
       "                      [ 1.6879e-01],\n",
       "                      [ 9.7138e-01],\n",
       "                      [-2.2190e-01],\n",
       "                      [-7.9928e-01],\n",
       "                      [-3.2727e-01],\n",
       "                      [-4.5020e-01],\n",
       "                      [ 7.8009e-01],\n",
       "                      [-2.5796e-01],\n",
       "                      [-3.1277e-01],\n",
       "                      [-4.1846e-01],\n",
       "                      [ 1.2391e-01],\n",
       "                      [ 9.5043e-02],\n",
       "                      [-7.2888e-01],\n",
       "                      [-9.6907e-02],\n",
       "                      [-2.9705e-01],\n",
       "                      [ 4.4210e-01],\n",
       "                      [-9.2621e-01],\n",
       "                      [ 6.3068e-01],\n",
       "                      [ 9.8507e-01],\n",
       "                      [ 8.9069e-01],\n",
       "                      [ 7.9164e-01],\n",
       "                      [ 6.9607e-01],\n",
       "                      [ 6.8478e-01],\n",
       "                      [ 1.5658e-01],\n",
       "                      [ 1.4461e-01],\n",
       "                      [ 4.9683e-01],\n",
       "                      [ 5.4834e-01],\n",
       "                      [ 6.6570e-01],\n",
       "                      [ 7.5986e-01],\n",
       "                      [-2.3575e-01],\n",
       "                      [ 1.5797e-01],\n",
       "                      [-9.2523e-01],\n",
       "                      [ 2.3748e-01],\n",
       "                      [ 8.9580e-01],\n",
       "                      [ 2.8775e-02],\n",
       "                      [-6.0244e-01],\n",
       "                      [ 3.6027e-01],\n",
       "                      [-3.4113e-01],\n",
       "                      [ 4.2225e-01],\n",
       "                      [-8.3169e-01],\n",
       "                      [ 9.1967e-01],\n",
       "                      [ 1.1240e-01],\n",
       "                      [-9.6847e-01],\n",
       "                      [-4.8267e-01],\n",
       "                      [ 3.3617e-01],\n",
       "                      [ 5.6533e-01],\n",
       "                      [ 5.5214e-03],\n",
       "                      [-8.2218e-01],\n",
       "                      [-3.3849e-01],\n",
       "                      [-8.0792e-01],\n",
       "                      [-1.2977e-04],\n",
       "                      [-4.2185e-01],\n",
       "                      [ 3.1676e-01],\n",
       "                      [ 2.8676e-01],\n",
       "                      [ 6.9898e-01],\n",
       "                      [ 2.4316e-01],\n",
       "                      [-7.1967e-01],\n",
       "                      [ 6.2538e-01],\n",
       "                      [ 4.5620e-01],\n",
       "                      [ 5.3244e-01],\n",
       "                      [ 1.9510e-01],\n",
       "                      [-9.5560e-01],\n",
       "                      [ 6.4400e-02],\n",
       "                      [-5.5544e-01],\n",
       "                      [ 6.8964e-01],\n",
       "                      [ 1.6307e-01],\n",
       "                      [ 2.2931e-01],\n",
       "                      [-5.2788e-01],\n",
       "                      [-9.7196e-01],\n",
       "                      [ 3.3661e-01],\n",
       "                      [-3.4210e-01],\n",
       "                      [-4.7809e-01],\n",
       "                      [ 7.1877e-01],\n",
       "                      [-5.1381e-01],\n",
       "                      [-5.3852e-01],\n",
       "                      [-7.8372e-01],\n",
       "                      [-2.3877e-01],\n",
       "                      [-1.1267e-01],\n",
       "                      [ 7.2680e-02],\n",
       "                      [ 3.7428e-01],\n",
       "                      [-1.9205e-01],\n",
       "                      [ 5.6323e-01],\n",
       "                      [ 7.7440e-01],\n",
       "                      [ 1.2340e-01],\n",
       "                      [-7.1461e-02],\n",
       "                      [-8.1454e-01],\n",
       "                      [-2.8594e-02],\n",
       "                      [ 2.3811e-01],\n",
       "                      [-9.7654e-01],\n",
       "                      [-3.2774e-01],\n",
       "                      [-8.7965e-01],\n",
       "                      [-7.6079e-01],\n",
       "                      [ 9.7138e-01],\n",
       "                      [ 9.7450e-01],\n",
       "                      [-2.2212e-01],\n",
       "                      [ 8.1868e-01],\n",
       "                      [ 2.0013e-01],\n",
       "                      [ 7.3726e-01],\n",
       "                      [-9.8986e-02],\n",
       "                      [-3.6808e-01],\n",
       "                      [-4.5170e-01],\n",
       "                      [ 3.5438e-01],\n",
       "                      [ 9.6120e-01],\n",
       "                      [-9.5706e-03],\n",
       "                      [-3.9410e-01],\n",
       "                      [ 9.9939e-02],\n",
       "                      [ 6.1625e-01],\n",
       "                      [-8.3137e-01],\n",
       "                      [ 5.1301e-01],\n",
       "                      [ 3.1329e-01],\n",
       "                      [ 2.8780e-01],\n",
       "                      [ 2.5886e-01],\n",
       "                      [-8.6793e-01],\n",
       "                      [-4.8075e-01],\n",
       "                      [-6.6219e-01],\n",
       "                      [ 6.3943e-01],\n",
       "                      [ 5.7304e-01],\n",
       "                      [ 3.6768e-01],\n",
       "                      [-1.8532e-01],\n",
       "                      [ 7.1067e-01],\n",
       "                      [ 4.1980e-01],\n",
       "                      [ 8.8694e-01],\n",
       "                      [ 7.2635e-01]])),\n",
       "             ('nodes.0.callable.block.g_nets.2.0.linear.linear.bias',\n",
       "              tensor([ 0.7766, -0.4196,  0.9872, -0.8125, -0.9461, -0.6504, -0.9467, -0.4677,\n",
       "                      -0.5729,  0.4570, -0.3013,  0.1425, -0.6142, -0.7030,  0.7595, -0.4987,\n",
       "                       0.9836,  0.2217, -0.8038,  0.2342, -0.3598,  0.1250, -0.5797, -0.4583,\n",
       "                      -0.5293,  0.1583,  0.0171,  0.9337,  0.4649,  0.7486, -0.1864, -0.0783,\n",
       "                       0.9913, -0.8192,  0.4112, -0.9992,  0.5705, -0.4825,  0.0744,  0.7839,\n",
       "                       0.9916, -0.7633, -0.1458,  0.6438,  0.7376, -0.6882,  0.0839,  0.7943,\n",
       "                       0.8014, -0.1007, -0.4701,  0.8049,  0.3507, -0.0445, -0.1237, -0.7646,\n",
       "                      -0.8013, -0.0107,  0.4827,  0.2059, -0.1281,  0.1122, -0.1330,  0.5301,\n",
       "                      -0.5178,  0.4880,  0.6784,  0.9715,  0.7645, -0.0121, -0.6782,  0.7148,\n",
       "                      -0.9362, -0.8898,  0.9872,  0.1491, -0.2831, -0.5983,  0.0174,  0.6828,\n",
       "                       0.0117, -0.7243, -0.2189,  0.1829, -0.0709, -0.0064, -0.8860,  0.2013,\n",
       "                      -0.3112, -0.3643, -0.9023,  0.7677,  0.5568, -0.5223,  0.6489, -0.2187,\n",
       "                      -0.3312, -0.3919, -0.0805,  0.7425,  0.9082,  0.4934,  0.5838,  0.0297,\n",
       "                       0.6088, -0.9182,  0.3019, -0.5243,  0.1309,  0.6946,  0.9651, -0.5458,\n",
       "                      -0.8748, -0.6481,  0.7322, -0.2031, -0.5475, -0.3195, -0.2620, -0.5683,\n",
       "                       0.3292,  0.9453, -0.0447, -0.7574,  0.1466, -0.4072, -0.3478,  0.3961])),\n",
       "             ('nodes.0.callable.block.g_nets.2.2.linear.bias',\n",
       "              tensor([-0.0465])),\n",
       "             ('nodes.0.callable.block.g_nets.2.2.linear.weight',\n",
       "              tensor([[ 0.0598, -0.0283, -0.0714, -0.0234,  0.0488, -0.0599, -0.0368, -0.0723,\n",
       "                       -0.0758, -0.0229, -0.0831,  0.0101, -0.0050, -0.0840,  0.0689, -0.0803,\n",
       "                       -0.0750, -0.0826,  0.0532, -0.0206,  0.0097,  0.0766, -0.0336, -0.0156,\n",
       "                        0.0717, -0.0623,  0.0137, -0.0025,  0.0149, -0.0518,  0.0147,  0.0690,\n",
       "                       -0.0111, -0.0424, -0.0633, -0.0668, -0.0358, -0.0715,  0.0411,  0.0693,\n",
       "                        0.0496, -0.0783,  0.0757, -0.0115,  0.0315,  0.0624,  0.0050,  0.0607,\n",
       "                        0.0102,  0.0446, -0.0055,  0.0224,  0.0773, -0.0128, -0.0782, -0.0605,\n",
       "                        0.0554, -0.0271, -0.0558, -0.0060,  0.0716, -0.0342, -0.0040, -0.0233,\n",
       "                       -0.0629,  0.0595, -0.0046, -0.0564,  0.0581, -0.0177,  0.0006, -0.0672,\n",
       "                       -0.0280, -0.0823, -0.0472, -0.0646,  0.0424,  0.0653, -0.0848, -0.0232,\n",
       "                        0.0786, -0.0308,  0.0095,  0.0576,  0.0652,  0.0058, -0.0103,  0.0110,\n",
       "                        0.0542,  0.0623,  0.0058, -0.0169,  0.0761, -0.0485,  0.0646,  0.0241,\n",
       "                       -0.0581, -0.0129, -0.0659, -0.0540,  0.0352, -0.0475, -0.0396, -0.0331,\n",
       "                       -0.0725, -0.0206,  0.0649, -0.0655, -0.0342, -0.0482, -0.0850,  0.0652,\n",
       "                        0.0408, -0.0606, -0.0310,  0.0561,  0.0503,  0.0429,  0.0311,  0.0360,\n",
       "                       -0.0051, -0.0270,  0.0627,  0.0269,  0.0885, -0.0034, -0.0131, -0.0737]])),\n",
       "             ('nodes.0.callable.block.g_nets.2.2.linear.linear.weight',\n",
       "              tensor([[ 0.0598, -0.0283, -0.0714, -0.0234,  0.0488, -0.0599, -0.0368, -0.0723,\n",
       "                       -0.0758, -0.0229, -0.0831,  0.0101, -0.0050, -0.0840,  0.0689, -0.0803,\n",
       "                       -0.0750, -0.0826,  0.0532, -0.0206,  0.0097,  0.0766, -0.0336, -0.0156,\n",
       "                        0.0717, -0.0623,  0.0137, -0.0025,  0.0149, -0.0518,  0.0147,  0.0690,\n",
       "                       -0.0111, -0.0424, -0.0633, -0.0668, -0.0358, -0.0715,  0.0411,  0.0693,\n",
       "                        0.0496, -0.0783,  0.0757, -0.0115,  0.0315,  0.0624,  0.0050,  0.0607,\n",
       "                        0.0102,  0.0446, -0.0055,  0.0224,  0.0773, -0.0128, -0.0782, -0.0605,\n",
       "                        0.0554, -0.0271, -0.0558, -0.0060,  0.0716, -0.0342, -0.0040, -0.0233,\n",
       "                       -0.0629,  0.0595, -0.0046, -0.0564,  0.0581, -0.0177,  0.0006, -0.0672,\n",
       "                       -0.0280, -0.0823, -0.0472, -0.0646,  0.0424,  0.0653, -0.0848, -0.0232,\n",
       "                        0.0786, -0.0308,  0.0095,  0.0576,  0.0652,  0.0058, -0.0103,  0.0110,\n",
       "                        0.0542,  0.0623,  0.0058, -0.0169,  0.0761, -0.0485,  0.0646,  0.0241,\n",
       "                       -0.0581, -0.0129, -0.0659, -0.0540,  0.0352, -0.0475, -0.0396, -0.0331,\n",
       "                       -0.0725, -0.0206,  0.0649, -0.0655, -0.0342, -0.0482, -0.0850,  0.0652,\n",
       "                        0.0408, -0.0606, -0.0310,  0.0561,  0.0503,  0.0429,  0.0311,  0.0360,\n",
       "                       -0.0051, -0.0270,  0.0627,  0.0269,  0.0885, -0.0034, -0.0131, -0.0737]])),\n",
       "             ('nodes.0.callable.block.g_nets.2.2.linear.linear.bias',\n",
       "              tensor([-0.0465])),\n",
       "             ('nodes.0.callable.block.g_nets.3.0.linear.bias',\n",
       "              tensor([-0.1897, -0.4136, -0.0600,  0.4781, -0.0062, -0.4760, -0.7360,  0.3182,\n",
       "                       0.7528,  0.7511,  0.7886,  0.0376, -0.7592, -0.9569, -0.5714,  0.9732,\n",
       "                      -0.2969,  0.0404, -0.4866,  0.6162,  0.9670, -0.5739, -0.5544, -0.7261,\n",
       "                       0.3954, -0.1049, -0.8337, -0.2600, -0.7648, -0.4967, -0.3010,  0.1629,\n",
       "                       0.5068, -0.4372, -0.6420, -0.7344, -0.7959, -0.6158,  0.8576,  0.0829,\n",
       "                      -0.1095, -0.0244,  0.9195,  0.2785, -0.4041,  0.3862, -0.9689,  0.5251,\n",
       "                      -0.3310, -0.1707, -0.4869,  0.3754, -0.4886,  0.9926,  0.5493,  0.7165,\n",
       "                       0.0659, -0.7991,  0.0334, -0.1997,  0.7789,  0.9576,  0.9841, -0.9823,\n",
       "                       0.5147, -0.8951,  0.0049,  0.2703,  0.1854, -0.6350,  0.7687, -0.3160,\n",
       "                      -0.3736, -0.4972,  0.6276,  0.0926, -0.8395,  0.5236, -0.1407,  0.3347,\n",
       "                       0.5605,  0.6185,  0.3103, -0.1836, -0.3719,  0.0931, -0.4212, -0.8486,\n",
       "                      -0.9194,  0.2395, -0.3648, -0.4924,  0.5171,  0.5812, -0.6744,  0.4620,\n",
       "                       0.8030,  0.2867,  0.3468,  0.1629, -0.2615,  0.5834, -0.1213, -0.9090,\n",
       "                       0.4576, -0.1778,  0.1157, -0.0877, -0.4802,  0.4466,  0.0856, -0.0484,\n",
       "                      -0.9200,  0.1059, -0.0929,  0.4066, -0.6213, -0.3584, -0.1433, -0.9119,\n",
       "                       0.2475,  0.8030,  0.9635,  0.2718, -0.6764,  0.3312,  0.7446, -0.1915])),\n",
       "             ('nodes.0.callable.block.g_nets.3.0.linear.weight',\n",
       "              tensor([[-0.7868],\n",
       "                      [ 0.9055],\n",
       "                      [ 0.7753],\n",
       "                      [ 0.1308],\n",
       "                      [-0.6317],\n",
       "                      [ 0.5908],\n",
       "                      [-1.0001],\n",
       "                      [-0.2860],\n",
       "                      [-0.6942],\n",
       "                      [ 0.6380],\n",
       "                      [-0.3750],\n",
       "                      [ 0.4100],\n",
       "                      [ 0.7790],\n",
       "                      [ 0.9677],\n",
       "                      [-0.9816],\n",
       "                      [-0.1140],\n",
       "                      [-0.7071],\n",
       "                      [ 0.9095],\n",
       "                      [-0.1951],\n",
       "                      [ 0.1636],\n",
       "                      [ 0.1284],\n",
       "                      [-0.0647],\n",
       "                      [-0.7313],\n",
       "                      [ 0.9825],\n",
       "                      [-0.5348],\n",
       "                      [ 0.6523],\n",
       "                      [ 0.6744],\n",
       "                      [-0.9633],\n",
       "                      [ 0.1932],\n",
       "                      [-0.7486],\n",
       "                      [-0.3483],\n",
       "                      [ 0.9096],\n",
       "                      [ 0.7495],\n",
       "                      [ 0.2819],\n",
       "                      [ 0.0174],\n",
       "                      [ 0.3927],\n",
       "                      [ 0.2120],\n",
       "                      [ 0.9502],\n",
       "                      [ 0.8396],\n",
       "                      [ 0.5378],\n",
       "                      [ 0.8968],\n",
       "                      [ 0.6437],\n",
       "                      [-0.2919],\n",
       "                      [-0.1662],\n",
       "                      [ 0.3090],\n",
       "                      [-0.9286],\n",
       "                      [-0.3334],\n",
       "                      [ 0.2128],\n",
       "                      [-0.0541],\n",
       "                      [-0.9093],\n",
       "                      [-0.2280],\n",
       "                      [-0.7720],\n",
       "                      [ 0.4750],\n",
       "                      [ 0.2341],\n",
       "                      [-0.6930],\n",
       "                      [ 0.4597],\n",
       "                      [-0.1062],\n",
       "                      [-0.5243],\n",
       "                      [-0.9983],\n",
       "                      [ 0.4140],\n",
       "                      [ 0.1559],\n",
       "                      [-0.9200],\n",
       "                      [ 0.5705],\n",
       "                      [-0.1691],\n",
       "                      [ 0.3461],\n",
       "                      [ 0.4002],\n",
       "                      [-0.1260],\n",
       "                      [-0.0525],\n",
       "                      [-0.1068],\n",
       "                      [ 0.8275],\n",
       "                      [ 0.0361],\n",
       "                      [-0.5092],\n",
       "                      [-0.2755],\n",
       "                      [-0.2995],\n",
       "                      [ 0.4923],\n",
       "                      [ 0.4414],\n",
       "                      [-0.7885],\n",
       "                      [-0.9703],\n",
       "                      [ 0.2567],\n",
       "                      [-0.4586],\n",
       "                      [ 0.0289],\n",
       "                      [ 0.1376],\n",
       "                      [-0.2431],\n",
       "                      [-0.3724],\n",
       "                      [-0.3309],\n",
       "                      [-0.7375],\n",
       "                      [ 0.6872],\n",
       "                      [ 0.9330],\n",
       "                      [ 0.2360],\n",
       "                      [ 0.5152],\n",
       "                      [-0.9423],\n",
       "                      [ 0.9695],\n",
       "                      [-0.8412],\n",
       "                      [-0.8938],\n",
       "                      [-0.0351],\n",
       "                      [-0.4171],\n",
       "                      [ 0.9647],\n",
       "                      [-0.6873],\n",
       "                      [-0.3411],\n",
       "                      [ 0.7412],\n",
       "                      [ 0.1191],\n",
       "                      [ 0.2346],\n",
       "                      [-0.4546],\n",
       "                      [-0.5362],\n",
       "                      [ 0.9403],\n",
       "                      [-0.6594],\n",
       "                      [-0.0511],\n",
       "                      [ 0.2044],\n",
       "                      [-0.1883],\n",
       "                      [ 0.3391],\n",
       "                      [-0.5006],\n",
       "                      [ 0.1378],\n",
       "                      [-0.3121],\n",
       "                      [-0.2223],\n",
       "                      [ 0.7768],\n",
       "                      [-0.0896],\n",
       "                      [-0.3809],\n",
       "                      [-0.8322],\n",
       "                      [-0.2010],\n",
       "                      [ 0.2431],\n",
       "                      [ 0.0152],\n",
       "                      [-0.2387],\n",
       "                      [-0.6317],\n",
       "                      [-0.6021],\n",
       "                      [-0.2691],\n",
       "                      [-0.4803],\n",
       "                      [-0.6780],\n",
       "                      [-0.5278]])),\n",
       "             ('nodes.0.callable.block.g_nets.3.0.linear.linear.weight',\n",
       "              tensor([[-0.7868],\n",
       "                      [ 0.9055],\n",
       "                      [ 0.7753],\n",
       "                      [ 0.1308],\n",
       "                      [-0.6317],\n",
       "                      [ 0.5908],\n",
       "                      [-1.0001],\n",
       "                      [-0.2860],\n",
       "                      [-0.6942],\n",
       "                      [ 0.6380],\n",
       "                      [-0.3750],\n",
       "                      [ 0.4100],\n",
       "                      [ 0.7790],\n",
       "                      [ 0.9677],\n",
       "                      [-0.9816],\n",
       "                      [-0.1140],\n",
       "                      [-0.7071],\n",
       "                      [ 0.9095],\n",
       "                      [-0.1951],\n",
       "                      [ 0.1636],\n",
       "                      [ 0.1284],\n",
       "                      [-0.0647],\n",
       "                      [-0.7313],\n",
       "                      [ 0.9825],\n",
       "                      [-0.5348],\n",
       "                      [ 0.6523],\n",
       "                      [ 0.6744],\n",
       "                      [-0.9633],\n",
       "                      [ 0.1932],\n",
       "                      [-0.7486],\n",
       "                      [-0.3483],\n",
       "                      [ 0.9096],\n",
       "                      [ 0.7495],\n",
       "                      [ 0.2819],\n",
       "                      [ 0.0174],\n",
       "                      [ 0.3927],\n",
       "                      [ 0.2120],\n",
       "                      [ 0.9502],\n",
       "                      [ 0.8396],\n",
       "                      [ 0.5378],\n",
       "                      [ 0.8968],\n",
       "                      [ 0.6437],\n",
       "                      [-0.2919],\n",
       "                      [-0.1662],\n",
       "                      [ 0.3090],\n",
       "                      [-0.9286],\n",
       "                      [-0.3334],\n",
       "                      [ 0.2128],\n",
       "                      [-0.0541],\n",
       "                      [-0.9093],\n",
       "                      [-0.2280],\n",
       "                      [-0.7720],\n",
       "                      [ 0.4750],\n",
       "                      [ 0.2341],\n",
       "                      [-0.6930],\n",
       "                      [ 0.4597],\n",
       "                      [-0.1062],\n",
       "                      [-0.5243],\n",
       "                      [-0.9983],\n",
       "                      [ 0.4140],\n",
       "                      [ 0.1559],\n",
       "                      [-0.9200],\n",
       "                      [ 0.5705],\n",
       "                      [-0.1691],\n",
       "                      [ 0.3461],\n",
       "                      [ 0.4002],\n",
       "                      [-0.1260],\n",
       "                      [-0.0525],\n",
       "                      [-0.1068],\n",
       "                      [ 0.8275],\n",
       "                      [ 0.0361],\n",
       "                      [-0.5092],\n",
       "                      [-0.2755],\n",
       "                      [-0.2995],\n",
       "                      [ 0.4923],\n",
       "                      [ 0.4414],\n",
       "                      [-0.7885],\n",
       "                      [-0.9703],\n",
       "                      [ 0.2567],\n",
       "                      [-0.4586],\n",
       "                      [ 0.0289],\n",
       "                      [ 0.1376],\n",
       "                      [-0.2431],\n",
       "                      [-0.3724],\n",
       "                      [-0.3309],\n",
       "                      [-0.7375],\n",
       "                      [ 0.6872],\n",
       "                      [ 0.9330],\n",
       "                      [ 0.2360],\n",
       "                      [ 0.5152],\n",
       "                      [-0.9423],\n",
       "                      [ 0.9695],\n",
       "                      [-0.8412],\n",
       "                      [-0.8938],\n",
       "                      [-0.0351],\n",
       "                      [-0.4171],\n",
       "                      [ 0.9647],\n",
       "                      [-0.6873],\n",
       "                      [-0.3411],\n",
       "                      [ 0.7412],\n",
       "                      [ 0.1191],\n",
       "                      [ 0.2346],\n",
       "                      [-0.4546],\n",
       "                      [-0.5362],\n",
       "                      [ 0.9403],\n",
       "                      [-0.6594],\n",
       "                      [-0.0511],\n",
       "                      [ 0.2044],\n",
       "                      [-0.1883],\n",
       "                      [ 0.3391],\n",
       "                      [-0.5006],\n",
       "                      [ 0.1378],\n",
       "                      [-0.3121],\n",
       "                      [-0.2223],\n",
       "                      [ 0.7768],\n",
       "                      [-0.0896],\n",
       "                      [-0.3809],\n",
       "                      [-0.8322],\n",
       "                      [-0.2010],\n",
       "                      [ 0.2431],\n",
       "                      [ 0.0152],\n",
       "                      [-0.2387],\n",
       "                      [-0.6317],\n",
       "                      [-0.6021],\n",
       "                      [-0.2691],\n",
       "                      [-0.4803],\n",
       "                      [-0.6780],\n",
       "                      [-0.5278]])),\n",
       "             ('nodes.0.callable.block.g_nets.3.0.linear.linear.bias',\n",
       "              tensor([-0.1897, -0.4136, -0.0600,  0.4781, -0.0062, -0.4760, -0.7360,  0.3182,\n",
       "                       0.7528,  0.7511,  0.7886,  0.0376, -0.7592, -0.9569, -0.5714,  0.9732,\n",
       "                      -0.2969,  0.0404, -0.4866,  0.6162,  0.9670, -0.5739, -0.5544, -0.7261,\n",
       "                       0.3954, -0.1049, -0.8337, -0.2600, -0.7648, -0.4967, -0.3010,  0.1629,\n",
       "                       0.5068, -0.4372, -0.6420, -0.7344, -0.7959, -0.6158,  0.8576,  0.0829,\n",
       "                      -0.1095, -0.0244,  0.9195,  0.2785, -0.4041,  0.3862, -0.9689,  0.5251,\n",
       "                      -0.3310, -0.1707, -0.4869,  0.3754, -0.4886,  0.9926,  0.5493,  0.7165,\n",
       "                       0.0659, -0.7991,  0.0334, -0.1997,  0.7789,  0.9576,  0.9841, -0.9823,\n",
       "                       0.5147, -0.8951,  0.0049,  0.2703,  0.1854, -0.6350,  0.7687, -0.3160,\n",
       "                      -0.3736, -0.4972,  0.6276,  0.0926, -0.8395,  0.5236, -0.1407,  0.3347,\n",
       "                       0.5605,  0.6185,  0.3103, -0.1836, -0.3719,  0.0931, -0.4212, -0.8486,\n",
       "                      -0.9194,  0.2395, -0.3648, -0.4924,  0.5171,  0.5812, -0.6744,  0.4620,\n",
       "                       0.8030,  0.2867,  0.3468,  0.1629, -0.2615,  0.5834, -0.1213, -0.9090,\n",
       "                       0.4576, -0.1778,  0.1157, -0.0877, -0.4802,  0.4466,  0.0856, -0.0484,\n",
       "                      -0.9200,  0.1059, -0.0929,  0.4066, -0.6213, -0.3584, -0.1433, -0.9119,\n",
       "                       0.2475,  0.8030,  0.9635,  0.2718, -0.6764,  0.3312,  0.7446, -0.1915])),\n",
       "             ('nodes.0.callable.block.g_nets.3.2.linear.bias',\n",
       "              tensor([0.0493])),\n",
       "             ('nodes.0.callable.block.g_nets.3.2.linear.weight',\n",
       "              tensor([[ 0.0623,  0.0024,  0.0185, -0.0319,  0.0058, -0.0329,  0.0602, -0.0275,\n",
       "                        0.0552,  0.0838,  0.0714,  0.0239,  0.0572, -0.0639, -0.0279,  0.0585,\n",
       "                        0.0342,  0.0115,  0.0092, -0.0198, -0.0023, -0.0499,  0.0239,  0.0243,\n",
       "                        0.0081, -0.0562, -0.0744,  0.0326,  0.0495,  0.0778, -0.0686,  0.0067,\n",
       "                       -0.0445, -0.0021,  0.0407,  0.0775, -0.0022,  0.0545,  0.0611, -0.0367,\n",
       "                       -0.0017,  0.0227, -0.0177, -0.0233, -0.0031,  0.0415,  0.0787,  0.0831,\n",
       "                       -0.0021,  0.0838,  0.0429,  0.0009, -0.0168,  0.0681, -0.0361,  0.0753,\n",
       "                       -0.0037, -0.0674,  0.0385,  0.0044,  0.0789,  0.0364, -0.0879,  0.0198,\n",
       "                       -0.0139,  0.0314,  0.0228, -0.0261,  0.0276, -0.0093, -0.0149, -0.0497,\n",
       "                        0.0275, -0.0845, -0.0005, -0.0358, -0.0214,  0.0409, -0.0234,  0.0505,\n",
       "                       -0.0126,  0.0718, -0.0517, -0.0598,  0.0846, -0.0492, -0.0527, -0.0764,\n",
       "                       -0.0582,  0.0332, -0.0195, -0.0180, -0.0576,  0.0313, -0.0586,  0.0485,\n",
       "                       -0.0035,  0.0735,  0.0753, -0.0109,  0.0449,  0.0548, -0.0205,  0.0594,\n",
       "                        0.0084, -0.0833,  0.0170,  0.0786, -0.0777, -0.0778,  0.0013, -0.0175,\n",
       "                       -0.0883,  0.0682, -0.0557,  0.0424, -0.0749,  0.0216, -0.0374, -0.0574,\n",
       "                        0.0837, -0.0887, -0.0005, -0.0065, -0.0341, -0.0323,  0.0044, -0.0287]])),\n",
       "             ('nodes.0.callable.block.g_nets.3.2.linear.linear.weight',\n",
       "              tensor([[ 0.0623,  0.0024,  0.0185, -0.0319,  0.0058, -0.0329,  0.0602, -0.0275,\n",
       "                        0.0552,  0.0838,  0.0714,  0.0239,  0.0572, -0.0639, -0.0279,  0.0585,\n",
       "                        0.0342,  0.0115,  0.0092, -0.0198, -0.0023, -0.0499,  0.0239,  0.0243,\n",
       "                        0.0081, -0.0562, -0.0744,  0.0326,  0.0495,  0.0778, -0.0686,  0.0067,\n",
       "                       -0.0445, -0.0021,  0.0407,  0.0775, -0.0022,  0.0545,  0.0611, -0.0367,\n",
       "                       -0.0017,  0.0227, -0.0177, -0.0233, -0.0031,  0.0415,  0.0787,  0.0831,\n",
       "                       -0.0021,  0.0838,  0.0429,  0.0009, -0.0168,  0.0681, -0.0361,  0.0753,\n",
       "                       -0.0037, -0.0674,  0.0385,  0.0044,  0.0789,  0.0364, -0.0879,  0.0198,\n",
       "                       -0.0139,  0.0314,  0.0228, -0.0261,  0.0276, -0.0093, -0.0149, -0.0497,\n",
       "                        0.0275, -0.0845, -0.0005, -0.0358, -0.0214,  0.0409, -0.0234,  0.0505,\n",
       "                       -0.0126,  0.0718, -0.0517, -0.0598,  0.0846, -0.0492, -0.0527, -0.0764,\n",
       "                       -0.0582,  0.0332, -0.0195, -0.0180, -0.0576,  0.0313, -0.0586,  0.0485,\n",
       "                       -0.0035,  0.0735,  0.0753, -0.0109,  0.0449,  0.0548, -0.0205,  0.0594,\n",
       "                        0.0084, -0.0833,  0.0170,  0.0786, -0.0777, -0.0778,  0.0013, -0.0175,\n",
       "                       -0.0883,  0.0682, -0.0557,  0.0424, -0.0749,  0.0216, -0.0374, -0.0574,\n",
       "                        0.0837, -0.0887, -0.0005, -0.0065, -0.0341, -0.0323,  0.0044, -0.0287]])),\n",
       "             ('nodes.0.callable.block.g_nets.3.2.linear.linear.bias',\n",
       "              tensor([0.0493])),\n",
       "             ('nodes.0.callable.block.projector.linear.bias',\n",
       "              tensor([-0.2267, -0.1689, -0.4122])),\n",
       "             ('nodes.0.callable.block.projector.linear.weight',\n",
       "              tensor([[ 0.2799,  0.1889,  0.3395,  0.4908],\n",
       "                      [-0.3642, -0.4697, -0.1444, -0.0058],\n",
       "                      [ 0.0800,  0.2223,  0.3628, -0.4956]])),\n",
       "             ('nodes.0.callable.block.projector.linear.linear.weight',\n",
       "              tensor([[ 0.2799,  0.1889,  0.3395,  0.4908],\n",
       "                      [-0.3642, -0.4697, -0.1444, -0.0058],\n",
       "                      [ 0.0800,  0.2223,  0.3628, -0.4956]])),\n",
       "             ('nodes.0.callable.block.projector.linear.linear.bias',\n",
       "              tensor([-0.2267, -0.1689, -0.4122])),\n",
       "             ('nodes.1.callable.pz0_mean', tensor([[0., 0., 0., 0.]])),\n",
       "             ('nodes.1.callable.pz0_logstd', tensor([[0., 0., 0., 0.]])),\n",
       "             ('nodes.1.callable.projector.weight',\n",
       "              tensor([[ 0.2588,  0.3487, -0.3603,  0.4279],\n",
       "                      [ 0.1483,  0.3145, -0.0887, -0.4674],\n",
       "                      [-0.0744,  0.1929, -0.2952, -0.0271]])),\n",
       "             ('nodes.1.callable.projector.bias',\n",
       "              tensor([-0.3918, -0.0397,  0.4745]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(problem.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# define neuromancer trainer\n",
    "trainer = Trainer(\n",
    "    problem,\n",
    "    train_data_loader,\n",
    "    train_data_loader,\n",
    "    train_data_loader,\n",
    "    optimizer,\n",
    "    patience=0,\n",
    "    warmup=0,\n",
    "    epochs=15,\n",
    "    eval_metric=\"train_loss\",\n",
    "    train_metric=\"train_loss\",\n",
    "    dev_metric=\"train_loss\",\n",
    "    test_metric=\"train_loss\"\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Learned Stochastic Samples\n",
    "\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromancer3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
